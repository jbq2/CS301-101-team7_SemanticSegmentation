{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbq2/CS301-101-team7_SemanticSegmentation/blob/milestone-2/CS301_101_TermProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "username = 'jbq2'\n",
        "repo = 'CS301-101-team7_SemanticSegmentation'"
      ],
      "metadata": {
        "id": "kQD6SEAgkxOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U31zKDtDjoAh",
        "outputId": "a5fb295a-a83b-4289-88e7-5aba75fddf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS301-101-team7_SemanticSegmentation'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 44 (delta 20), reused 12 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# required installation of all dependencies required\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install patchify\n",
        "!pip install Pillow\n",
        "!pip install segmentation_models\n",
        "!pip install keras\n",
        "!pip install opencv-python\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA5L6IfClY-w",
        "outputId": "32da3c37-d0fc-4712-b5a8-cb322a0dc0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=4bc5aa16d77dda367c1764d1433867782abc50fceafb356031d84de49c528ff7\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.21.6)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.5.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.7.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=c366dc9e670c0dfdd864376a24931f9d095670baec787a42b61bc36a5bc45f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wJjvwz79W2ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing NNI and loading interface with ngrok\n",
        "\n",
        "!pip install nni\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip # download ngrok and unzip it\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!pip install pyngrok\n",
        "!mkdir -p nni_repo\n",
        "!git clone https://github.com/microsoft/nni.git nni_repo/nni # clone NNI's offical repo to get examples\n",
        "!ngrok authtoken 2GmpXSplbu5kON4LBKYMX4BLUrc_HRnx32rrQa8XnSaMQhHQ\n",
        "!nnictl create --config nni_repo/nni/examples/trials/mnist-pytorch/config.yml --port 5001 &\n",
        "get_ipython().system_raw('./ngrok http 5001 &')\n",
        "!curl -s http://localhost:4040/api/tunnels # don't change the port number 4040\n",
        "# Link to NNI Interface - link following \"public_url\" in last line of output (https://xxxx-xx-xx-xx-xxx.ngrok.io)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLAKOz45J5CH",
        "outputId": "eb05e1cf-1b16-460f-b36b-812e9c2cb9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nni in /usr/local/lib/python3.7/dist-packages (2.9)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from nni) (3.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.7/dist-packages (from nni) (6.0)\n",
            "Requirement already satisfied: schema in /usr/local/lib/python3.7/dist-packages (from nni) (0.7.5)\n",
            "Requirement already satisfied: scipy<1.8 in /usr/local/lib/python3.7/dist-packages (from nni) (1.7.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nni) (5.4.8)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: responses in /usr/local/lib/python3.7/dist-packages (from nni) (0.22.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from nni) (0.4.6)\n",
            "Requirement already satisfied: PythonWebHDFS in /usr/local/lib/python3.7/dist-packages (from nni) (0.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nni) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nni) (3.8.0)\n",
            "Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.7/dist-packages (from nni) (0.1.2)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from nni) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nni) (21.3)\n",
            "Requirement already satisfied: websockets>=10.1 in /usr/local/lib/python3.7/dist-packages (from nni) (10.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from nni) (4.1.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from nni) (1.5.0)\n",
            "Requirement already satisfied: numpy<1.22 in /usr/local/lib/python3.7/dist-packages (from nni) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nni) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.7/dist-packages (from nni) (1.0.2)\n",
            "Requirement already satisfied: json-tricks>=3.15.5 in /usr/local/lib/python3.7/dist-packages (from nni) (3.15.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from nni) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (4.3.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (2.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->nni) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.1->nni) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nni) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (4.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->nni) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->nni) (3.9.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo->hyperopt==0.1.2->nni) (2.2.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.7/dist-packages (from PythonWebHDFS->nni) (3.17.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->nni) (2022.9.24)\n",
            "Requirement already satisfied: types-toml in /usr/local/lib/python3.7/dist-packages (from responses->nni) (0.10.8)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from responses->nni) (0.10.2)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from schema->nni) (0.5.5)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "[2022-10-30 19:35:22] \u001b[32mCreating experiment, Experiment ID: \u001b[36mrso65fzq\u001b[0m\n",
            "[2022-10-30 19:35:22] \u001b[32mStarting web server...\u001b[0m\n",
            "[2022-10-30 19:35:23] \u001b[32mSetting up...\u001b[0m\n",
            "[2022-10-30 19:35:23] \u001b[32mWeb portal URLs: \u001b[36mhttp://127.0.0.1:5001 http://172.28.0.2:5001\u001b[0m\n",
            "[2022-10-30 19:35:23] \u001b[32mTo stop experiment run \"nnictl stop rso65fzq\" or \"nnictl stop --all\"\u001b[0m\n",
            "[2022-10-30 19:35:23] \u001b[32mReference: https://nni.readthedocs.io/en/stable/reference/nnictl.html\u001b[0m\n",
            "\u001b[0m\u001b[0m{\"tunnels\":[{\"name\":\"command_line\",\"uri\":\"/api/tunnels/command_line\",\"public_url\":\"https://f8db-107-167-190-249.ngrok.io\",\"proto\":\"https\",\"config\":{\"addr\":\"http://localhost:5001\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":8,\"gauge\":0,\"rate1\":0.0059367352548702745,\"rate5\":0.009888482006022778,\"rate15\":0.005992275250329275,\"p50\":1353029.5,\"p90\":2942767,\"p95\":2942767,\"p99\":2942767},\"http\":{\"count\":8,\"rate1\":0.0059367352548702745,\"rate5\":0.009888482006022778,\"rate15\":0.005992275250329275,\"p50\":484303.5,\"p90\":573519,\"p95\":573519,\"p99\":573519}}},{\"name\":\"command_line (http)\",\"uri\":\"/api/tunnels/command_line%20%28http%29\",\"public_url\":\"http://f8db-107-167-190-249.ngrok.io\",\"proto\":\"http\",\"config\":{\"addr\":\"http://localhost:5001\",\"inspect\":true},\"metrics\":{\"conns\":{\"count\":2,\"gauge\":0,\"rate1\":2.9807877296806424e-7,\"rate5\":0.0006518971720540297,\"rate15\":0.001023787496595663,\"p50\":1075317,\"p90\":1166920,\"p95\":1166920,\"p99\":1166920},\"http\":{\"count\":2,\"rate1\":2.9807877296806424e-7,\"rate5\":0.0006518971720540297,\"rate15\":0.001023787496595663,\"p50\":443203.5,\"p90\":539923,\"p95\":539923,\"p99\":539923}}}],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnictl stop --all  # command to stop all experiments"
      ],
      "metadata": {
        "id": "-8fRbpfyIrR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_multi_unet_model.py\n",
        "\n",
        "# https://youtu.be/jvZm8REF2KY\n",
        "\"\"\"\n",
        "Standard Unet\n",
        "Model not compiled here, instead will be done externally to make it\n",
        "easy to test various loss functions and optimizers. \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.2)(c1)  # Original 0.1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.2)(c2)  # Original 0.1\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.2)(c8)  # Original 0.1\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.2)(c9)  # Original 0.1\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        " "
      ],
      "metadata": {
        "id": "A-LPSALNLoof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FtQuPvjTN9ye",
        "outputId": "d5760fc2-e1d3-4618-fb11-2b060f25173d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import statements; had to change tensorflow keras metrics import\n",
        "# proper path to keras metrics is tensorflow/python/keras/metrics\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "import segmentation_models as sm\n",
        "from tensorflow.python.keras.metrics import MeanIoU\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ],
      "metadata": {
        "id": "XHAxTASmNobG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5d348c-ce69-4d04-84c9-4fb4b2f61169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset from kaggle\n",
        "#!mkdir ~/.kaggle\n",
        "#!mv ~/../content/kaggle.json ~/.kaggle/\n",
        "#!chmod 600 ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download -d humansintheloop/semantic-segmentation-of-aerial-imagery\n",
        "!unzip semantic-segmentation-of-aerial-imagery.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0YfhtRnTXhd",
        "outputId": "fa8cc175-1e6f-4269-d167-e783f1307777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  semantic-segmentation-of-aerial-imagery.zip\n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 1/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 2/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 3/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 4/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 5/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 6/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 7/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_001.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_002.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_003.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_004.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_005.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_006.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_007.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_008.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/images/image_part_009.jpg  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_001.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_002.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_003.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_004.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_005.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_006.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_007.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_008.png  \n",
            "  inflating: Semantic segmentation dataset/Tile 8/masks/image_part_009.png  \n",
            "  inflating: Semantic segmentation dataset/classes.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 228_training_aerial_imagery.py\n",
        "\n",
        "# https://youtu.be/jvZm8REF2KY\n",
        "\"\"\"\n",
        "Explanation of using RGB masks: https://youtu.be/sGAwx4GMe4E\n",
        "\n",
        "https://www.kaggle.com/humansintheloop/semantic-segmentation-of-aerial-imagery\n",
        "\n",
        "The dataset consists of aerial imagery of Dubai obtained by MBRSC satellites and annotated with pixel-wise semantic segmentation in 6 classes. The total volume of the dataset is 72 images grouped into 6 larger tiles. The classes are:\n",
        "\n",
        "Building: #3C1098\n",
        "Land (unpaved area): #8429F6\n",
        "Road: #6EC1E4\n",
        "Vegetation: #FEDD3A\n",
        "Water: #E2A929\n",
        "Unlabeled: #9B9B9B\n",
        "\n",
        "Use patchify....\n",
        "Tile 1: 797 x 644 --> 768 x 512 --> 6\n",
        "Tile 2: 509 x 544 --> 512 x 256 --> 2\n",
        "Tile 3: 682 x 658 --> 512 x 512  --> 4\n",
        "Tile 4: 1099 x 846 --> 1024 x 768 --> 12\n",
        "Tile 5: 1126 x 1058 --> 1024 x 1024 --> 16\n",
        "Tile 6: 859 x 838 --> 768 x 768 --> 9\n",
        "Tile 7: 1817 x 2061 --> 1792 x 2048 --> 56\n",
        "Tile 8: 2149 x 1479 --> 1280 x 2048 --> 40\n",
        "Total 9 images in each folder * (145 patches) = 1305\n",
        "Total 1305 patches of size 256x256\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "root_directory = '~/../content/Semantic segmentation dataset/'\n",
        "\n",
        "patch_size = 256\n",
        "\n",
        "#Read images from repsective 'images' subdirectory\n",
        "#As all images are of ddifferent size we have 2 options, either resize or crop\n",
        "#But, some images are too large and some small. Resizing will change the size of real objects.\n",
        "#Therefore, we will crop them to a nearest size divisible by 256 and then \n",
        "#divide all images into patches of 256x256x3. \n",
        "image_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'images':   #Find all 'images' directories\n",
        "        images = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        for i, image_name in enumerate(images):  \n",
        "            if image_name.endswith(\".jpg\"):   #Only read jpg images...\n",
        "               \n",
        "                image = cv2.imread(path+\"/\"+image_name, 1)  #Read each image as BGR\n",
        "                SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                image = Image.fromarray(image)\n",
        "                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #image = image.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                image = np.array(image)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_img.shape[0]):\n",
        "                    for j in range(patches_img.shape[1]):\n",
        "                        \n",
        "                        single_patch_img = patches_img[i,j,:,:]\n",
        "                        \n",
        "                        #Use minmaxscaler instead of just dividing by 255. \n",
        "                        single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "                        \n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. \n",
        "                        single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        image_dataset.append(single_patch_img)\n",
        "                \n",
        "  \n",
        "                \n",
        "  \n",
        " #Now do the same as above for masks\n",
        " #For this specific dataset we could have added masks to the above code as masks have extension png\n",
        "mask_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(path)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'masks':   #Find all 'images' directories\n",
        "        masks = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        for i, mask_name in enumerate(masks):  \n",
        "            if mask_name.endswith(\".png\"):   #Only read png images... (masks in this dataset)\n",
        "               \n",
        "                mask = cv2.imread(path+\"/\"+mask_name, 1)  #Read each image as Grey (or color but remember to map each color to an integer)\n",
        "                mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
        "                SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                mask = Image.fromarray(mask)\n",
        "                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #mask = mask.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                mask = np.array(mask)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_mask.shape[0]):\n",
        "                    for j in range(patches_mask.shape[1]):\n",
        "                        \n",
        "                        single_patch_mask = patches_mask[i,j,:,:]\n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. #No need to scale masks, but you can do it if you want\n",
        "                        single_patch_mask = single_patch_mask[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        mask_dataset.append(single_patch_mask) \n",
        " \n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "\n",
        "#Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(image_dataset))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(image_dataset[image_number], (patch_size, patch_size, 3)))\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(mask_dataset[image_number], (patch_size, patch_size, 3)))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "\"\"\"\n",
        "RGB to HEX: (Hexadecimel --> base 16)\n",
        "This number divided by sixteen (integer division; ignoring any remainder) gives \n",
        "the first hexadecimal digit (between 0 and F, where the letters A to F represent \n",
        "the numbers 10 to 15). The remainder gives the second hexadecimal digit. \n",
        "0-9 --> 0-9\n",
        "10-15 --> A-F\n",
        "\n",
        "Example: RGB --> R=201, G=, B=\n",
        "\n",
        "R = 201/16 = 12 with remainder of 9. So hex code for R is C9 (remember C=12)\n",
        "\n",
        "Calculating RGB from HEX: #3C1098\n",
        "3C = 3*16 + 12 = 60\n",
        "10 = 1*16 + 0 = 16\n",
        "98 = 9*16 + 8 = 152\n",
        "\n",
        "\"\"\"\n",
        "#Convert HEX to RGB array\n",
        "# Try the following to understand how python handles hex values...\n",
        "a=int('3C', 16)  #3C with base 16. Should return 60. \n",
        "print(a)\n",
        "#Do the same for all RGB channels in each hex code to convert to RGB\n",
        "Building = '#3C1098'.lstrip('#')\n",
        "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#') \n",
        "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
        "\n",
        "Vegetation =  'FEDD3A'.lstrip('#') \n",
        "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
        "\n",
        "Water = 'E2A929'.lstrip('#') \n",
        "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#') \n",
        "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n",
        "\n",
        "label = single_patch_mask\n",
        "\n",
        "# Now replace RGB to integer values to be used as labels.\n",
        "#Find pixels with combination of RGB for the above defined arrays...\n",
        "#if matches then replace all values in that pixel with a specific integer\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == Building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==Land,axis=-1)] = 1\n",
        "    label_seg [np.all(label==Road,axis=-1)] = 2\n",
        "    label_seg [np.all(label==Vegetation,axis=-1)] = 3\n",
        "    label_seg [np.all(label==Water,axis=-1)] = 4\n",
        "    label_seg [np.all(label==Unlabeled,axis=-1)] = 5\n",
        "    \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg\n",
        "\n",
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "    label = rgb_to_2D_label(mask_dataset[i])\n",
        "    labels.append(label)    \n",
        "\n",
        "labels = np.array(labels)   \n",
        "labels = np.expand_dims(labels, axis=3)\n",
        " \n",
        "\n",
        "print(\"Unique labels in label dataset are: \", np.unique(labels))\n",
        "\n",
        "#Another Sanity check, view few mages\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(image_dataset))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(image_dataset[image_number])\n",
        "plt.subplot(122)\n",
        "plt.imshow(labels[image_number][:,:,0])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "\n",
        "n_classes = len(np.unique(labels))\n",
        "from keras.utils import to_categorical\n",
        "labels_cat = to_categorical(labels, num_classes=n_classes)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)\n",
        "\n",
        "\n",
        "#######################################\n",
        "#Parameters for model\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# weights = compute_class_weight('balanced', np.unique(np.ravel(labels,order='C')), \n",
        "#                               np.ravel(labels,order='C'))\n",
        "# print(weights)\n",
        "\n",
        "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=weights) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)  #\n",
        "\n",
        "\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "\n",
        "# from simple_multi_unet_model import multi_unet_model, jacard_coef  (not required because they are defined in a prev code block)\n",
        "\n",
        "metrics=['accuracy', jacard_coef]\n",
        "\n",
        "def get_model():\n",
        "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam', loss=total_loss, metrics=metrics)\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history1 = model.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=5, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)\n",
        "\n",
        "#Minmaxscaler\n",
        "#With weights...[0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]   in Dice loss\n",
        "#With focal loss only, after 100 epochs val jacard is: 0.62  (Mean IoU: 0.6)            \n",
        "#With dice loss only, after 100 epochs val jacard is: 0.74 (Reached 0.7 in 40 epochs)\n",
        "#With dice + 5 focal, after 100 epochs val jacard is: 0.711 (Mean IoU: 0.611)\n",
        "##With dice + 1 focal, after 100 epochs val jacard is: 0.75 (Mean IoU: 0.62)\n",
        "#Using categorical crossentropy as loss: 0.71\n",
        "\n",
        "##With calculated weights in Dice loss.    \n",
        "#With dice loss only, after 100 epochs val jacard is: 0.672 (0.52 iou)\n",
        "\n",
        "\n",
        "##Standardscaler \n",
        "#Using categorical crossentropy as loss: 0.677\n",
        "\n",
        "#model.save('models/satellite_standard_unet_100epochs_7May2021.hdf5')\n",
        "############################################################\n",
        "#TRY ANOTHE MODEL - WITH PRETRINED WEIGHTS\n",
        "#Resnet backbone\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# preprocess input\n",
        "X_train_prepr = preprocess_input(X_train)\n",
        "X_test_prepr = preprocess_input(X_test)\n",
        "\n",
        "# define model\n",
        "model_resnet_backbone = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=n_classes, activation='softmax')\n",
        "\n",
        "# compile keras model with defined optimozer, loss and metrics\n",
        "#model_resnet_backbone.compile(optimizer='adam', loss=focal_loss, metrics=metrics)\n",
        "model_resnet_backbone.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "\n",
        "print(model_resnet_backbone.summary())\n",
        "\n",
        "\n",
        "history2=model_resnet_backbone.fit(X_train_prepr, \n",
        "          y_train,\n",
        "          batch_size=16, \n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test_prepr, y_test))\n",
        "\n",
        "#Minmaxscaler\n",
        "#With weights...[0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]   in Dice loss\n",
        "#With focal loss only, after 100 epochs val jacard is:               \n",
        "#With dice + 5 focal, after 100 epochs val jacard is: 0.73 (reached 0.71 in 40 epochs. So faster training but not better result. )\n",
        "##With dice + 1 focal, after 100 epochs val jacard is:   \n",
        "    ##Using categorical crossentropy as loss: 0.755 (100 epochs)\n",
        "#With calc. weights supplied to model.fit: \n",
        " \n",
        "#Standard scaler\n",
        "#Using categorical crossentropy as loss: 0.74\n",
        "\n",
        "\n",
        "###########################################################\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "history = history1\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['jacard_coef']\n",
        "val_acc = history.history['val_jacard_coef']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training IoU')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation IoU')\n",
        "plt.title('Training and validation IoU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "##################################\n",
        "from keras.models import load_model\n",
        "model = load_model(\"models/satellite_standard_unet_100epochs.hdf5\",\n",
        "                   custom_objects={'dice_loss_plus_2focal_loss': total_loss,\n",
        "                                   'jacard_coef':jacard_coef})\n",
        "\n",
        "#IOU\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
        "y_test_argmax=np.argmax(y_test, axis=3)\n",
        "\n",
        "\n",
        "#Using built in keras function for IoU\n",
        "from keras.metrics import MeanIoU\n",
        "n_classes = 6\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test_argmax, y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
        "\n",
        "#######################################################################\n",
        "#Predict on a few images\n",
        "\n",
        "import random\n",
        "test_img_number = random.randint(0, len(X_test))\n",
        "test_img = X_test[test_img_number]\n",
        "ground_truth=y_test_argmax[test_img_number]\n",
        "#test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input))\n",
        "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img)\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth)\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(predicted_img)\n",
        "plt.show()\n",
        "\n",
        "#####################################################################"
      ],
      "metadata": {
        "id": "A8O4OttQ0lp-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}