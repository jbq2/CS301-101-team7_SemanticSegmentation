{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbq2/CS301-101-team7_SemanticSegmentation/blob/milestone-3/CS301_101_TermProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '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'\n",
        "username = 'jbq2'\n",
        "repo = 'CS301-101-team7_SemanticSegmentation'"
      ],
      "metadata": {
        "id": "kQD6SEAgkxOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U31zKDtDjoAh"
      },
      "outputs": [],
      "source": [
        "!git clone https://{token}@github.com/{username}/{repo}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# required installation of all dependencies required\n",
        "!pip install sklearn\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install patchify\n",
        "!pip install Pillow\n",
        "!pip install segmentation_models\n",
        "!pip install keras\n",
        "!pip install opencv-python\n",
        "!pip install pyngrok\n",
        "!pip install hpbandster\n",
        "!pip install ConfigSpace"
      ],
      "metadata": {
        "id": "DA5L6IfClY-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wJjvwz79W2ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing NNI and loading interface with ngrok\n",
        "\n",
        "!pip install nni\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip # download ngrok and unzip it\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!pip install pyngrok\n",
        "!mkdir -p nni_repo\n",
        "!git clone https://github.com/microsoft/nni.git nni_repo/nni # clone NNI's offical repo to get examples\n",
        "!ngrok authtoken 2GmpXSplbu5kON4LBKYMX4BLUrc_HRnx32rrQa8XnSaMQhHQ\n",
        "!nnictl create --config nni_repo/nni/examples/trials/mnist-pytorch/config.yml --port 5001 &\n",
        "get_ipython().system_raw('./ngrok http 5001 &')\n",
        "!curl -s http://localhost:4040/api/tunnels # don't change the port number 4040\n",
        "# Link to NNI Interface - link following \"public_url\" in last line of output (https://xxxx-xx-xx-xx-xxx.ngrok.io)"
      ],
      "metadata": {
        "id": "yLAKOz45J5CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnictl stop --all  # command to stop all experiments"
      ],
      "metadata": {
        "id": "-8fRbpfyIrR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! cp /content/drive/MyDrive/Fall\\ 2022/CS301/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d humansintheloop/semantic-segmentation-of-aerial-imagery\n",
        "! unzip semantic-segmentation-of-aerial-imagery.zip"
      ],
      "metadata": {
        "id": "wsP6Suj85w9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset from kaggle (peter's code)\n",
        "!mkdir ~/.kaggle\n",
        "!mv ~/../content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d humansintheloop/semantic-segmentation-of-aerial-imagery\n",
        "!unzip semantic-segmentation-of-aerial-imagery.zip"
      ],
      "metadata": {
        "id": "p0YfhtRnTXhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_multi_unet_model.py\n",
        "\n",
        "# https://youtu.be/jvZm8REF2KY\n",
        "\"\"\"\n",
        "Standard Unet\n",
        "Model not compiled here, instead will be done externally to make it\n",
        "easy to test various loss functions and optimizers. \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.2)(c1)  # Original 0.1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    \n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.2)(c2)  # Original 0.1\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "     \n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "     \n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "     \n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    \n",
        "    #Expansive path \n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "     \n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "     \n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.2)(c8)  # Original 0.1\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "     \n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.2)(c9)  # Original 0.1\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "     \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "     \n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    \n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #model.summary()\n",
        "    \n",
        "    return model\n",
        " \n",
        "\n",
        "# 228_training_aerial_imagery.py\n",
        "\n",
        "# https://youtu.be/jvZm8REF2KY\n",
        "\"\"\"\n",
        "Explanation of using RGB masks: https://youtu.be/sGAwx4GMe4E\n",
        "\n",
        "https://www.kaggle.com/humansintheloop/semantic-segmentation-of-aerial-imagery\n",
        "\n",
        "The dataset consists of aerial imagery of Dubai obtained by MBRSC satellites and annotated with pixel-wise semantic segmentation in 6 classes. The total volume of the dataset is 72 images grouped into 6 larger tiles. The classes are:\n",
        "\n",
        "Building: #3C1098\n",
        "Land (unpaved area): #8429F6\n",
        "Road: #6EC1E4\n",
        "Vegetation: #FEDD3A\n",
        "Water: #E2A929\n",
        "Unlabeled: #9B9B9B\n",
        "\n",
        "Use patchify....\n",
        "Tile 1: 797 x 644 --> 768 x 512 --> 6\n",
        "Tile 2: 509 x 544 --> 512 x 256 --> 2\n",
        "Tile 3: 682 x 658 --> 512 x 512  --> 4\n",
        "Tile 4: 1099 x 846 --> 1024 x 768 --> 12\n",
        "Tile 5: 1126 x 1058 --> 1024 x 1024 --> 16\n",
        "Tile 6: 859 x 838 --> 768 x 768 --> 9\n",
        "Tile 7: 1817 x 2061 --> 1792 x 2048 --> 56\n",
        "Tile 8: 2149 x 1479 --> 1280 x 2048 --> 40\n",
        "Total 9 images in each folder * (145 patches) = 1305\n",
        "Total 1305 patches of size 256x256\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# import statements; had to change tensorflow keras metrics import\n",
        "# proper path to keras metrics is tensorflow/python/keras/metrics\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "import segmentation_models as sm\n",
        "from tensorflow.python.keras.metrics import MeanIoU\n",
        "import keras\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "root_directory = 'Semantic segmentation dataset/'  # idt this is the right root directory for us\n",
        "\n",
        "patch_size = 256\n",
        "\n",
        "#Read images from repsective 'images' subdirectory\n",
        "#As all images are of ddifferent size we have 2 options, either resize or crop\n",
        "#But, some images are too large and some small. Resizing will change the size of real objects.\n",
        "#Therefore, we will crop them to a nearest size divisible by 256 and then \n",
        "#divide all images into patches of 256x256x3. \n",
        "\n",
        "image_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(files)  \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'images':   #Find all 'images' directories\n",
        "        images = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        images = sorted(images)\n",
        "        for i, image_name in enumerate(images):  \n",
        "            if image_name.endswith(\".jpg\"):   #Only read jpg images...\n",
        "                #print(image_name)\n",
        "                image = cv2.imread(path+\"/\"+image_name, 1)  #Read each image as BGR\n",
        "                SIZE_X = (image.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (image.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                image = Image.fromarray(image)\n",
        "                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #image = image.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                image = np.array(image)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                #print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_img.shape[0]):\n",
        "                    for j in range(patches_img.shape[1]):\n",
        "                        \n",
        "                        single_patch_img = patches_img[i,j,:,:]\n",
        "                        \n",
        "                        #Use minmaxscaler instead of just dividing by 255. \n",
        "                        single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "                        \n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. \n",
        "                        single_patch_img = single_patch_img[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        image_dataset.append(single_patch_img)\n",
        "                \n",
        "  \n",
        "                \n",
        "  \n",
        " #Now do the same as above for masks\n",
        " #For this specific dataset we could have added masks to the above code as masks have extension png\n",
        "mask_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    #print(files)    \n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'masks':   #Find all 'images' directories\n",
        "        masks = os.listdir(path)  #List of all image names in this subdirectory\n",
        "        masks = sorted(masks)\n",
        "        for i, mask_name in enumerate(masks):  \n",
        "            if mask_name.endswith(\".png\"):   #Only read png images... (masks in this dataset)\n",
        "                #print(mask_name)\n",
        "                mask = cv2.imread(path+\"/\"+mask_name, 1)  #Read each image as Grey (or color but remember to map each color to an integer)\n",
        "                mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
        "                SIZE_X = (mask.shape[1]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                SIZE_Y = (mask.shape[0]//patch_size)*patch_size #Nearest size divisible by our patch size\n",
        "                mask = Image.fromarray(mask)\n",
        "                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                #mask = mask.resize((SIZE_X, SIZE_Y))  #Try not to resize for semantic segmentation\n",
        "                mask = np.array(mask)             \n",
        "       \n",
        "                #Extract patches from each image\n",
        "                #print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size)  #Step=256 for 256 patches means no overlap\n",
        "        \n",
        "                for i in range(patches_mask.shape[0]):\n",
        "                    for j in range(patches_mask.shape[1]):\n",
        "                        \n",
        "                        single_patch_mask = patches_mask[i,j,:,:]\n",
        "                        #single_patch_img = (single_patch_img.astype('float32')) / 255. #No need to scale masks, but you can do it if you want\n",
        "                        single_patch_mask = single_patch_mask[0] #Drop the extra unecessary dimension that patchify adds.                               \n",
        "                        mask_dataset.append(single_patch_mask) \n",
        " \n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "\n",
        "#Sanity check, view few mages -- commented this out to reduce output size\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(image_dataset))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(np.reshape(image_dataset[image_number], (patch_size, patch_size, 3)))  # throwing an out of bounds error\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.reshape(mask_dataset[image_number], (patch_size, patch_size, 3)))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "\"\"\"\n",
        "RGB to HEX: (Hexadecimel --> base 16)\n",
        "This number divided by sixteen (integer division; ignoring any remainder) gives \n",
        "the first hexadecimal digit (between 0 and F, where the letters A to F represent \n",
        "the numbers 10 to 15). The remainder gives the second hexadecimal digit. \n",
        "0-9 --> 0-9\n",
        "10-15 --> A-F\n",
        "\n",
        "Example: RGB --> R=201, G=, B=\n",
        "\n",
        "R = 201/16 = 12 with remainder of 9. So hex code for R is C9 (remember C=12)\n",
        "\n",
        "Calculating RGB from HEX: #3C1098\n",
        "3C = 3*16 + 12 = 60\n",
        "10 = 1*16 + 0 = 16\n",
        "98 = 9*16 + 8 = 152\n",
        "\n",
        "\"\"\"\n",
        "#Convert HEX to RGB array\n",
        "# Try the following to understand how python handles hex values...\n",
        "a=int('3C', 16)  #3C with base 16. Should return 60. \n",
        "# print(a) # commented this out\n",
        "#Do the same for all RGB channels in each hex code to convert to RGB\n",
        "Building = '#3C1098'.lstrip('#')\n",
        "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#') \n",
        "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
        "\n",
        "Vegetation =  'FEDD3A'.lstrip('#') \n",
        "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
        "\n",
        "Water = 'E2A929'.lstrip('#') \n",
        "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#') \n",
        "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n",
        "\n",
        "label = single_patch_mask\n",
        "\n",
        "# Now replace RGB to integer values to be used as labels.\n",
        "#Find pixels with combination of RGB for the above defined arrays...\n",
        "#if matches then replace all values in that pixel with a specific integer\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == Building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==Land,axis=-1)] = 1\n",
        "    label_seg [np.all(label==Road,axis=-1)] = 2\n",
        "    label_seg [np.all(label==Vegetation,axis=-1)] = 3\n",
        "    label_seg [np.all(label==Water,axis=-1)] = 4\n",
        "    label_seg [np.all(label==Unlabeled,axis=-1)] = 5\n",
        "    \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg\n",
        "\n",
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "    label = rgb_to_2D_label(mask_dataset[i])\n",
        "    labels.append(label)    \n",
        "\n",
        "labels = np.array(labels)   \n",
        "labels = np.expand_dims(labels, axis=3)\n",
        " \n",
        "\n",
        "# print(\"Unique labels in label dataset are: \", np.unique(labels)) # commented this out\n",
        "\n",
        "#Another Sanity check, view few mages - commented this out to reduce the output size\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "image_number = random.randint(0, len(image_dataset))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(121)\n",
        "plt.imshow(image_dataset[image_number])\n",
        "plt.subplot(122)\n",
        "plt.imshow(labels[image_number][:,:,0])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "\n",
        "n_classes = len(np.unique(labels))\n",
        "from keras.utils import to_categorical\n",
        "labels_cat = to_categorical(labels, num_classes=n_classes)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)\n",
        "\n",
        "\n",
        "#######################################\n",
        "#Parameters for model\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "# set class weights for dice_loss\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# weights = compute_class_weight('balanced', np.unique(np.ravel(labels,order='C')), \n",
        "#                               np.ravel(labels,order='C'))\n",
        "# print(weights)\n",
        "\n",
        "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=weights)  # loss function that is widely used in computer vision: calculates similarity between 2 images \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()  # improved cross entropy loss function: adds more weight to easily misclassified examples\n",
        "total_loss = dice_loss + (1 * focal_loss)  # overall loss function combines dice_loss and focal_loss\n",
        "\n",
        "\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "\n",
        "# from simple_multi_unet_model import multi_unet_model, jacard_coef  (not required because they are defined in a prev code block)\n",
        "\n",
        "# metrics=['accuracy', jacard_coef]\n",
        "\n",
        "# def get_model():\n",
        "#     return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "# model = get_model()\n",
        "# #model.compile(optimizer='adam', loss=total_loss, metrics=metrics)\n",
        "# model.compile(optimizer='adam', loss=total_loss, metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "# #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# history1 = model.fit(X_train, y_train, \n",
        "#                     batch_size = 4, \n",
        "#                     verbose=1, \n",
        "#                     epochs=5, \n",
        "#                     validation_data=(X_test, y_test), \n",
        "#                     shuffle=False)\n",
        "\n",
        "\n",
        "# ###########################################################\n",
        "# #plot the training and validation accuracy and loss at each epoch\n",
        "# history = history1\n",
        "# loss = history.history['loss']\n",
        "# val_loss = history.history['val_loss']\n",
        "# epochs = range(1, len(loss) + 1)\n",
        "# plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# precision = history.history['precision_3']\n",
        "# recall = history.history['recall_3']\n",
        "\n",
        "# plt.plot(recall, precision, 'y', label='Precision vs Recall')\n",
        "# plt.title('Precision vs Recall')\n",
        "# plt.xlabel('Recall')\n",
        "# plt.ylabel('Precision')\n",
        "# #plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "A8O4OttQ0lp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "#Prediction on 10 images\n",
        "\n",
        "import random\n",
        "for i in range(10):\n",
        "  print(\"Prediction\", i+1)\n",
        "  test_img_number = random.randint(0, len(X_test))\n",
        "  test_img = X_test[test_img_number]\n",
        "  ground_truth=y_test[test_img_number]\n",
        "  #test_img_norm=test_img[:,:,0][:,:,None]\n",
        "  test_img_input=np.expand_dims(test_img, 0)\n",
        "  prediction = (model.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  ground_truth=np.argmax(ground_truth, axis=2)[:,:]\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.subplot(231)\n",
        "  plt.title('Testing Image')\n",
        "  plt.imshow(test_img)\n",
        "  plt.subplot(232)\n",
        "  plt.title('Testing Label')\n",
        "  plt.imshow(ground_truth)\n",
        "  plt.subplot(233)\n",
        "  plt.title('Prediction on test image')\n",
        "  plt.imshow(predicted_img)\n",
        "  plt.show()\n",
        "\n",
        "#####################################################################"
      ],
      "metadata": {
        "id": "8cYuHOShu1gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This block of code will be for HPO.\n",
        "HPO using HpBandster BOHB. \n",
        "First, set up a worker; workers will evaluate a hyperparam setting\n",
        "and return the associated minimized loss from that setting.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import socket, os\n",
        "\n",
        "import ConfigSpace as cs\n",
        "from hpbandster.core.worker import Worker\n",
        "\n",
        "\n",
        "class MyWorker(Worker):\n",
        "    i = 1\n",
        "    def __init__(self, *args, sleep_interval=0, **kwargs):\n",
        "        \"\"\"\n",
        "        TODO:\n",
        "\n",
        "        Load data here.\n",
        "        Basically the part where we set up the images and \n",
        "        matrices to train the model with.\n",
        "\n",
        "        Not exatly sure what parts will need to be copied and\n",
        "        pasted though.\n",
        "        \n",
        "        Still gotta figure this out\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # what i got from the example is that we can preprocess\n",
        "        # data in another block and make the dataset variables global\n",
        "        # in this function, and set them to the self.data variables:\n",
        "\n",
        "        global X_train, X_test, y_train, y_test\n",
        "\n",
        "        self.img_rows = self.img_cols = 256\n",
        "        self.x_train, self.y_train = X_train, y_train\n",
        "        self.x_test, self.y_test   = X_test, y_test\n",
        "\n",
        "    def compute(self, config, budget, **kwargs):\n",
        "        print(\"Iteration\", i)\n",
        "        i += 1\n",
        "        \"\"\"\n",
        "        TODO: \n",
        "\n",
        "        This compute function is required since MyWorker extends Worker.\n",
        "        Compute will be called repeatedly during optimization.\n",
        "\n",
        "        config: dictionary containing sampled hyperparam configs.\n",
        "        budget: amount of epochs the model will use to train (not sure\n",
        "        how this will go because one of our hyperparams is # of epochs).\n",
        "\n",
        "        Basically will be a copy and paste the following parts\n",
        "        of fitting the data to the model:\n",
        "        - initalizing weights\n",
        "        - total loss = dice loss + focal loss\n",
        "        - getting image dimensions (requires __init__ to load data)\n",
        "        - get the simple multi unet model\n",
        "        - compile it using the config hyperparams\n",
        "        - model.fit\n",
        "        \"\"\"\n",
        "        def jacard_coef(y_true, y_pred):\n",
        "            y_true_f = K.flatten(y_true)\n",
        "            y_pred_f = K.flatten(y_pred)\n",
        "            intersection = K.sum(y_true_f * y_pred_f)\n",
        "            return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "        def multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=1):\n",
        "        #Build the model\n",
        "            inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "            #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "            s = inputs\n",
        "\n",
        "            #Contraction path\n",
        "            c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "            c1 = Dropout(0.2)(c1)  # Original 0.1\n",
        "            c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "            p1 = MaxPooling2D((2, 2))(c1)\n",
        "            \n",
        "            c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "            c2 = Dropout(0.2)(c2)  # Original 0.1\n",
        "            c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "            p2 = MaxPooling2D((2, 2))(c2)\n",
        "            \n",
        "            c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "            c3 = Dropout(0.2)(c3)\n",
        "            c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "            p3 = MaxPooling2D((2, 2))(c3)\n",
        "            \n",
        "            c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "            c4 = Dropout(0.2)(c4)\n",
        "            c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "            p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "            \n",
        "            c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "            c5 = Dropout(0.3)(c5)\n",
        "            c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "            \n",
        "            #Expansive path \n",
        "            u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "            u6 = concatenate([u6, c4])\n",
        "            c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "            c6 = Dropout(0.2)(c6)\n",
        "            c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "            \n",
        "            u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "            u7 = concatenate([u7, c3])\n",
        "            c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "            c7 = Dropout(0.2)(c7)\n",
        "            c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "            \n",
        "            u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "            u8 = concatenate([u8, c2])\n",
        "            c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "            c8 = Dropout(0.2)(c8)  # Original 0.1\n",
        "            c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "            \n",
        "            u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "            u9 = concatenate([u9, c1], axis=3)\n",
        "            c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "            c9 = Dropout(0.2)(c9)  # Original 0.1\n",
        "            c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "            \n",
        "            outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "            \n",
        "            model = Model(inputs=[inputs], outputs=[outputs])\n",
        "            \n",
        "            #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "            #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "            \n",
        "            #model.summary()\n",
        "            \n",
        "            return model\n",
        "\n",
        "        \n",
        "        def get_model():\n",
        "            return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "        print(\"Config Space:\\n\", config)\n",
        "\n",
        "        # defining weights and total_loss\n",
        "        weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]\n",
        "        dice_loss = sm.losses.DiceLoss(class_weights=weights)  # loss function that is widely used in computer vision: calculates similarity between 2 images \n",
        "        focal_loss = sm.losses.CategoricalFocalLoss()  # improved cross entropy loss function: adds more weight to easily misclassified examples\n",
        "        total_loss = dice_loss + (1 * focal_loss)  # overall loss function combines dice_loss and focal_loss\n",
        "\n",
        "        IMG_HEIGHT = X_train.shape[1]\n",
        "        IMG_WIDTH  = X_train.shape[2]\n",
        "        IMG_CHANNELS = X_train.shape[3]\n",
        "\n",
        "        # getting multi unet model\n",
        "        model = get_model()\n",
        "\n",
        "        # defining optimizer based on config\n",
        "        if config['optimizer'] == 'adam':\n",
        "            Optimizer = keras.optimizers.Adam(lr=config['learning_rate'])\n",
        "        else:\n",
        "            Optimizer = keras.optimizers.SGD(lr=config['learning_rate'], momentum=config['sgd_momentum'])\n",
        "\n",
        "        # compiling with config hyperparams\n",
        "        model.compile(loss=total_loss,\n",
        "                      optimizer=Optimizer,\n",
        "                      metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "        # fitting model with config\n",
        "        history = model.fit(self.x_train, self.y_train,\n",
        "                      batch_size=config['batch_size'],\n",
        "                      epochs=int(budget),\n",
        "                      # epochs=config['epochs'],\n",
        "                      verbose=1,\n",
        "                      validation_data=(self.x_test, self.y_test),\n",
        "                      shuffle=False)\n",
        "\n",
        "        # get train and test accuracy\n",
        "        train_score = 1 - sum(history.history['loss']) / len(history.history['loss'])\n",
        "        test_score = 1 - sum(history.history['val_loss']) / len(history.history['val_loss'])\n",
        "\n",
        "        import IPython; IPython.embed()\n",
        "        return ({\n",
        "                'loss': 1 - test_score, # remember: HpBandSter always minimizes!\n",
        "                'info': {       \n",
        "                    'test accuracy': test_score,\n",
        "                    'train accuracy': train_score\n",
        "                }\n",
        "        })\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_configspace():\n",
        "        \"\"\"\n",
        "        Hyperparameters of interest:\n",
        "            - learning rate\n",
        "            - optimizer (sgd or adam)\n",
        "            - sgd_momentum\n",
        "            - batch size\n",
        "        \"\"\"\n",
        "        config_space = cs.ConfigurationSpace()\n",
        "        learning_rate = cs.hyperparameters.UniformFloatHyperparameter('learning_rate', lower=0.0001, upper=0.1, default_value=0.001, log=True)\n",
        "        optimizer = cs.hyperparameters.CategoricalHyperparameter('optimizer', ['adam', 'sgd'])\n",
        "        sgd_momentum = cs.hyperparameters.UniformFloatHyperparameter('sgd_momentum', lower=0.0, upper=0.99, default_value=0.9, log=False)\n",
        "        batch_size = cs.hyperparameters.UniformIntegerHyperparameter('batch_size', lower=1, upper=32, default_value=16)\n",
        "        # epochs = cs.hyperparameters.UniformIntegerHyperparameter('epochs', lower=30, upper=100, default_value=100)\n",
        "        config_space.add_hyperparameters([learning_rate, optimizer, sgd_momentum, batch_size])\n",
        "        return config_space\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "a9SIgH0ATXcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HPO Using BOHB (n_iterations = 5) Results (first test):\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/98120760/202880199-55c25870-e8a9-4223-afec-aa84356bd939.png)"
      ],
      "metadata": {
        "id": "RZLFCd5cIlbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hpbandster.optimizers.bohb import BOHB\n",
        "from hpbandster.core.nameserver import NameServer\n",
        "import socket, os\n",
        "\n",
        "NS = NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
        "NS.start()\n",
        "\n",
        "worker = MyWorker(sleep_interval=0, nameserver='127.0.0.1', run_id='example1')\n",
        "worker.run(background=True)\n",
        "bohb = BOHB(configspace=worker.get_configspace(), run_id='example1', \n",
        "            nameserver='127.0.0.1', min_budget=25, max_budget=75)\n",
        "result = bohb.run(n_iterations=30)"
      ],
      "metadata": {
        "id": "Z5jGwdMEMv4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7d265b5-3952-4ec6-e48d-d4f8f1a0d41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config Space:\n",
            " {'batch_size': 25, 'learning_rate': 0.010423454645547298, 'optimizer': 'adam', 'sgd_momentum': 0.43521186058412903}\n",
            "Epoch 1/25\n",
            "42/42 [==============================] - 8s 107ms/step - loss: 1.2901 - precision: 0.5290 - recall: 0.5166 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 2/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 3/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 4/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 5/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 6/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 7/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 8/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 9/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 10/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 11/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 12/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 13/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 14/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 15/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 16/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 17/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 18/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 19/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 20/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 21/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 22/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 23/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 24/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Epoch 25/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 1.2951 - precision: 0.5311 - recall: 0.5311 - val_loss: 1.2842 - val_precision: 0.5400 - val_recall: 0.5400\n",
            "Config Space:\n",
            " {'batch_size': 26, 'learning_rate': 0.0006325494254217899, 'optimizer': 'sgd', 'sgd_momentum': 0.20260222918369616}\n",
            "Epoch 1/25\n",
            "41/41 [==============================] - 7s 101ms/step - loss: 1.0323 - precision: 0.1119 - recall: 0.0155 - val_loss: 1.0278 - val_precision: 0.4236 - val_recall: 0.0014\n",
            "Epoch 2/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0312 - precision: 0.1127 - recall: 0.0140 - val_loss: 1.0270 - val_precision: 0.5019 - val_recall: 0.0010\n",
            "Epoch 3/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0301 - precision: 0.1139 - recall: 0.0128 - val_loss: 1.0263 - val_precision: 0.5513 - val_recall: 7.7960e-04\n",
            "Epoch 4/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0292 - precision: 0.1155 - recall: 0.0117 - val_loss: 1.0257 - val_precision: 0.5954 - val_recall: 6.0263e-04\n",
            "Epoch 5/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0283 - precision: 0.1173 - recall: 0.0109 - val_loss: 1.0252 - val_precision: 0.6317 - val_recall: 4.7671e-04\n",
            "Epoch 6/25\n",
            "41/41 [==============================] - 3s 69ms/step - loss: 1.0275 - precision: 0.1197 - recall: 0.0101 - val_loss: 1.0246 - val_precision: 0.6673 - val_recall: 3.8176e-04\n",
            "Epoch 7/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0267 - precision: 0.1221 - recall: 0.0095 - val_loss: 1.0241 - val_precision: 0.6976 - val_recall: 3.0944e-04\n",
            "Epoch 8/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0260 - precision: 0.1254 - recall: 0.0090 - val_loss: 1.0237 - val_precision: 0.7192 - val_recall: 2.5385e-04\n",
            "Epoch 9/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0254 - precision: 0.1294 - recall: 0.0087 - val_loss: 1.0233 - val_precision: 0.7421 - val_recall: 2.0976e-04\n",
            "Epoch 10/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0248 - precision: 0.1332 - recall: 0.0084 - val_loss: 1.0228 - val_precision: 0.7691 - val_recall: 1.7743e-04\n",
            "Epoch 11/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0242 - precision: 0.1381 - recall: 0.0081 - val_loss: 1.0225 - val_precision: 0.7964 - val_recall: 1.5136e-04\n",
            "Epoch 12/25\n",
            "41/41 [==============================] - 3s 69ms/step - loss: 1.0236 - precision: 0.1435 - recall: 0.0080 - val_loss: 1.0221 - val_precision: 0.8283 - val_recall: 1.3026e-04\n",
            "Epoch 13/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0231 - precision: 0.1500 - recall: 0.0079 - val_loss: 1.0217 - val_precision: 0.8539 - val_recall: 1.1272e-04\n",
            "Epoch 14/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0226 - precision: 0.1569 - recall: 0.0079 - val_loss: 1.0213 - val_precision: 0.8789 - val_recall: 9.6697e-05\n",
            "Epoch 15/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0221 - precision: 0.1646 - recall: 0.0079 - val_loss: 1.0210 - val_precision: 0.8894 - val_recall: 8.4186e-05\n",
            "Epoch 16/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0216 - precision: 0.1738 - recall: 0.0081 - val_loss: 1.0206 - val_precision: 0.8912 - val_recall: 7.5183e-05\n",
            "Epoch 17/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0211 - precision: 0.1832 - recall: 0.0082 - val_loss: 1.0203 - val_precision: 0.8967 - val_recall: 6.6472e-05\n",
            "Epoch 18/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0207 - precision: 0.1937 - recall: 0.0084 - val_loss: 1.0200 - val_precision: 0.8985 - val_recall: 6.0041e-05\n",
            "Epoch 19/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0202 - precision: 0.2057 - recall: 0.0087 - val_loss: 1.0196 - val_precision: 0.9012 - val_recall: 5.4370e-05\n",
            "Epoch 20/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0198 - precision: 0.2187 - recall: 0.0091 - val_loss: 1.0193 - val_precision: 0.9004 - val_recall: 4.9693e-05\n",
            "Epoch 21/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0194 - precision: 0.2325 - recall: 0.0095 - val_loss: 1.0190 - val_precision: 0.9050 - val_recall: 4.5133e-05\n",
            "Epoch 22/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0190 - precision: 0.2477 - recall: 0.0101 - val_loss: 1.0187 - val_precision: 0.9014 - val_recall: 4.0632e-05\n",
            "Epoch 23/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0185 - precision: 0.2643 - recall: 0.0106 - val_loss: 1.0183 - val_precision: 0.9033 - val_recall: 3.7124e-05\n",
            "Epoch 24/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0181 - precision: 0.2816 - recall: 0.0113 - val_loss: 1.0180 - val_precision: 0.8985 - val_recall: 3.4142e-05\n",
            "Epoch 25/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0178 - precision: 0.2993 - recall: 0.0121 - val_loss: 1.0177 - val_precision: 0.9038 - val_recall: 3.1862e-05\n",
            "Config Space:\n",
            " {'batch_size': 30, 'learning_rate': 0.006410637905687802, 'optimizer': 'sgd', 'sgd_momentum': 0.10204604192227403}\n",
            "Epoch 1/25\n",
            "35/35 [==============================] - 8s 142ms/step - loss: 1.0649 - precision: 0.0708 - recall: 0.0216 - val_loss: 1.0270 - val_precision: 0.0152 - val_recall: 4.3262e-06\n",
            "Epoch 2/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0294 - precision: 0.4052 - recall: 0.0606 - val_loss: 1.0114 - val_precision: 0.9036 - val_recall: 0.1353\n",
            "Epoch 3/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0176 - precision: 0.7267 - recall: 0.1600 - val_loss: 1.0080 - val_precision: 0.8641 - val_recall: 0.3756\n",
            "Epoch 4/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0132 - precision: 0.7812 - recall: 0.2380 - val_loss: 1.0068 - val_precision: 0.8364 - val_recall: 0.4405\n",
            "Epoch 5/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0111 - precision: 0.7910 - recall: 0.2835 - val_loss: 1.0060 - val_precision: 0.8208 - val_recall: 0.4546\n",
            "Epoch 6/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0097 - precision: 0.7935 - recall: 0.3089 - val_loss: 1.0053 - val_precision: 0.8138 - val_recall: 0.4595\n",
            "Epoch 7/25\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0087 - precision: 0.7947 - recall: 0.3236 - val_loss: 1.0047 - val_precision: 0.8109 - val_recall: 0.4614\n",
            "Epoch 8/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0078 - precision: 0.7958 - recall: 0.3326 - val_loss: 1.0041 - val_precision: 0.8099 - val_recall: 0.4621\n",
            "Epoch 9/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0071 - precision: 0.7968 - recall: 0.3388 - val_loss: 1.0036 - val_precision: 0.8097 - val_recall: 0.4625\n",
            "Epoch 10/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0065 - precision: 0.7976 - recall: 0.3433 - val_loss: 1.0031 - val_precision: 0.8097 - val_recall: 0.4627\n",
            "Epoch 11/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0059 - precision: 0.7983 - recall: 0.3469 - val_loss: 1.0026 - val_precision: 0.8097 - val_recall: 0.4629\n",
            "Epoch 12/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0054 - precision: 0.7987 - recall: 0.3501 - val_loss: 1.0022 - val_precision: 0.8097 - val_recall: 0.4630\n",
            "Epoch 13/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0049 - precision: 0.7990 - recall: 0.3528 - val_loss: 1.0018 - val_precision: 0.8095 - val_recall: 0.4632\n",
            "Epoch 14/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0045 - precision: 0.7992 - recall: 0.3555 - val_loss: 1.0014 - val_precision: 0.8093 - val_recall: 0.4635\n",
            "Epoch 15/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0041 - precision: 0.7994 - recall: 0.3579 - val_loss: 1.0010 - val_precision: 0.8090 - val_recall: 0.4637\n",
            "Epoch 16/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0037 - precision: 0.7994 - recall: 0.3602 - val_loss: 1.0007 - val_precision: 0.8086 - val_recall: 0.4640\n",
            "Epoch 17/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0033 - precision: 0.7993 - recall: 0.3623 - val_loss: 1.0004 - val_precision: 0.8083 - val_recall: 0.4643\n",
            "Epoch 18/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0030 - precision: 0.7994 - recall: 0.3643 - val_loss: 1.0000 - val_precision: 0.8079 - val_recall: 0.4646\n",
            "Epoch 19/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0027 - precision: 0.7994 - recall: 0.3663 - val_loss: 0.9997 - val_precision: 0.8075 - val_recall: 0.4649\n",
            "Epoch 20/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0024 - precision: 0.7993 - recall: 0.3680 - val_loss: 0.9994 - val_precision: 0.8070 - val_recall: 0.4652\n",
            "Epoch 21/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0021 - precision: 0.7991 - recall: 0.3698 - val_loss: 0.9992 - val_precision: 0.8066 - val_recall: 0.4655\n",
            "Epoch 22/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0018 - precision: 0.7991 - recall: 0.3714 - val_loss: 0.9989 - val_precision: 0.8062 - val_recall: 0.4658\n",
            "Epoch 23/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0015 - precision: 0.7989 - recall: 0.3729 - val_loss: 0.9987 - val_precision: 0.8058 - val_recall: 0.4661\n",
            "Epoch 24/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0012 - precision: 0.7988 - recall: 0.3744 - val_loss: 0.9984 - val_precision: 0.8054 - val_recall: 0.4663\n",
            "Epoch 25/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0010 - precision: 0.7986 - recall: 0.3758 - val_loss: 0.9982 - val_precision: 0.8050 - val_recall: 0.4666\n",
            "Config Space:\n",
            " {'batch_size': 30, 'learning_rate': 0.006410637905687802, 'optimizer': 'sgd', 'sgd_momentum': 0.10204604192227403}\n",
            "Epoch 1/75\n",
            "35/35 [==============================] - 6s 105ms/step - loss: 1.0173 - precision: 0.6629 - recall: 0.1758 - val_loss: 1.0138 - val_precision: 0.8712 - val_recall: 0.0783\n",
            "Epoch 2/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0144 - precision: 0.7335 - recall: 0.2029 - val_loss: 1.0116 - val_precision: 0.8721 - val_recall: 0.0954\n",
            "Epoch 3/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0125 - precision: 0.7591 - recall: 0.2274 - val_loss: 1.0098 - val_precision: 0.8806 - val_recall: 0.1379\n",
            "Epoch 4/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0110 - precision: 0.7678 - recall: 0.2484 - val_loss: 1.0084 - val_precision: 0.8747 - val_recall: 0.1730\n",
            "Epoch 5/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0099 - precision: 0.7705 - recall: 0.2659 - val_loss: 1.0072 - val_precision: 0.8691 - val_recall: 0.2027\n",
            "Epoch 6/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0090 - precision: 0.7709 - recall: 0.2804 - val_loss: 1.0062 - val_precision: 0.8663 - val_recall: 0.2300\n",
            "Epoch 7/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0082 - precision: 0.7706 - recall: 0.2923 - val_loss: 1.0054 - val_precision: 0.8642 - val_recall: 0.2515\n",
            "Epoch 8/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0075 - precision: 0.7701 - recall: 0.3018 - val_loss: 1.0047 - val_precision: 0.8620 - val_recall: 0.2662\n",
            "Epoch 9/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0069 - precision: 0.7696 - recall: 0.3098 - val_loss: 1.0042 - val_precision: 0.8598 - val_recall: 0.2757\n",
            "Epoch 10/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0063 - precision: 0.7694 - recall: 0.3163 - val_loss: 1.0038 - val_precision: 0.8580 - val_recall: 0.2820\n",
            "Epoch 11/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0058 - precision: 0.7693 - recall: 0.3219 - val_loss: 1.0034 - val_precision: 0.8566 - val_recall: 0.2865\n",
            "Epoch 12/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0054 - precision: 0.7693 - recall: 0.3264 - val_loss: 1.0030 - val_precision: 0.8555 - val_recall: 0.2900\n",
            "Epoch 13/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0049 - precision: 0.7695 - recall: 0.3304 - val_loss: 1.0027 - val_precision: 0.8547 - val_recall: 0.2933\n",
            "Epoch 14/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0046 - precision: 0.7697 - recall: 0.3337 - val_loss: 1.0024 - val_precision: 0.8543 - val_recall: 0.2967\n",
            "Epoch 15/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0042 - precision: 0.7701 - recall: 0.3366 - val_loss: 1.0021 - val_precision: 0.8540 - val_recall: 0.3003\n",
            "Epoch 16/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0039 - precision: 0.7705 - recall: 0.3391 - val_loss: 1.0019 - val_precision: 0.8540 - val_recall: 0.3042\n",
            "Epoch 17/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0036 - precision: 0.7710 - recall: 0.3413 - val_loss: 1.0017 - val_precision: 0.8541 - val_recall: 0.3085\n",
            "Epoch 18/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0034 - precision: 0.7715 - recall: 0.3434 - val_loss: 1.0015 - val_precision: 0.8544 - val_recall: 0.3133\n",
            "Epoch 19/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0031 - precision: 0.7721 - recall: 0.3451 - val_loss: 1.0013 - val_precision: 0.8548 - val_recall: 0.3187\n",
            "Epoch 20/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0029 - precision: 0.7727 - recall: 0.3469 - val_loss: 1.0011 - val_precision: 0.8554 - val_recall: 0.3248\n",
            "Epoch 21/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0027 - precision: 0.7733 - recall: 0.3485 - val_loss: 1.0009 - val_precision: 0.8561 - val_recall: 0.3316\n",
            "Epoch 22/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0024 - precision: 0.7741 - recall: 0.3500 - val_loss: 1.0007 - val_precision: 0.8570 - val_recall: 0.3392\n",
            "Epoch 23/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0022 - precision: 0.7747 - recall: 0.3513 - val_loss: 1.0006 - val_precision: 0.8579 - val_recall: 0.3471\n",
            "Epoch 24/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0021 - precision: 0.7756 - recall: 0.3528 - val_loss: 1.0004 - val_precision: 0.8586 - val_recall: 0.3548\n",
            "Epoch 25/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0019 - precision: 0.7763 - recall: 0.3542 - val_loss: 1.0002 - val_precision: 0.8591 - val_recall: 0.3622\n",
            "Epoch 26/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0017 - precision: 0.7769 - recall: 0.3554 - val_loss: 1.0001 - val_precision: 0.8594 - val_recall: 0.3690\n",
            "Epoch 27/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0015 - precision: 0.7776 - recall: 0.3567 - val_loss: 0.9999 - val_precision: 0.8595 - val_recall: 0.3752\n",
            "Epoch 28/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0013 - precision: 0.7784 - recall: 0.3579 - val_loss: 0.9997 - val_precision: 0.8594 - val_recall: 0.3807\n",
            "Epoch 29/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0012 - precision: 0.7791 - recall: 0.3591 - val_loss: 0.9996 - val_precision: 0.8590 - val_recall: 0.3857\n",
            "Epoch 30/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0010 - precision: 0.7798 - recall: 0.3603 - val_loss: 0.9994 - val_precision: 0.8585 - val_recall: 0.3901\n",
            "Epoch 31/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0009 - precision: 0.7806 - recall: 0.3615 - val_loss: 0.9992 - val_precision: 0.8578 - val_recall: 0.3941\n",
            "Epoch 32/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0007 - precision: 0.7812 - recall: 0.3626 - val_loss: 0.9991 - val_precision: 0.8571 - val_recall: 0.3976\n",
            "Epoch 33/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0006 - precision: 0.7819 - recall: 0.3638 - val_loss: 0.9989 - val_precision: 0.8563 - val_recall: 0.4008\n",
            "Epoch 34/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0004 - precision: 0.7825 - recall: 0.3649 - val_loss: 0.9987 - val_precision: 0.8555 - val_recall: 0.4038\n",
            "Epoch 35/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0003 - precision: 0.7832 - recall: 0.3660 - val_loss: 0.9986 - val_precision: 0.8547 - val_recall: 0.4065\n",
            "Epoch 36/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0001 - precision: 0.7838 - recall: 0.3671 - val_loss: 0.9984 - val_precision: 0.8538 - val_recall: 0.4089\n",
            "Epoch 37/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0000 - precision: 0.7845 - recall: 0.3682 - val_loss: 0.9982 - val_precision: 0.8529 - val_recall: 0.4112\n",
            "Epoch 38/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9998 - precision: 0.7851 - recall: 0.3693 - val_loss: 0.9981 - val_precision: 0.8519 - val_recall: 0.4133\n",
            "Epoch 39/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9997 - precision: 0.7857 - recall: 0.3703 - val_loss: 0.9979 - val_precision: 0.8510 - val_recall: 0.4153\n",
            "Epoch 40/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9996 - precision: 0.7863 - recall: 0.3713 - val_loss: 0.9978 - val_precision: 0.8501 - val_recall: 0.4171\n",
            "Epoch 41/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9994 - precision: 0.7868 - recall: 0.3724 - val_loss: 0.9976 - val_precision: 0.8493 - val_recall: 0.4189\n",
            "Epoch 42/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9993 - precision: 0.7874 - recall: 0.3733 - val_loss: 0.9974 - val_precision: 0.8484 - val_recall: 0.4204\n",
            "Epoch 43/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9992 - precision: 0.7880 - recall: 0.3742 - val_loss: 0.9973 - val_precision: 0.8475 - val_recall: 0.4219\n",
            "Epoch 44/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9990 - precision: 0.7885 - recall: 0.3752 - val_loss: 0.9971 - val_precision: 0.8467 - val_recall: 0.4234\n",
            "Epoch 45/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9989 - precision: 0.7890 - recall: 0.3762 - val_loss: 0.9970 - val_precision: 0.8459 - val_recall: 0.4246\n",
            "Epoch 46/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9988 - precision: 0.7896 - recall: 0.3771 - val_loss: 0.9969 - val_precision: 0.8451 - val_recall: 0.4259\n",
            "Epoch 47/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9987 - precision: 0.7900 - recall: 0.3780 - val_loss: 0.9967 - val_precision: 0.8443 - val_recall: 0.4270\n",
            "Epoch 48/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9985 - precision: 0.7906 - recall: 0.3789 - val_loss: 0.9966 - val_precision: 0.8436 - val_recall: 0.4280\n",
            "Epoch 49/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9984 - precision: 0.7909 - recall: 0.3798 - val_loss: 0.9965 - val_precision: 0.8428 - val_recall: 0.4290\n",
            "Epoch 50/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9983 - precision: 0.7915 - recall: 0.3806 - val_loss: 0.9963 - val_precision: 0.8421 - val_recall: 0.4300\n",
            "Epoch 51/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9982 - precision: 0.7919 - recall: 0.3814 - val_loss: 0.9962 - val_precision: 0.8414 - val_recall: 0.4308\n",
            "Epoch 52/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9981 - precision: 0.7923 - recall: 0.3823 - val_loss: 0.9961 - val_precision: 0.8408 - val_recall: 0.4316\n",
            "Epoch 53/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9980 - precision: 0.7928 - recall: 0.3832 - val_loss: 0.9960 - val_precision: 0.8401 - val_recall: 0.4324\n",
            "Epoch 54/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9979 - precision: 0.7932 - recall: 0.3839 - val_loss: 0.9959 - val_precision: 0.8395 - val_recall: 0.4331\n",
            "Epoch 55/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9977 - precision: 0.7936 - recall: 0.3847 - val_loss: 0.9957 - val_precision: 0.8389 - val_recall: 0.4338\n",
            "Epoch 56/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9976 - precision: 0.7940 - recall: 0.3855 - val_loss: 0.9956 - val_precision: 0.8384 - val_recall: 0.4344\n",
            "Epoch 57/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9975 - precision: 0.7945 - recall: 0.3862 - val_loss: 0.9955 - val_precision: 0.8378 - val_recall: 0.4350\n",
            "Epoch 58/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9974 - precision: 0.7948 - recall: 0.3869 - val_loss: 0.9954 - val_precision: 0.8373 - val_recall: 0.4356\n",
            "Epoch 59/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9973 - precision: 0.7952 - recall: 0.3877 - val_loss: 0.9953 - val_precision: 0.8368 - val_recall: 0.4362\n",
            "Epoch 60/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9972 - precision: 0.7957 - recall: 0.3885 - val_loss: 0.9952 - val_precision: 0.8363 - val_recall: 0.4367\n",
            "Epoch 61/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9971 - precision: 0.7960 - recall: 0.3892 - val_loss: 0.9951 - val_precision: 0.8358 - val_recall: 0.4372\n",
            "Epoch 62/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9970 - precision: 0.7965 - recall: 0.3899 - val_loss: 0.9950 - val_precision: 0.8354 - val_recall: 0.4377\n",
            "Epoch 63/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9969 - precision: 0.7969 - recall: 0.3907 - val_loss: 0.9949 - val_precision: 0.8349 - val_recall: 0.4381\n",
            "Epoch 64/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9968 - precision: 0.7971 - recall: 0.3913 - val_loss: 0.9948 - val_precision: 0.8345 - val_recall: 0.4385\n",
            "Epoch 65/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9967 - precision: 0.7976 - recall: 0.3920 - val_loss: 0.9947 - val_precision: 0.8341 - val_recall: 0.4389\n",
            "Epoch 66/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9966 - precision: 0.7979 - recall: 0.3927 - val_loss: 0.9946 - val_precision: 0.8337 - val_recall: 0.4393\n",
            "Epoch 67/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9965 - precision: 0.7982 - recall: 0.3933 - val_loss: 0.9946 - val_precision: 0.8333 - val_recall: 0.4397\n",
            "Epoch 68/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9964 - precision: 0.7986 - recall: 0.3939 - val_loss: 0.9945 - val_precision: 0.8329 - val_recall: 0.4401\n",
            "Epoch 69/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9963 - precision: 0.7989 - recall: 0.3945 - val_loss: 0.9944 - val_precision: 0.8325 - val_recall: 0.4404\n",
            "Epoch 70/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9962 - precision: 0.7994 - recall: 0.3953 - val_loss: 0.9943 - val_precision: 0.8322 - val_recall: 0.4408\n",
            "Epoch 71/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9961 - precision: 0.7996 - recall: 0.3959 - val_loss: 0.9942 - val_precision: 0.8319 - val_recall: 0.4411\n",
            "Epoch 72/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9960 - precision: 0.8000 - recall: 0.3965 - val_loss: 0.9941 - val_precision: 0.8315 - val_recall: 0.4414\n",
            "Epoch 73/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9960 - precision: 0.8002 - recall: 0.3971 - val_loss: 0.9940 - val_precision: 0.8312 - val_recall: 0.4417\n",
            "Epoch 74/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9959 - precision: 0.8006 - recall: 0.3978 - val_loss: 0.9940 - val_precision: 0.8309 - val_recall: 0.4420\n",
            "Epoch 75/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9958 - precision: 0.8010 - recall: 0.3983 - val_loss: 0.9939 - val_precision: 0.8305 - val_recall: 0.4423\n",
            "Config Space:\n",
            " {'batch_size': 6, 'learning_rate': 0.00044712998042093497, 'optimizer': 'sgd', 'sgd_momentum': 0.6244634986402445}\n",
            "Epoch 1/75\n",
            "174/174 [==============================] - 7s 27ms/step - loss: 1.0304 - precision: 0.8882 - recall: 1.2799e-04 - val_loss: 1.0327 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0271 - precision: 0.8947 - recall: 4.6072e-04 - val_loss: 1.0296 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0242 - precision: 0.8966 - recall: 0.0015 - val_loss: 1.0266 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0213 - precision: 0.8957 - recall: 0.0047 - val_loss: 1.0236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0185 - precision: 0.8909 - recall: 0.0126 - val_loss: 1.0206 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0158 - precision: 0.8835 - recall: 0.0293 - val_loss: 1.0174 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0132 - precision: 0.8729 - recall: 0.0585 - val_loss: 1.0144 - val_precision: 0.6653 - val_recall: 2.7536e-05\n",
            "Epoch 8/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0109 - precision: 0.8609 - recall: 0.1011 - val_loss: 1.0118 - val_precision: 0.8879 - val_recall: 0.0062\n",
            "Epoch 9/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0090 - precision: 0.8481 - recall: 0.1521 - val_loss: 1.0097 - val_precision: 0.9012 - val_recall: 0.0339\n",
            "Epoch 10/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0076 - precision: 0.8351 - recall: 0.2030 - val_loss: 1.0081 - val_precision: 0.8945 - val_recall: 0.0772\n",
            "Epoch 11/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0067 - precision: 0.8233 - recall: 0.2471 - val_loss: 1.0070 - val_precision: 0.8893 - val_recall: 0.1306\n",
            "Epoch 12/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0060 - precision: 0.8133 - recall: 0.2818 - val_loss: 1.0061 - val_precision: 0.8847 - val_recall: 0.1831\n",
            "Epoch 13/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0055 - precision: 0.8055 - recall: 0.3076 - val_loss: 1.0055 - val_precision: 0.8818 - val_recall: 0.2313\n",
            "Epoch 14/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0051 - precision: 0.7996 - recall: 0.3264 - val_loss: 1.0051 - val_precision: 0.8795 - val_recall: 0.2699\n",
            "Epoch 15/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0048 - precision: 0.7955 - recall: 0.3400 - val_loss: 1.0047 - val_precision: 0.8768 - val_recall: 0.2980\n",
            "Epoch 16/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0045 - precision: 0.7925 - recall: 0.3500 - val_loss: 1.0044 - val_precision: 0.8745 - val_recall: 0.3187\n",
            "Epoch 17/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0043 - precision: 0.7907 - recall: 0.3575 - val_loss: 1.0041 - val_precision: 0.8726 - val_recall: 0.3343\n",
            "Epoch 18/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0041 - precision: 0.7897 - recall: 0.3631 - val_loss: 1.0039 - val_precision: 0.8710 - val_recall: 0.3464\n",
            "Epoch 19/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0039 - precision: 0.7890 - recall: 0.3674 - val_loss: 1.0036 - val_precision: 0.8697 - val_recall: 0.3561\n",
            "Epoch 20/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0037 - precision: 0.7889 - recall: 0.3710 - val_loss: 1.0034 - val_precision: 0.8684 - val_recall: 0.3639\n",
            "Epoch 21/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0035 - precision: 0.7890 - recall: 0.3738 - val_loss: 1.0032 - val_precision: 0.8673 - val_recall: 0.3705\n",
            "Epoch 22/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0033 - precision: 0.7891 - recall: 0.3764 - val_loss: 1.0030 - val_precision: 0.8662 - val_recall: 0.3759\n",
            "Epoch 23/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0032 - precision: 0.7895 - recall: 0.3783 - val_loss: 1.0028 - val_precision: 0.8652 - val_recall: 0.3807\n",
            "Epoch 24/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0030 - precision: 0.7899 - recall: 0.3802 - val_loss: 1.0026 - val_precision: 0.8642 - val_recall: 0.3849\n",
            "Epoch 25/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0029 - precision: 0.7903 - recall: 0.3819 - val_loss: 1.0024 - val_precision: 0.8632 - val_recall: 0.3886\n",
            "Epoch 26/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0027 - precision: 0.7909 - recall: 0.3834 - val_loss: 1.0023 - val_precision: 0.8622 - val_recall: 0.3920\n",
            "Epoch 27/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0025 - precision: 0.7912 - recall: 0.3847 - val_loss: 1.0021 - val_precision: 0.8613 - val_recall: 0.3950\n",
            "Epoch 28/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0024 - precision: 0.7918 - recall: 0.3860 - val_loss: 1.0019 - val_precision: 0.8603 - val_recall: 0.3978\n",
            "Epoch 29/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0022 - precision: 0.7924 - recall: 0.3872 - val_loss: 1.0017 - val_precision: 0.8593 - val_recall: 0.4005\n",
            "Epoch 30/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0021 - precision: 0.7928 - recall: 0.3884 - val_loss: 1.0016 - val_precision: 0.8584 - val_recall: 0.4029\n",
            "Epoch 31/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0020 - precision: 0.7934 - recall: 0.3895 - val_loss: 1.0014 - val_precision: 0.8574 - val_recall: 0.4052\n",
            "Epoch 32/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0018 - precision: 0.7938 - recall: 0.3906 - val_loss: 1.0013 - val_precision: 0.8565 - val_recall: 0.4073\n",
            "Epoch 33/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0017 - precision: 0.7944 - recall: 0.3917 - val_loss: 1.0011 - val_precision: 0.8556 - val_recall: 0.4094\n",
            "Epoch 34/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0015 - precision: 0.7948 - recall: 0.3927 - val_loss: 1.0009 - val_precision: 0.8547 - val_recall: 0.4113\n",
            "Epoch 35/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0014 - precision: 0.7953 - recall: 0.3936 - val_loss: 1.0008 - val_precision: 0.8538 - val_recall: 0.4130\n",
            "Epoch 36/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0013 - precision: 0.7957 - recall: 0.3945 - val_loss: 1.0006 - val_precision: 0.8530 - val_recall: 0.4147\n",
            "Epoch 37/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0011 - precision: 0.7962 - recall: 0.3954 - val_loss: 1.0005 - val_precision: 0.8521 - val_recall: 0.4163\n",
            "Epoch 38/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0010 - precision: 0.7967 - recall: 0.3963 - val_loss: 1.0003 - val_precision: 0.8513 - val_recall: 0.4178\n",
            "Epoch 39/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0009 - precision: 0.7970 - recall: 0.3972 - val_loss: 1.0002 - val_precision: 0.8504 - val_recall: 0.4193\n",
            "Epoch 40/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0008 - precision: 0.7974 - recall: 0.3980 - val_loss: 1.0000 - val_precision: 0.8496 - val_recall: 0.4206\n",
            "Epoch 41/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0006 - precision: 0.7978 - recall: 0.3988 - val_loss: 0.9999 - val_precision: 0.8489 - val_recall: 0.4219\n",
            "Epoch 42/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0005 - precision: 0.7983 - recall: 0.3997 - val_loss: 0.9998 - val_precision: 0.8481 - val_recall: 0.4231\n",
            "Epoch 43/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0004 - precision: 0.7986 - recall: 0.4004 - val_loss: 0.9996 - val_precision: 0.8473 - val_recall: 0.4242\n",
            "Epoch 44/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0003 - precision: 0.7991 - recall: 0.4012 - val_loss: 0.9995 - val_precision: 0.8466 - val_recall: 0.4253\n",
            "Epoch 45/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0002 - precision: 0.7994 - recall: 0.4020 - val_loss: 0.9994 - val_precision: 0.8459 - val_recall: 0.4264\n",
            "Epoch 46/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 1.0000 - precision: 0.7998 - recall: 0.4027 - val_loss: 0.9992 - val_precision: 0.8452 - val_recall: 0.4274\n",
            "Epoch 47/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9999 - precision: 0.8002 - recall: 0.4034 - val_loss: 0.9991 - val_precision: 0.8445 - val_recall: 0.4283\n",
            "Epoch 48/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9998 - precision: 0.8005 - recall: 0.4041 - val_loss: 0.9990 - val_precision: 0.8438 - val_recall: 0.4292\n",
            "Epoch 49/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9997 - precision: 0.8009 - recall: 0.4048 - val_loss: 0.9989 - val_precision: 0.8431 - val_recall: 0.4301\n",
            "Epoch 50/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9996 - precision: 0.8012 - recall: 0.4054 - val_loss: 0.9988 - val_precision: 0.8425 - val_recall: 0.4309\n",
            "Epoch 51/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9995 - precision: 0.8015 - recall: 0.4061 - val_loss: 0.9986 - val_precision: 0.8419 - val_recall: 0.4317\n",
            "Epoch 52/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9993 - precision: 0.8019 - recall: 0.4068 - val_loss: 0.9985 - val_precision: 0.8413 - val_recall: 0.4325\n",
            "Epoch 53/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9992 - precision: 0.8022 - recall: 0.4075 - val_loss: 0.9984 - val_precision: 0.8407 - val_recall: 0.4332\n",
            "Epoch 54/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9991 - precision: 0.8025 - recall: 0.4081 - val_loss: 0.9983 - val_precision: 0.8401 - val_recall: 0.4339\n",
            "Epoch 55/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9990 - precision: 0.8028 - recall: 0.4086 - val_loss: 0.9982 - val_precision: 0.8396 - val_recall: 0.4345\n",
            "Epoch 56/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9989 - precision: 0.8031 - recall: 0.4093 - val_loss: 0.9981 - val_precision: 0.8390 - val_recall: 0.4352\n",
            "Epoch 57/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9988 - precision: 0.8035 - recall: 0.4098 - val_loss: 0.9980 - val_precision: 0.8385 - val_recall: 0.4358\n",
            "Epoch 58/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9987 - precision: 0.8036 - recall: 0.4104 - val_loss: 0.9979 - val_precision: 0.8380 - val_recall: 0.4363\n",
            "Epoch 59/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9986 - precision: 0.8041 - recall: 0.4110 - val_loss: 0.9978 - val_precision: 0.8375 - val_recall: 0.4369\n",
            "Epoch 60/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9985 - precision: 0.8042 - recall: 0.4115 - val_loss: 0.9977 - val_precision: 0.8370 - val_recall: 0.4375\n",
            "Epoch 61/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9984 - precision: 0.8046 - recall: 0.4121 - val_loss: 0.9976 - val_precision: 0.8365 - val_recall: 0.4380\n",
            "Epoch 62/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9983 - precision: 0.8049 - recall: 0.4126 - val_loss: 0.9975 - val_precision: 0.8361 - val_recall: 0.4385\n",
            "Epoch 63/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9982 - precision: 0.8052 - recall: 0.4130 - val_loss: 0.9974 - val_precision: 0.8356 - val_recall: 0.4390\n",
            "Epoch 64/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9981 - precision: 0.8055 - recall: 0.4137 - val_loss: 0.9973 - val_precision: 0.8352 - val_recall: 0.4395\n",
            "Epoch 65/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9980 - precision: 0.8058 - recall: 0.4141 - val_loss: 0.9972 - val_precision: 0.8348 - val_recall: 0.4399\n",
            "Epoch 66/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9979 - precision: 0.8061 - recall: 0.4146 - val_loss: 0.9971 - val_precision: 0.8344 - val_recall: 0.4404\n",
            "Epoch 67/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9978 - precision: 0.8063 - recall: 0.4151 - val_loss: 0.9970 - val_precision: 0.8340 - val_recall: 0.4408\n",
            "Epoch 68/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9977 - precision: 0.8066 - recall: 0.4156 - val_loss: 0.9969 - val_precision: 0.8336 - val_recall: 0.4412\n",
            "Epoch 69/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9976 - precision: 0.8069 - recall: 0.4161 - val_loss: 0.9968 - val_precision: 0.8333 - val_recall: 0.4416\n",
            "Epoch 70/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9975 - precision: 0.8071 - recall: 0.4166 - val_loss: 0.9967 - val_precision: 0.8329 - val_recall: 0.4420\n",
            "Epoch 71/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9974 - precision: 0.8075 - recall: 0.4169 - val_loss: 0.9966 - val_precision: 0.8326 - val_recall: 0.4424\n",
            "Epoch 72/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9973 - precision: 0.8078 - recall: 0.4174 - val_loss: 0.9965 - val_precision: 0.8323 - val_recall: 0.4427\n",
            "Epoch 73/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9972 - precision: 0.8080 - recall: 0.4178 - val_loss: 0.9964 - val_precision: 0.8319 - val_recall: 0.4431\n",
            "Epoch 74/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9971 - precision: 0.8082 - recall: 0.4182 - val_loss: 0.9963 - val_precision: 0.8316 - val_recall: 0.4434\n",
            "Epoch 75/75\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9970 - precision: 0.8085 - recall: 0.4186 - val_loss: 0.9962 - val_precision: 0.8313 - val_recall: 0.4437\n",
            "Config Space:\n",
            " {'batch_size': 30, 'learning_rate': 0.0002555337726396552, 'optimizer': 'adam', 'sgd_momentum': 0.11425434943877688}\n",
            "Epoch 1/75\n",
            "35/35 [==============================] - 6s 106ms/step - loss: 1.0321 - precision: 0.1317 - recall: 0.0038 - val_loss: 1.0179 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0112 - precision: 0.7877 - recall: 0.1882 - val_loss: 1.0059 - val_precision: 0.8976 - val_recall: 0.2772\n",
            "Epoch 3/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0008 - precision: 0.8630 - recall: 0.3792 - val_loss: 0.9953 - val_precision: 0.8922 - val_recall: 0.4282\n",
            "Epoch 4/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9937 - precision: 0.9083 - recall: 0.4021 - val_loss: 0.9907 - val_precision: 0.9114 - val_recall: 0.4194\n",
            "Epoch 5/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9861 - precision: 0.8915 - recall: 0.4332 - val_loss: 0.9817 - val_precision: 0.8971 - val_recall: 0.4454\n",
            "Epoch 6/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9756 - precision: 0.8769 - recall: 0.4973 - val_loss: 0.9726 - val_precision: 0.8511 - val_recall: 0.5493\n",
            "Epoch 7/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9654 - precision: 0.8851 - recall: 0.5448 - val_loss: 0.9643 - val_precision: 0.8499 - val_recall: 0.6002\n",
            "Epoch 8/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9597 - precision: 0.8631 - recall: 0.5911 - val_loss: 0.9590 - val_precision: 0.8615 - val_recall: 0.6124\n",
            "Epoch 9/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 0.9563 - precision: 0.8532 - recall: 0.6119 - val_loss: 0.9606 - val_precision: 0.8351 - val_recall: 0.5911\n",
            "Epoch 10/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9537 - precision: 0.8462 - recall: 0.6274 - val_loss: 0.9604 - val_precision: 0.8031 - val_recall: 0.5989\n",
            "Epoch 11/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9491 - precision: 0.8380 - recall: 0.6530 - val_loss: 0.9545 - val_precision: 0.8020 - val_recall: 0.6327\n",
            "Epoch 12/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9421 - precision: 0.8234 - recall: 0.7020 - val_loss: 0.9487 - val_precision: 0.7822 - val_recall: 0.6820\n",
            "Epoch 13/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9363 - precision: 0.8222 - recall: 0.7407 - val_loss: 0.9447 - val_precision: 0.7752 - val_recall: 0.7072\n",
            "Epoch 14/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9335 - precision: 0.8240 - recall: 0.7513 - val_loss: 0.9534 - val_precision: 0.7375 - val_recall: 0.6881\n",
            "Epoch 15/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9311 - precision: 0.8287 - recall: 0.7617 - val_loss: 0.9521 - val_precision: 0.7441 - val_recall: 0.6983\n",
            "Epoch 16/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9289 - precision: 0.8330 - recall: 0.7705 - val_loss: 0.9501 - val_precision: 0.7497 - val_recall: 0.7053\n",
            "Epoch 17/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9259 - precision: 0.8379 - recall: 0.7808 - val_loss: 0.9496 - val_precision: 0.7465 - val_recall: 0.7089\n",
            "Epoch 18/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9244 - precision: 0.8404 - recall: 0.7861 - val_loss: 0.9454 - val_precision: 0.7598 - val_recall: 0.7200\n",
            "Epoch 19/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9234 - precision: 0.8426 - recall: 0.7881 - val_loss: 0.9466 - val_precision: 0.7520 - val_recall: 0.7129\n",
            "Epoch 20/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9221 - precision: 0.8443 - recall: 0.7927 - val_loss: 0.9430 - val_precision: 0.7654 - val_recall: 0.7265\n",
            "Epoch 21/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9210 - precision: 0.8473 - recall: 0.7954 - val_loss: 0.9432 - val_precision: 0.7664 - val_recall: 0.7267\n",
            "Epoch 22/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9200 - precision: 0.8487 - recall: 0.7991 - val_loss: 0.9480 - val_precision: 0.7522 - val_recall: 0.7200\n",
            "Epoch 23/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9186 - precision: 0.8516 - recall: 0.8013 - val_loss: 0.9527 - val_precision: 0.7473 - val_recall: 0.7131\n",
            "Epoch 24/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 0.9178 - precision: 0.8540 - recall: 0.8054 - val_loss: 0.9400 - val_precision: 0.7780 - val_recall: 0.7456\n",
            "Epoch 25/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9156 - precision: 0.8584 - recall: 0.8117 - val_loss: 0.9420 - val_precision: 0.7672 - val_recall: 0.7394\n",
            "Epoch 26/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9163 - precision: 0.8559 - recall: 0.8094 - val_loss: 0.9413 - val_precision: 0.7708 - val_recall: 0.7376\n",
            "Epoch 27/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9156 - precision: 0.8584 - recall: 0.8128 - val_loss: 0.9364 - val_precision: 0.7865 - val_recall: 0.7501\n",
            "Epoch 28/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9139 - precision: 0.8606 - recall: 0.8170 - val_loss: 0.9370 - val_precision: 0.7925 - val_recall: 0.7566\n",
            "Epoch 29/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9123 - precision: 0.8644 - recall: 0.8219 - val_loss: 0.9335 - val_precision: 0.8065 - val_recall: 0.7706\n",
            "Epoch 30/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9115 - precision: 0.8658 - recall: 0.8242 - val_loss: 0.9320 - val_precision: 0.8049 - val_recall: 0.7710\n",
            "Epoch 31/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9110 - precision: 0.8673 - recall: 0.8260 - val_loss: 0.9382 - val_precision: 0.7900 - val_recall: 0.7556\n",
            "Epoch 32/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9100 - precision: 0.8694 - recall: 0.8298 - val_loss: 0.9314 - val_precision: 0.8120 - val_recall: 0.7732\n",
            "Epoch 33/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9095 - precision: 0.8706 - recall: 0.8315 - val_loss: 0.9325 - val_precision: 0.8104 - val_recall: 0.7732\n",
            "Epoch 34/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9080 - precision: 0.8742 - recall: 0.8363 - val_loss: 0.9297 - val_precision: 0.8193 - val_recall: 0.7812\n",
            "Epoch 35/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9073 - precision: 0.8753 - recall: 0.8382 - val_loss: 0.9308 - val_precision: 0.8155 - val_recall: 0.7774\n",
            "Epoch 36/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9074 - precision: 0.8751 - recall: 0.8385 - val_loss: 0.9352 - val_precision: 0.8078 - val_recall: 0.7684\n",
            "Epoch 37/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9066 - precision: 0.8775 - recall: 0.8407 - val_loss: 0.9341 - val_precision: 0.8098 - val_recall: 0.7741\n",
            "Epoch 38/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9062 - precision: 0.8777 - recall: 0.8423 - val_loss: 0.9287 - val_precision: 0.8264 - val_recall: 0.7871\n",
            "Epoch 39/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9049 - precision: 0.8815 - recall: 0.8469 - val_loss: 0.9286 - val_precision: 0.8244 - val_recall: 0.7882\n",
            "Epoch 40/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9043 - precision: 0.8826 - recall: 0.8492 - val_loss: 0.9295 - val_precision: 0.8222 - val_recall: 0.7859\n",
            "Epoch 41/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9034 - precision: 0.8848 - recall: 0.8524 - val_loss: 0.9311 - val_precision: 0.8161 - val_recall: 0.7809\n",
            "Epoch 42/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9029 - precision: 0.8859 - recall: 0.8537 - val_loss: 0.9284 - val_precision: 0.8260 - val_recall: 0.7918\n",
            "Epoch 43/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9026 - precision: 0.8864 - recall: 0.8549 - val_loss: 0.9320 - val_precision: 0.8159 - val_recall: 0.7852\n",
            "Epoch 44/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9026 - precision: 0.8864 - recall: 0.8545 - val_loss: 0.9217 - val_precision: 0.8428 - val_recall: 0.8082\n",
            "Epoch 45/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9019 - precision: 0.8882 - recall: 0.8566 - val_loss: 0.9209 - val_precision: 0.8462 - val_recall: 0.8138\n",
            "Epoch 46/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9012 - precision: 0.8899 - recall: 0.8597 - val_loss: 0.9230 - val_precision: 0.8421 - val_recall: 0.8116\n",
            "Epoch 47/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9004 - precision: 0.8918 - recall: 0.8630 - val_loss: 0.9229 - val_precision: 0.8403 - val_recall: 0.8088\n",
            "Epoch 48/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8998 - precision: 0.8929 - recall: 0.8652 - val_loss: 0.9218 - val_precision: 0.8435 - val_recall: 0.8127\n",
            "Epoch 49/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8990 - precision: 0.8951 - recall: 0.8674 - val_loss: 0.9262 - val_precision: 0.8345 - val_recall: 0.8065\n",
            "Epoch 50/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8984 - precision: 0.8963 - recall: 0.8691 - val_loss: 0.9245 - val_precision: 0.8387 - val_recall: 0.8101\n",
            "Epoch 51/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8978 - precision: 0.8983 - recall: 0.8718 - val_loss: 0.9261 - val_precision: 0.8352 - val_recall: 0.8068\n",
            "Epoch 52/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8974 - precision: 0.8991 - recall: 0.8727 - val_loss: 0.9266 - val_precision: 0.8334 - val_recall: 0.8071\n",
            "Epoch 53/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8968 - precision: 0.9002 - recall: 0.8746 - val_loss: 0.9269 - val_precision: 0.8338 - val_recall: 0.8079\n",
            "Epoch 54/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8960 - precision: 0.9022 - recall: 0.8775 - val_loss: 0.9279 - val_precision: 0.8314 - val_recall: 0.8055\n",
            "Epoch 55/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8956 - precision: 0.9027 - recall: 0.8782 - val_loss: 0.9238 - val_precision: 0.8405 - val_recall: 0.8146\n",
            "Epoch 56/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8954 - precision: 0.9040 - recall: 0.8790 - val_loss: 0.9313 - val_precision: 0.8240 - val_recall: 0.7991\n",
            "Epoch 57/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8949 - precision: 0.9043 - recall: 0.8799 - val_loss: 0.9290 - val_precision: 0.8302 - val_recall: 0.8019\n",
            "Epoch 58/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8948 - precision: 0.9046 - recall: 0.8803 - val_loss: 0.9349 - val_precision: 0.8140 - val_recall: 0.7880\n",
            "Epoch 59/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8951 - precision: 0.9037 - recall: 0.8783 - val_loss: 0.9318 - val_precision: 0.8146 - val_recall: 0.7867\n",
            "Epoch 60/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8956 - precision: 0.9021 - recall: 0.8760 - val_loss: 0.9322 - val_precision: 0.8196 - val_recall: 0.7907\n",
            "Epoch 61/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8979 - precision: 0.8971 - recall: 0.8688 - val_loss: 0.9298 - val_precision: 0.8259 - val_recall: 0.7940\n",
            "Epoch 62/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8981 - precision: 0.8968 - recall: 0.8687 - val_loss: 0.9302 - val_precision: 0.8202 - val_recall: 0.7963\n",
            "Epoch 63/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8950 - precision: 0.9033 - recall: 0.8786 - val_loss: 0.9267 - val_precision: 0.8343 - val_recall: 0.8115\n",
            "Epoch 64/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8929 - precision: 0.9080 - recall: 0.8845 - val_loss: 0.9244 - val_precision: 0.8412 - val_recall: 0.8189\n",
            "Epoch 65/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8935 - precision: 0.9066 - recall: 0.8822 - val_loss: 0.9249 - val_precision: 0.8365 - val_recall: 0.8144\n",
            "Epoch 66/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8921 - precision: 0.9096 - recall: 0.8861 - val_loss: 0.9303 - val_precision: 0.8292 - val_recall: 0.8103\n",
            "Epoch 67/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8912 - precision: 0.9115 - recall: 0.8880 - val_loss: 0.9309 - val_precision: 0.8284 - val_recall: 0.8090\n",
            "Epoch 68/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8907 - precision: 0.9117 - recall: 0.8888 - val_loss: 0.9329 - val_precision: 0.8277 - val_recall: 0.8088\n",
            "Epoch 69/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8910 - precision: 0.9110 - recall: 0.8866 - val_loss: 0.9263 - val_precision: 0.8387 - val_recall: 0.8158\n",
            "Epoch 70/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8905 - precision: 0.9108 - recall: 0.8873 - val_loss: 0.9316 - val_precision: 0.8208 - val_recall: 0.8017\n",
            "Epoch 71/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8897 - precision: 0.9078 - recall: 0.8878 - val_loss: 0.9390 - val_precision: 0.8108 - val_recall: 0.7931\n",
            "Epoch 72/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8920 - precision: 0.8965 - recall: 0.8776 - val_loss: 0.9269 - val_precision: 0.8368 - val_recall: 0.8197\n",
            "Epoch 73/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8921 - precision: 0.8961 - recall: 0.8783 - val_loss: 0.9310 - val_precision: 0.8229 - val_recall: 0.8064\n",
            "Epoch 74/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8876 - precision: 0.9008 - recall: 0.8851 - val_loss: 0.9388 - val_precision: 0.8043 - val_recall: 0.7885\n",
            "Epoch 75/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8888 - precision: 0.8965 - recall: 0.8807 - val_loss: 0.9412 - val_precision: 0.8058 - val_recall: 0.7889\n",
            "Config Space:\n",
            " {'batch_size': 24, 'learning_rate': 0.0012444573981454413, 'optimizer': 'adam', 'sgd_momentum': 0.22181057142726812}\n",
            "Epoch 1/25\n",
            "44/44 [==============================] - 6s 85ms/step - loss: 1.0021 - precision: 0.8084 - recall: 0.3658 - val_loss: 0.9914 - val_precision: 0.8605 - val_recall: 0.4457\n",
            "Epoch 2/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9806 - precision: 0.8390 - recall: 0.4945 - val_loss: 0.9656 - val_precision: 0.8268 - val_recall: 0.6082\n",
            "Epoch 3/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9596 - precision: 0.8530 - recall: 0.6173 - val_loss: 0.9680 - val_precision: 0.8486 - val_recall: 0.5662\n",
            "Epoch 4/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9545 - precision: 0.8616 - recall: 0.6241 - val_loss: 0.9512 - val_precision: 0.8623 - val_recall: 0.6411\n",
            "Epoch 5/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9480 - precision: 0.8509 - recall: 0.6559 - val_loss: 0.9464 - val_precision: 0.8209 - val_recall: 0.6893\n",
            "Epoch 6/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9405 - precision: 0.8206 - recall: 0.7165 - val_loss: 0.9373 - val_precision: 0.8019 - val_recall: 0.7399\n",
            "Epoch 7/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9355 - precision: 0.8192 - recall: 0.7435 - val_loss: 0.9433 - val_precision: 0.7691 - val_recall: 0.7295\n",
            "Epoch 8/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9294 - precision: 0.8265 - recall: 0.7672 - val_loss: 0.9309 - val_precision: 0.8120 - val_recall: 0.7696\n",
            "Epoch 9/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9263 - precision: 0.8326 - recall: 0.7782 - val_loss: 0.9315 - val_precision: 0.8082 - val_recall: 0.7677\n",
            "Epoch 10/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9273 - precision: 0.8292 - recall: 0.7733 - val_loss: 0.9305 - val_precision: 0.8179 - val_recall: 0.7716\n",
            "Epoch 11/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9250 - precision: 0.8349 - recall: 0.7802 - val_loss: 0.9347 - val_precision: 0.8016 - val_recall: 0.7578\n",
            "Epoch 12/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9207 - precision: 0.8452 - recall: 0.7950 - val_loss: 0.9299 - val_precision: 0.8134 - val_recall: 0.7752\n",
            "Epoch 13/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9187 - precision: 0.8478 - recall: 0.8025 - val_loss: 0.9260 - val_precision: 0.8221 - val_recall: 0.7850\n",
            "Epoch 14/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9158 - precision: 0.8536 - recall: 0.8110 - val_loss: 0.9237 - val_precision: 0.8286 - val_recall: 0.7921\n",
            "Epoch 15/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9146 - precision: 0.8569 - recall: 0.8149 - val_loss: 0.9241 - val_precision: 0.8265 - val_recall: 0.7910\n",
            "Epoch 16/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9136 - precision: 0.8590 - recall: 0.8180 - val_loss: 0.9228 - val_precision: 0.8302 - val_recall: 0.7978\n",
            "Epoch 17/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9129 - precision: 0.8602 - recall: 0.8203 - val_loss: 0.9229 - val_precision: 0.8321 - val_recall: 0.7975\n",
            "Epoch 18/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9121 - precision: 0.8620 - recall: 0.8219 - val_loss: 0.9205 - val_precision: 0.8397 - val_recall: 0.8069\n",
            "Epoch 19/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9108 - precision: 0.8644 - recall: 0.8256 - val_loss: 0.9200 - val_precision: 0.8401 - val_recall: 0.8071\n",
            "Epoch 20/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9096 - precision: 0.8668 - recall: 0.8296 - val_loss: 0.9197 - val_precision: 0.8418 - val_recall: 0.8083\n",
            "Epoch 21/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9104 - precision: 0.8656 - recall: 0.8273 - val_loss: 0.9227 - val_precision: 0.8387 - val_recall: 0.8078\n",
            "Epoch 22/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9103 - precision: 0.8654 - recall: 0.8274 - val_loss: 0.9214 - val_precision: 0.8371 - val_recall: 0.8040\n",
            "Epoch 23/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9093 - precision: 0.8680 - recall: 0.8303 - val_loss: 0.9220 - val_precision: 0.8359 - val_recall: 0.8046\n",
            "Epoch 24/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9078 - precision: 0.8709 - recall: 0.8349 - val_loss: 0.9220 - val_precision: 0.8388 - val_recall: 0.8048\n",
            "Epoch 25/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9066 - precision: 0.8738 - recall: 0.8383 - val_loss: 0.9241 - val_precision: 0.8336 - val_recall: 0.8034\n",
            "Config Space:\n",
            " {'batch_size': 11, 'learning_rate': 0.000921560725725206, 'optimizer': 'sgd', 'sgd_momentum': 0.28005263182984264}\n",
            "Epoch 1/25\n",
            "95/95 [==============================] - 7s 45ms/step - loss: 1.0226 - precision: 0.3105 - recall: 0.0262 - val_loss: 1.0115 - val_precision: 0.7376 - val_recall: 1.2195e-04\n",
            "Epoch 2/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0190 - precision: 0.4814 - recall: 0.0466 - val_loss: 1.0091 - val_precision: 0.8860 - val_recall: 0.0080\n",
            "Epoch 3/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0163 - precision: 0.6163 - recall: 0.0731 - val_loss: 1.0076 - val_precision: 0.9138 - val_recall: 0.0471\n",
            "Epoch 4/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0143 - precision: 0.7044 - recall: 0.1035 - val_loss: 1.0065 - val_precision: 0.9130 - val_recall: 0.1149\n",
            "Epoch 5/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0127 - precision: 0.7567 - recall: 0.1351 - val_loss: 1.0058 - val_precision: 0.9105 - val_recall: 0.2005\n",
            "Epoch 6/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0115 - precision: 0.7868 - recall: 0.1659 - val_loss: 1.0052 - val_precision: 0.9069 - val_recall: 0.2872\n",
            "Epoch 7/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0106 - precision: 0.8035 - recall: 0.1941 - val_loss: 1.0048 - val_precision: 0.8993 - val_recall: 0.3449\n",
            "Epoch 8/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0098 - precision: 0.8123 - recall: 0.2192 - val_loss: 1.0045 - val_precision: 0.8900 - val_recall: 0.3766\n",
            "Epoch 9/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0092 - precision: 0.8167 - recall: 0.2409 - val_loss: 1.0043 - val_precision: 0.8813 - val_recall: 0.3953\n",
            "Epoch 10/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0087 - precision: 0.8187 - recall: 0.2595 - val_loss: 1.0041 - val_precision: 0.8736 - val_recall: 0.4075\n",
            "Epoch 11/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0083 - precision: 0.8193 - recall: 0.2753 - val_loss: 1.0039 - val_precision: 0.8669 - val_recall: 0.4158\n",
            "Epoch 12/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0080 - precision: 0.8192 - recall: 0.2884 - val_loss: 1.0038 - val_precision: 0.8613 - val_recall: 0.4218\n",
            "Epoch 13/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0077 - precision: 0.8187 - recall: 0.2996 - val_loss: 1.0037 - val_precision: 0.8567 - val_recall: 0.4264\n",
            "Epoch 14/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0074 - precision: 0.8179 - recall: 0.3092 - val_loss: 1.0035 - val_precision: 0.8529 - val_recall: 0.4299\n",
            "Epoch 15/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0072 - precision: 0.8173 - recall: 0.3173 - val_loss: 1.0034 - val_precision: 0.8498 - val_recall: 0.4327\n",
            "Epoch 16/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0069 - precision: 0.8166 - recall: 0.3241 - val_loss: 1.0033 - val_precision: 0.8473 - val_recall: 0.4349\n",
            "Epoch 17/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0067 - precision: 0.8161 - recall: 0.3300 - val_loss: 1.0032 - val_precision: 0.8452 - val_recall: 0.4367\n",
            "Epoch 18/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0066 - precision: 0.8154 - recall: 0.3351 - val_loss: 1.0032 - val_precision: 0.8434 - val_recall: 0.4383\n",
            "Epoch 19/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0064 - precision: 0.8150 - recall: 0.3396 - val_loss: 1.0031 - val_precision: 0.8420 - val_recall: 0.4395\n",
            "Epoch 20/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0062 - precision: 0.8145 - recall: 0.3436 - val_loss: 1.0030 - val_precision: 0.8408 - val_recall: 0.4406\n",
            "Epoch 21/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 1.0061 - precision: 0.8142 - recall: 0.3471 - val_loss: 1.0029 - val_precision: 0.8397 - val_recall: 0.4414\n",
            "Epoch 22/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0059 - precision: 0.8138 - recall: 0.3501 - val_loss: 1.0028 - val_precision: 0.8389 - val_recall: 0.4422\n",
            "Epoch 23/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0058 - precision: 0.8137 - recall: 0.3530 - val_loss: 1.0028 - val_precision: 0.8381 - val_recall: 0.4428\n",
            "Epoch 24/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0057 - precision: 0.8135 - recall: 0.3555 - val_loss: 1.0027 - val_precision: 0.8375 - val_recall: 0.4434\n",
            "Epoch 25/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 1.0055 - precision: 0.8133 - recall: 0.3578 - val_loss: 1.0026 - val_precision: 0.8369 - val_recall: 0.4438\n",
            "Config Space:\n",
            " {'batch_size': 26, 'learning_rate': 0.0008617202284439472, 'optimizer': 'sgd', 'sgd_momentum': 0.9596310724837166}\n",
            "Epoch 1/25\n",
            "41/41 [==============================] - 6s 90ms/step - loss: 1.0334 - precision: 0.3050 - recall: 0.0271 - val_loss: 1.0143 - val_precision: 0.3812 - val_recall: 7.1003e-04\n",
            "Epoch 2/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0152 - precision: 0.8017 - recall: 0.2078 - val_loss: 1.0092 - val_precision: 0.8352 - val_recall: 0.4398\n",
            "Epoch 3/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0100 - precision: 0.7942 - recall: 0.3461 - val_loss: 1.0055 - val_precision: 0.8237 - val_recall: 0.4498\n",
            "Epoch 4/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0068 - precision: 0.8000 - recall: 0.3451 - val_loss: 1.0019 - val_precision: 0.8369 - val_recall: 0.4393\n",
            "Epoch 5/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0047 - precision: 0.8011 - recall: 0.3472 - val_loss: 0.9998 - val_precision: 0.8315 - val_recall: 0.4448\n",
            "Epoch 6/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0033 - precision: 0.7960 - recall: 0.3668 - val_loss: 0.9987 - val_precision: 0.8223 - val_recall: 0.4539\n",
            "Epoch 7/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0022 - precision: 0.7931 - recall: 0.3797 - val_loss: 0.9979 - val_precision: 0.8162 - val_recall: 0.4593\n",
            "Epoch 8/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0014 - precision: 0.7934 - recall: 0.3854 - val_loss: 0.9973 - val_precision: 0.8126 - val_recall: 0.4621\n",
            "Epoch 9/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0007 - precision: 0.7945 - recall: 0.3890 - val_loss: 0.9969 - val_precision: 0.8102 - val_recall: 0.4638\n",
            "Epoch 10/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0001 - precision: 0.7960 - recall: 0.3925 - val_loss: 0.9965 - val_precision: 0.8085 - val_recall: 0.4650\n",
            "Epoch 11/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9996 - precision: 0.7974 - recall: 0.3956 - val_loss: 0.9961 - val_precision: 0.8074 - val_recall: 0.4658\n",
            "Epoch 12/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9990 - precision: 0.7991 - recall: 0.3983 - val_loss: 0.9958 - val_precision: 0.8065 - val_recall: 0.4665\n",
            "Epoch 13/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9985 - precision: 0.8006 - recall: 0.4008 - val_loss: 0.9954 - val_precision: 0.8056 - val_recall: 0.4671\n",
            "Epoch 14/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9981 - precision: 0.8019 - recall: 0.4032 - val_loss: 0.9951 - val_precision: 0.8050 - val_recall: 0.4676\n",
            "Epoch 15/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9976 - precision: 0.8033 - recall: 0.4053 - val_loss: 0.9948 - val_precision: 0.8044 - val_recall: 0.4681\n",
            "Epoch 16/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9972 - precision: 0.8047 - recall: 0.4075 - val_loss: 0.9945 - val_precision: 0.8038 - val_recall: 0.4685\n",
            "Epoch 17/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9968 - precision: 0.8058 - recall: 0.4095 - val_loss: 0.9942 - val_precision: 0.8034 - val_recall: 0.4689\n",
            "Epoch 18/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9964 - precision: 0.8069 - recall: 0.4113 - val_loss: 0.9940 - val_precision: 0.8031 - val_recall: 0.4692\n",
            "Epoch 19/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9960 - precision: 0.8080 - recall: 0.4129 - val_loss: 0.9937 - val_precision: 0.8028 - val_recall: 0.4695\n",
            "Epoch 20/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9957 - precision: 0.8092 - recall: 0.4145 - val_loss: 0.9934 - val_precision: 0.8026 - val_recall: 0.4697\n",
            "Epoch 21/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9953 - precision: 0.8102 - recall: 0.4160 - val_loss: 0.9932 - val_precision: 0.8024 - val_recall: 0.4700\n",
            "Epoch 22/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9950 - precision: 0.8112 - recall: 0.4175 - val_loss: 0.9929 - val_precision: 0.8024 - val_recall: 0.4701\n",
            "Epoch 23/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9947 - precision: 0.8122 - recall: 0.4188 - val_loss: 0.9927 - val_precision: 0.8023 - val_recall: 0.4703\n",
            "Epoch 24/25\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9944 - precision: 0.8132 - recall: 0.4201 - val_loss: 0.9925 - val_precision: 0.8024 - val_recall: 0.4703\n",
            "Epoch 25/25\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9940 - precision: 0.8140 - recall: 0.4214 - val_loss: 0.9922 - val_precision: 0.8025 - val_recall: 0.4704\n",
            "Config Space:\n",
            " {'batch_size': 24, 'learning_rate': 0.0012444573981454413, 'optimizer': 'adam', 'sgd_momentum': 0.22181057142726812}\n",
            "Epoch 1/75\n",
            "44/44 [==============================] - 6s 92ms/step - loss: 1.0094 - precision: 0.8164 - recall: 0.2895 - val_loss: 0.9952 - val_precision: 0.8716 - val_recall: 0.4355\n",
            "Epoch 2/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9777 - precision: 0.8798 - recall: 0.4784 - val_loss: 0.9671 - val_precision: 0.8713 - val_recall: 0.5285\n",
            "Epoch 3/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9623 - precision: 0.8595 - recall: 0.5507 - val_loss: 0.9644 - val_precision: 0.8476 - val_recall: 0.5532\n",
            "Epoch 4/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9551 - precision: 0.8359 - recall: 0.6058 - val_loss: 0.9565 - val_precision: 0.8203 - val_recall: 0.6146\n",
            "Epoch 5/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9479 - precision: 0.8167 - recall: 0.6743 - val_loss: 0.9497 - val_precision: 0.7809 - val_recall: 0.6815\n",
            "Epoch 6/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9411 - precision: 0.8109 - recall: 0.7208 - val_loss: 0.9427 - val_precision: 0.7879 - val_recall: 0.7166\n",
            "Epoch 7/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9374 - precision: 0.8139 - recall: 0.7378 - val_loss: 0.9410 - val_precision: 0.7937 - val_recall: 0.7294\n",
            "Epoch 8/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9357 - precision: 0.8159 - recall: 0.7433 - val_loss: 0.9441 - val_precision: 0.7929 - val_recall: 0.7168\n",
            "Epoch 9/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9313 - precision: 0.8244 - recall: 0.7576 - val_loss: 0.9311 - val_precision: 0.8182 - val_recall: 0.7670\n",
            "Epoch 10/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9336 - precision: 0.8193 - recall: 0.7541 - val_loss: 0.9351 - val_precision: 0.8095 - val_recall: 0.7545\n",
            "Epoch 11/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9267 - precision: 0.8341 - recall: 0.7765 - val_loss: 0.9262 - val_precision: 0.8285 - val_recall: 0.7859\n",
            "Epoch 12/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9241 - precision: 0.8374 - recall: 0.7850 - val_loss: 0.9256 - val_precision: 0.8293 - val_recall: 0.7881\n",
            "Epoch 13/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9221 - precision: 0.8411 - recall: 0.7919 - val_loss: 0.9244 - val_precision: 0.8313 - val_recall: 0.7923\n",
            "Epoch 14/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9207 - precision: 0.8435 - recall: 0.7972 - val_loss: 0.9232 - val_precision: 0.8348 - val_recall: 0.7989\n",
            "Epoch 15/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9211 - precision: 0.8423 - recall: 0.7962 - val_loss: 0.9274 - val_precision: 0.8251 - val_recall: 0.7815\n",
            "Epoch 16/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9206 - precision: 0.8445 - recall: 0.7962 - val_loss: 0.9229 - val_precision: 0.8339 - val_recall: 0.7997\n",
            "Epoch 17/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9176 - precision: 0.8490 - recall: 0.8071 - val_loss: 0.9232 - val_precision: 0.8302 - val_recall: 0.7995\n",
            "Epoch 18/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9163 - precision: 0.8513 - recall: 0.8103 - val_loss: 0.9218 - val_precision: 0.8362 - val_recall: 0.8052\n",
            "Epoch 19/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9153 - precision: 0.8538 - recall: 0.8130 - val_loss: 0.9236 - val_precision: 0.8299 - val_recall: 0.7976\n",
            "Epoch 20/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9144 - precision: 0.8556 - recall: 0.8154 - val_loss: 0.9200 - val_precision: 0.8394 - val_recall: 0.8097\n",
            "Epoch 21/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9134 - precision: 0.8574 - recall: 0.8181 - val_loss: 0.9202 - val_precision: 0.8371 - val_recall: 0.8065\n",
            "Epoch 22/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9138 - precision: 0.8569 - recall: 0.8168 - val_loss: 0.9194 - val_precision: 0.8421 - val_recall: 0.8131\n",
            "Epoch 23/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9125 - precision: 0.8591 - recall: 0.8209 - val_loss: 0.9209 - val_precision: 0.8356 - val_recall: 0.8072\n",
            "Epoch 24/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9122 - precision: 0.8598 - recall: 0.8210 - val_loss: 0.9194 - val_precision: 0.8380 - val_recall: 0.8105\n",
            "Epoch 25/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9136 - precision: 0.8567 - recall: 0.8177 - val_loss: 0.9193 - val_precision: 0.8422 - val_recall: 0.8136\n",
            "Epoch 26/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9115 - precision: 0.8611 - recall: 0.8230 - val_loss: 0.9178 - val_precision: 0.8428 - val_recall: 0.8137\n",
            "Epoch 27/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9103 - precision: 0.8634 - recall: 0.8258 - val_loss: 0.9185 - val_precision: 0.8415 - val_recall: 0.8129\n",
            "Epoch 28/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9101 - precision: 0.8643 - recall: 0.8260 - val_loss: 0.9179 - val_precision: 0.8436 - val_recall: 0.8158\n",
            "Epoch 29/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9095 - precision: 0.8656 - recall: 0.8275 - val_loss: 0.9184 - val_precision: 0.8419 - val_recall: 0.8144\n",
            "Epoch 30/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9090 - precision: 0.8659 - recall: 0.8278 - val_loss: 0.9184 - val_precision: 0.8377 - val_recall: 0.8108\n",
            "Epoch 31/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9097 - precision: 0.8637 - recall: 0.8272 - val_loss: 0.9170 - val_precision: 0.8444 - val_recall: 0.8166\n",
            "Epoch 32/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9080 - precision: 0.8658 - recall: 0.8313 - val_loss: 0.9167 - val_precision: 0.8420 - val_recall: 0.8162\n",
            "Epoch 33/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9085 - precision: 0.8637 - recall: 0.8312 - val_loss: 0.9137 - val_precision: 0.8520 - val_recall: 0.8248\n",
            "Epoch 34/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9076 - precision: 0.8650 - recall: 0.8344 - val_loss: 0.9152 - val_precision: 0.8440 - val_recall: 0.8209\n",
            "Epoch 35/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9079 - precision: 0.8631 - recall: 0.8332 - val_loss: 0.9148 - val_precision: 0.8448 - val_recall: 0.8189\n",
            "Epoch 36/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9066 - precision: 0.8650 - recall: 0.8361 - val_loss: 0.9153 - val_precision: 0.8420 - val_recall: 0.8188\n",
            "Epoch 37/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9067 - precision: 0.8650 - recall: 0.8369 - val_loss: 0.9140 - val_precision: 0.8478 - val_recall: 0.8258\n",
            "Epoch 38/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9061 - precision: 0.8654 - recall: 0.8382 - val_loss: 0.9148 - val_precision: 0.8439 - val_recall: 0.8214\n",
            "Epoch 39/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9088 - precision: 0.8607 - recall: 0.8308 - val_loss: 0.9168 - val_precision: 0.8410 - val_recall: 0.8166\n",
            "Epoch 40/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9080 - precision: 0.8619 - recall: 0.8327 - val_loss: 0.9134 - val_precision: 0.8485 - val_recall: 0.8240\n",
            "Epoch 41/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9047 - precision: 0.8660 - recall: 0.8394 - val_loss: 0.9149 - val_precision: 0.8416 - val_recall: 0.8198\n",
            "Epoch 42/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9038 - precision: 0.8662 - recall: 0.8408 - val_loss: 0.9150 - val_precision: 0.8439 - val_recall: 0.8214\n",
            "Epoch 43/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9037 - precision: 0.8666 - recall: 0.8404 - val_loss: 0.9139 - val_precision: 0.8474 - val_recall: 0.8248\n",
            "Epoch 44/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9045 - precision: 0.8652 - recall: 0.8386 - val_loss: 0.9148 - val_precision: 0.8437 - val_recall: 0.8220\n",
            "Epoch 45/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9074 - precision: 0.8605 - recall: 0.8329 - val_loss: 0.9163 - val_precision: 0.8434 - val_recall: 0.8096\n",
            "Epoch 46/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9071 - precision: 0.8619 - recall: 0.8326 - val_loss: 0.9182 - val_precision: 0.8340 - val_recall: 0.8116\n",
            "Epoch 47/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9049 - precision: 0.8660 - recall: 0.8385 - val_loss: 0.9141 - val_precision: 0.8498 - val_recall: 0.8251\n",
            "Epoch 48/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9032 - precision: 0.8669 - recall: 0.8407 - val_loss: 0.9141 - val_precision: 0.8446 - val_recall: 0.8238\n",
            "Epoch 49/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9034 - precision: 0.8663 - recall: 0.8412 - val_loss: 0.9152 - val_precision: 0.8458 - val_recall: 0.8230\n",
            "Epoch 50/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9032 - precision: 0.8660 - recall: 0.8402 - val_loss: 0.9141 - val_precision: 0.8515 - val_recall: 0.8295\n",
            "Epoch 51/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9016 - precision: 0.8688 - recall: 0.8442 - val_loss: 0.9131 - val_precision: 0.8506 - val_recall: 0.8296\n",
            "Epoch 52/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9020 - precision: 0.8696 - recall: 0.8453 - val_loss: 0.9147 - val_precision: 0.8473 - val_recall: 0.8237\n",
            "Epoch 53/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9021 - precision: 0.8676 - recall: 0.8439 - val_loss: 0.9169 - val_precision: 0.8346 - val_recall: 0.8122\n",
            "Epoch 54/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9011 - precision: 0.8680 - recall: 0.8441 - val_loss: 0.9150 - val_precision: 0.8458 - val_recall: 0.8232\n",
            "Epoch 55/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9019 - precision: 0.8661 - recall: 0.8412 - val_loss: 0.9163 - val_precision: 0.8443 - val_recall: 0.8219\n",
            "Epoch 56/75\n",
            "44/44 [==============================] - 3s 65ms/step - loss: 0.9023 - precision: 0.8661 - recall: 0.8408 - val_loss: 0.9173 - val_precision: 0.8409 - val_recall: 0.8190\n",
            "Epoch 57/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9035 - precision: 0.8641 - recall: 0.8371 - val_loss: 0.9137 - val_precision: 0.8525 - val_recall: 0.8326\n",
            "Epoch 58/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9003 - precision: 0.8682 - recall: 0.8450 - val_loss: 0.9155 - val_precision: 0.8462 - val_recall: 0.8234\n",
            "Epoch 59/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9007 - precision: 0.8682 - recall: 0.8432 - val_loss: 0.9185 - val_precision: 0.8413 - val_recall: 0.8143\n",
            "Epoch 60/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9045 - precision: 0.8630 - recall: 0.8374 - val_loss: 0.9122 - val_precision: 0.8547 - val_recall: 0.8303\n",
            "Epoch 61/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8995 - precision: 0.8707 - recall: 0.8471 - val_loss: 0.9143 - val_precision: 0.8495 - val_recall: 0.8243\n",
            "Epoch 62/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9007 - precision: 0.8693 - recall: 0.8459 - val_loss: 0.9146 - val_precision: 0.8505 - val_recall: 0.8296\n",
            "Epoch 63/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9006 - precision: 0.8687 - recall: 0.8453 - val_loss: 0.9147 - val_precision: 0.8525 - val_recall: 0.8314\n",
            "Epoch 64/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8991 - precision: 0.8719 - recall: 0.8492 - val_loss: 0.9138 - val_precision: 0.8544 - val_recall: 0.8326\n",
            "Epoch 65/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8981 - precision: 0.8728 - recall: 0.8507 - val_loss: 0.9119 - val_precision: 0.8568 - val_recall: 0.8366\n",
            "Epoch 66/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8975 - precision: 0.8720 - recall: 0.8504 - val_loss: 0.9111 - val_precision: 0.8600 - val_recall: 0.8401\n",
            "Epoch 67/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9007 - precision: 0.8695 - recall: 0.8454 - val_loss: 0.9143 - val_precision: 0.8516 - val_recall: 0.8323\n",
            "Epoch 68/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8978 - precision: 0.8714 - recall: 0.8500 - val_loss: 0.9157 - val_precision: 0.8499 - val_recall: 0.8258\n",
            "Epoch 69/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8981 - precision: 0.8716 - recall: 0.8505 - val_loss: 0.9121 - val_precision: 0.8535 - val_recall: 0.8345\n",
            "Epoch 70/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8979 - precision: 0.8709 - recall: 0.8490 - val_loss: 0.9123 - val_precision: 0.8554 - val_recall: 0.8349\n",
            "Epoch 71/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8975 - precision: 0.8730 - recall: 0.8516 - val_loss: 0.9152 - val_precision: 0.8530 - val_recall: 0.8295\n",
            "Epoch 72/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8974 - precision: 0.8722 - recall: 0.8499 - val_loss: 0.9117 - val_precision: 0.8562 - val_recall: 0.8372\n",
            "Epoch 73/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8963 - precision: 0.8735 - recall: 0.8529 - val_loss: 0.9141 - val_precision: 0.8522 - val_recall: 0.8313\n",
            "Epoch 74/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.8951 - precision: 0.8742 - recall: 0.8529 - val_loss: 0.9107 - val_precision: 0.8567 - val_recall: 0.8366\n",
            "Epoch 75/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8981 - precision: 0.8694 - recall: 0.8485 - val_loss: 0.9126 - val_precision: 0.8549 - val_recall: 0.8328\n",
            "Config Space:\n",
            " {'batch_size': 23, 'learning_rate': 0.012702172114669764, 'optimizer': 'adam', 'sgd_momentum': 0.5591241916566293}\n",
            "Epoch 1/75\n",
            "46/46 [==============================] - 7s 90ms/step - loss: 0.9949 - precision: 0.8047 - recall: 0.4015 - val_loss: 0.9884 - val_precision: 0.8804 - val_recall: 0.4121\n",
            "Epoch 2/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9815 - precision: 0.8227 - recall: 0.4523 - val_loss: 0.9838 - val_precision: 0.8232 - val_recall: 0.4415\n",
            "Epoch 3/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9721 - precision: 0.8217 - recall: 0.5232 - val_loss: 0.9737 - val_precision: 0.8613 - val_recall: 0.4862\n",
            "Epoch 4/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9694 - precision: 0.8270 - recall: 0.5250 - val_loss: 0.9721 - val_precision: 0.8689 - val_recall: 0.4784\n",
            "Epoch 5/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9673 - precision: 0.8325 - recall: 0.5268 - val_loss: 0.9724 - val_precision: 0.7919 - val_recall: 0.5272\n",
            "Epoch 6/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9654 - precision: 0.8123 - recall: 0.5535 - val_loss: 0.9682 - val_precision: 0.7856 - val_recall: 0.5658\n",
            "Epoch 7/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9646 - precision: 0.8063 - recall: 0.5597 - val_loss: 0.9689 - val_precision: 0.7814 - val_recall: 0.5582\n",
            "Epoch 8/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9636 - precision: 0.8034 - recall: 0.5677 - val_loss: 0.9658 - val_precision: 0.7969 - val_recall: 0.5667\n",
            "Epoch 9/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9638 - precision: 0.8025 - recall: 0.5634 - val_loss: 0.9681 - val_precision: 0.7825 - val_recall: 0.5563\n",
            "Epoch 10/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9641 - precision: 0.7979 - recall: 0.5662 - val_loss: 0.9664 - val_precision: 0.8003 - val_recall: 0.5472\n",
            "Epoch 11/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9636 - precision: 0.8034 - recall: 0.5621 - val_loss: 0.9665 - val_precision: 0.7809 - val_recall: 0.5650\n",
            "Epoch 12/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9625 - precision: 0.8050 - recall: 0.5671 - val_loss: 0.9661 - val_precision: 0.7802 - val_recall: 0.5609\n",
            "Epoch 13/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9618 - precision: 0.8092 - recall: 0.5659 - val_loss: 0.9645 - val_precision: 0.7796 - val_recall: 0.5708\n",
            "Epoch 14/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9613 - precision: 0.8114 - recall: 0.5658 - val_loss: 0.9645 - val_precision: 0.7783 - val_recall: 0.5688\n",
            "Epoch 15/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9610 - precision: 0.8119 - recall: 0.5656 - val_loss: 0.9644 - val_precision: 0.7801 - val_recall: 0.5631\n",
            "Epoch 16/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9605 - precision: 0.8160 - recall: 0.5654 - val_loss: 0.9617 - val_precision: 0.8075 - val_recall: 0.5632\n",
            "Epoch 17/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9601 - precision: 0.8187 - recall: 0.5621 - val_loss: 0.9647 - val_precision: 0.7817 - val_recall: 0.5549\n",
            "Epoch 18/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9608 - precision: 0.8124 - recall: 0.5639 - val_loss: 0.9637 - val_precision: 0.7801 - val_recall: 0.5666\n",
            "Epoch 19/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9601 - precision: 0.8076 - recall: 0.5698 - val_loss: 0.9625 - val_precision: 0.7914 - val_recall: 0.5660\n",
            "Epoch 20/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9599 - precision: 0.8098 - recall: 0.5696 - val_loss: 0.9610 - val_precision: 0.8146 - val_recall: 0.5588\n",
            "Epoch 21/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9592 - precision: 0.8095 - recall: 0.5697 - val_loss: 0.9604 - val_precision: 0.8248 - val_recall: 0.5477\n",
            "Epoch 22/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9591 - precision: 0.8061 - recall: 0.5716 - val_loss: 0.9604 - val_precision: 0.8199 - val_recall: 0.5559\n",
            "Epoch 23/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9587 - precision: 0.8018 - recall: 0.5767 - val_loss: 0.9603 - val_precision: 0.8207 - val_recall: 0.5535\n",
            "Epoch 24/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9590 - precision: 0.7962 - recall: 0.5789 - val_loss: 0.9606 - val_precision: 0.8149 - val_recall: 0.5626\n",
            "Epoch 25/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9584 - precision: 0.7950 - recall: 0.5849 - val_loss: 0.9596 - val_precision: 0.8246 - val_recall: 0.5534\n",
            "Epoch 26/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9582 - precision: 0.7929 - recall: 0.5858 - val_loss: 0.9595 - val_precision: 0.8082 - val_recall: 0.5717\n",
            "Epoch 27/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9581 - precision: 0.7903 - recall: 0.5881 - val_loss: 0.9595 - val_precision: 0.7935 - val_recall: 0.5836\n",
            "Epoch 28/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9582 - precision: 0.7872 - recall: 0.5899 - val_loss: 0.9591 - val_precision: 0.7895 - val_recall: 0.5913\n",
            "Epoch 29/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9580 - precision: 0.7863 - recall: 0.5920 - val_loss: 0.9594 - val_precision: 0.7812 - val_recall: 0.5964\n",
            "Epoch 30/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9580 - precision: 0.7843 - recall: 0.5936 - val_loss: 0.9586 - val_precision: 0.7791 - val_recall: 0.6009\n",
            "Epoch 31/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9577 - precision: 0.7835 - recall: 0.5955 - val_loss: 0.9596 - val_precision: 0.7766 - val_recall: 0.6010\n",
            "Epoch 32/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9576 - precision: 0.7819 - recall: 0.5980 - val_loss: 0.9602 - val_precision: 0.7721 - val_recall: 0.5997\n",
            "Epoch 33/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9576 - precision: 0.7817 - recall: 0.5981 - val_loss: 0.9594 - val_precision: 0.7728 - val_recall: 0.6013\n",
            "Epoch 34/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9576 - precision: 0.7813 - recall: 0.5991 - val_loss: 0.9582 - val_precision: 0.7733 - val_recall: 0.6026\n",
            "Epoch 35/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9574 - precision: 0.7777 - recall: 0.6009 - val_loss: 0.9602 - val_precision: 0.7689 - val_recall: 0.5991\n",
            "Epoch 36/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9569 - precision: 0.7767 - recall: 0.6059 - val_loss: 0.9599 - val_precision: 0.7714 - val_recall: 0.5960\n",
            "Epoch 37/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9572 - precision: 0.7766 - recall: 0.6051 - val_loss: 0.9590 - val_precision: 0.7692 - val_recall: 0.5964\n",
            "Epoch 38/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9574 - precision: 0.7734 - recall: 0.6048 - val_loss: 0.9608 - val_precision: 0.7650 - val_recall: 0.5980\n",
            "Epoch 39/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9569 - precision: 0.7699 - recall: 0.6096 - val_loss: 0.9597 - val_precision: 0.7659 - val_recall: 0.6001\n",
            "Epoch 40/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9570 - precision: 0.7675 - recall: 0.6112 - val_loss: 0.9604 - val_precision: 0.7673 - val_recall: 0.5908\n",
            "Epoch 41/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9568 - precision: 0.7661 - recall: 0.6127 - val_loss: 0.9604 - val_precision: 0.7661 - val_recall: 0.5927\n",
            "Epoch 42/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9566 - precision: 0.7648 - recall: 0.6155 - val_loss: 0.9600 - val_precision: 0.7678 - val_recall: 0.5909\n",
            "Epoch 43/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9565 - precision: 0.7629 - recall: 0.6180 - val_loss: 0.9597 - val_precision: 0.7696 - val_recall: 0.5970\n",
            "Epoch 44/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9565 - precision: 0.7612 - recall: 0.6190 - val_loss: 0.9605 - val_precision: 0.7628 - val_recall: 0.5955\n",
            "Epoch 45/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9556 - precision: 0.7549 - recall: 0.6278 - val_loss: 0.9578 - val_precision: 0.7517 - val_recall: 0.5914\n",
            "Epoch 46/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9547 - precision: 0.7550 - recall: 0.6321 - val_loss: 0.9562 - val_precision: 0.7543 - val_recall: 0.6032\n",
            "Epoch 47/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9536 - precision: 0.7561 - recall: 0.6414 - val_loss: 0.9548 - val_precision: 0.7545 - val_recall: 0.6225\n",
            "Epoch 48/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9528 - precision: 0.7554 - recall: 0.6492 - val_loss: 0.9549 - val_precision: 0.7408 - val_recall: 0.6170\n",
            "Epoch 49/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9521 - precision: 0.7506 - recall: 0.6580 - val_loss: 0.9527 - val_precision: 0.7467 - val_recall: 0.6412\n",
            "Epoch 50/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9512 - precision: 0.7507 - recall: 0.6661 - val_loss: 0.9511 - val_precision: 0.7537 - val_recall: 0.6600\n",
            "Epoch 51/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9500 - precision: 0.7551 - recall: 0.6760 - val_loss: 0.9500 - val_precision: 0.7623 - val_recall: 0.6680\n",
            "Epoch 52/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9487 - precision: 0.7632 - recall: 0.6855 - val_loss: 0.9502 - val_precision: 0.7668 - val_recall: 0.6683\n",
            "Epoch 53/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9479 - precision: 0.7665 - recall: 0.6911 - val_loss: 0.9498 - val_precision: 0.7680 - val_recall: 0.6728\n",
            "Epoch 54/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9473 - precision: 0.7675 - recall: 0.6953 - val_loss: 0.9493 - val_precision: 0.7681 - val_recall: 0.6800\n",
            "Epoch 55/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9471 - precision: 0.7677 - recall: 0.6962 - val_loss: 0.9492 - val_precision: 0.7673 - val_recall: 0.6882\n",
            "Epoch 56/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9461 - precision: 0.7705 - recall: 0.6992 - val_loss: 0.9490 - val_precision: 0.7692 - val_recall: 0.6888\n",
            "Epoch 57/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9455 - precision: 0.7741 - recall: 0.7007 - val_loss: 0.9483 - val_precision: 0.7727 - val_recall: 0.6916\n",
            "Epoch 58/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9450 - precision: 0.7765 - recall: 0.7028 - val_loss: 0.9484 - val_precision: 0.7739 - val_recall: 0.6931\n",
            "Epoch 59/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9446 - precision: 0.7786 - recall: 0.7052 - val_loss: 0.9483 - val_precision: 0.7719 - val_recall: 0.6933\n",
            "Epoch 60/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9441 - precision: 0.7803 - recall: 0.7087 - val_loss: 0.9476 - val_precision: 0.7711 - val_recall: 0.6935\n",
            "Epoch 61/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9437 - precision: 0.7811 - recall: 0.7110 - val_loss: 0.9474 - val_precision: 0.7703 - val_recall: 0.6934\n",
            "Epoch 62/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9434 - precision: 0.7817 - recall: 0.7125 - val_loss: 0.9468 - val_precision: 0.7711 - val_recall: 0.6967\n",
            "Epoch 63/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9431 - precision: 0.7822 - recall: 0.7136 - val_loss: 0.9465 - val_precision: 0.7712 - val_recall: 0.6972\n",
            "Epoch 64/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9428 - precision: 0.7823 - recall: 0.7145 - val_loss: 0.9462 - val_precision: 0.7715 - val_recall: 0.6988\n",
            "Epoch 65/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9426 - precision: 0.7829 - recall: 0.7156 - val_loss: 0.9460 - val_precision: 0.7717 - val_recall: 0.6988\n",
            "Epoch 66/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9424 - precision: 0.7830 - recall: 0.7160 - val_loss: 0.9457 - val_precision: 0.7723 - val_recall: 0.6999\n",
            "Epoch 67/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9426 - precision: 0.7827 - recall: 0.7158 - val_loss: 0.9451 - val_precision: 0.7751 - val_recall: 0.6997\n",
            "Epoch 68/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9425 - precision: 0.7829 - recall: 0.7160 - val_loss: 0.9458 - val_precision: 0.7725 - val_recall: 0.7010\n",
            "Epoch 69/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9421 - precision: 0.7838 - recall: 0.7177 - val_loss: 0.9450 - val_precision: 0.7741 - val_recall: 0.7051\n",
            "Epoch 70/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9419 - precision: 0.7842 - recall: 0.7179 - val_loss: 0.9450 - val_precision: 0.7740 - val_recall: 0.7056\n",
            "Epoch 71/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9417 - precision: 0.7846 - recall: 0.7183 - val_loss: 0.9448 - val_precision: 0.7745 - val_recall: 0.7062\n",
            "Epoch 72/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9417 - precision: 0.7846 - recall: 0.7189 - val_loss: 0.9448 - val_precision: 0.7736 - val_recall: 0.7060\n",
            "Epoch 73/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9414 - precision: 0.7853 - recall: 0.7198 - val_loss: 0.9443 - val_precision: 0.7763 - val_recall: 0.7091\n",
            "Epoch 74/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9413 - precision: 0.7854 - recall: 0.7200 - val_loss: 0.9445 - val_precision: 0.7749 - val_recall: 0.7081\n",
            "Epoch 75/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9411 - precision: 0.7867 - recall: 0.7204 - val_loss: 0.9445 - val_precision: 0.7746 - val_recall: 0.7079\n",
            "Config Space:\n",
            " {'batch_size': 9, 'learning_rate': 0.05169249868326114, 'optimizer': 'sgd', 'sgd_momentum': 0.36091461749398956}\n",
            "Epoch 1/75\n",
            "116/116 [==============================] - 6s 37ms/step - loss: 1.0122 - precision: 0.8300 - recall: 0.2472 - val_loss: 1.0003 - val_precision: 0.8421 - val_recall: 0.4462\n",
            "Epoch 2/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9986 - precision: 0.8246 - recall: 0.3893 - val_loss: 0.9938 - val_precision: 0.8269 - val_recall: 0.4575\n",
            "Epoch 3/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9928 - precision: 0.8294 - recall: 0.4100 - val_loss: 0.9890 - val_precision: 0.8262 - val_recall: 0.4590\n",
            "Epoch 4/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9876 - precision: 0.8321 - recall: 0.4213 - val_loss: 0.9849 - val_precision: 0.8230 - val_recall: 0.4623\n",
            "Epoch 5/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9827 - precision: 0.8333 - recall: 0.4403 - val_loss: 0.9811 - val_precision: 0.8255 - val_recall: 0.5322\n",
            "Epoch 6/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9779 - precision: 0.8409 - recall: 0.5093 - val_loss: 0.9782 - val_precision: 0.8076 - val_recall: 0.5547\n",
            "Epoch 7/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9733 - precision: 0.8445 - recall: 0.5352 - val_loss: 0.9766 - val_precision: 0.7987 - val_recall: 0.5637\n",
            "Epoch 8/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9691 - precision: 0.8475 - recall: 0.5548 - val_loss: 0.9756 - val_precision: 0.7963 - val_recall: 0.5679\n",
            "Epoch 9/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9655 - precision: 0.8467 - recall: 0.5746 - val_loss: 0.9749 - val_precision: 0.8005 - val_recall: 0.5676\n",
            "Epoch 10/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9625 - precision: 0.8446 - recall: 0.5901 - val_loss: 0.9750 - val_precision: 0.8053 - val_recall: 0.5652\n",
            "Epoch 11/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9601 - precision: 0.8410 - recall: 0.6035 - val_loss: 0.9757 - val_precision: 0.7934 - val_recall: 0.5680\n",
            "Epoch 12/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9580 - precision: 0.8347 - recall: 0.6192 - val_loss: 0.9767 - val_precision: 0.7547 - val_recall: 0.5982\n",
            "Epoch 13/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9563 - precision: 0.8286 - recall: 0.6332 - val_loss: 0.9776 - val_precision: 0.7366 - val_recall: 0.6141\n",
            "Epoch 14/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9550 - precision: 0.8249 - recall: 0.6436 - val_loss: 0.9783 - val_precision: 0.7290 - val_recall: 0.6188\n",
            "Epoch 15/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9541 - precision: 0.8226 - recall: 0.6504 - val_loss: 0.9787 - val_precision: 0.7256 - val_recall: 0.6210\n",
            "Epoch 16/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9532 - precision: 0.8217 - recall: 0.6554 - val_loss: 0.9788 - val_precision: 0.7244 - val_recall: 0.6230\n",
            "Epoch 17/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9525 - precision: 0.8213 - recall: 0.6591 - val_loss: 0.9788 - val_precision: 0.7243 - val_recall: 0.6243\n",
            "Epoch 18/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9519 - precision: 0.8213 - recall: 0.6620 - val_loss: 0.9784 - val_precision: 0.7253 - val_recall: 0.6258\n",
            "Epoch 19/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9514 - precision: 0.8212 - recall: 0.6644 - val_loss: 0.9779 - val_precision: 0.7267 - val_recall: 0.6271\n",
            "Epoch 20/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9510 - precision: 0.8214 - recall: 0.6665 - val_loss: 0.9777 - val_precision: 0.7275 - val_recall: 0.6284\n",
            "Epoch 21/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9506 - precision: 0.8216 - recall: 0.6683 - val_loss: 0.9767 - val_precision: 0.7301 - val_recall: 0.6302\n",
            "Epoch 22/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9502 - precision: 0.8218 - recall: 0.6700 - val_loss: 0.9765 - val_precision: 0.7308 - val_recall: 0.6314\n",
            "Epoch 23/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9498 - precision: 0.8222 - recall: 0.6717 - val_loss: 0.9761 - val_precision: 0.7320 - val_recall: 0.6326\n",
            "Epoch 24/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9495 - precision: 0.8223 - recall: 0.6730 - val_loss: 0.9756 - val_precision: 0.7332 - val_recall: 0.6339\n",
            "Epoch 25/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9492 - precision: 0.8226 - recall: 0.6744 - val_loss: 0.9750 - val_precision: 0.7347 - val_recall: 0.6356\n",
            "Epoch 26/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9489 - precision: 0.8229 - recall: 0.6753 - val_loss: 0.9748 - val_precision: 0.7353 - val_recall: 0.6366\n",
            "Epoch 27/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9486 - precision: 0.8234 - recall: 0.6765 - val_loss: 0.9740 - val_precision: 0.7372 - val_recall: 0.6385\n",
            "Epoch 28/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9483 - precision: 0.8237 - recall: 0.6775 - val_loss: 0.9740 - val_precision: 0.7371 - val_recall: 0.6395\n",
            "Epoch 29/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9481 - precision: 0.8239 - recall: 0.6784 - val_loss: 0.9732 - val_precision: 0.7391 - val_recall: 0.6412\n",
            "Epoch 30/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9478 - precision: 0.8245 - recall: 0.6795 - val_loss: 0.9729 - val_precision: 0.7397 - val_recall: 0.6425\n",
            "Epoch 31/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9476 - precision: 0.8246 - recall: 0.6802 - val_loss: 0.9730 - val_precision: 0.7395 - val_recall: 0.6433\n",
            "Epoch 32/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9474 - precision: 0.8251 - recall: 0.6813 - val_loss: 0.9724 - val_precision: 0.7408 - val_recall: 0.6450\n",
            "Epoch 33/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9471 - precision: 0.8254 - recall: 0.6820 - val_loss: 0.9719 - val_precision: 0.7418 - val_recall: 0.6466\n",
            "Epoch 34/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9468 - precision: 0.8257 - recall: 0.6832 - val_loss: 0.9712 - val_precision: 0.7432 - val_recall: 0.6484\n",
            "Epoch 35/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9465 - precision: 0.8257 - recall: 0.6847 - val_loss: 0.9714 - val_precision: 0.7426 - val_recall: 0.6491\n",
            "Epoch 36/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9464 - precision: 0.8258 - recall: 0.6857 - val_loss: 0.9707 - val_precision: 0.7438 - val_recall: 0.6509\n",
            "Epoch 37/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9460 - precision: 0.8256 - recall: 0.6878 - val_loss: 0.9705 - val_precision: 0.7441 - val_recall: 0.6522\n",
            "Epoch 38/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9457 - precision: 0.8254 - recall: 0.6900 - val_loss: 0.9696 - val_precision: 0.7457 - val_recall: 0.6545\n",
            "Epoch 39/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9454 - precision: 0.8248 - recall: 0.6927 - val_loss: 0.9695 - val_precision: 0.7455 - val_recall: 0.6562\n",
            "Epoch 40/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9451 - precision: 0.8239 - recall: 0.6959 - val_loss: 0.9689 - val_precision: 0.7461 - val_recall: 0.6588\n",
            "Epoch 41/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9447 - precision: 0.8229 - recall: 0.6999 - val_loss: 0.9683 - val_precision: 0.7470 - val_recall: 0.6619\n",
            "Epoch 42/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9443 - precision: 0.8214 - recall: 0.7038 - val_loss: 0.9675 - val_precision: 0.7480 - val_recall: 0.6656\n",
            "Epoch 43/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9439 - precision: 0.8198 - recall: 0.7078 - val_loss: 0.9669 - val_precision: 0.7484 - val_recall: 0.6692\n",
            "Epoch 44/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9435 - precision: 0.8179 - recall: 0.7120 - val_loss: 0.9658 - val_precision: 0.7502 - val_recall: 0.6738\n",
            "Epoch 45/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9430 - precision: 0.8160 - recall: 0.7156 - val_loss: 0.9646 - val_precision: 0.7518 - val_recall: 0.6786\n",
            "Epoch 46/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9425 - precision: 0.8146 - recall: 0.7194 - val_loss: 0.9641 - val_precision: 0.7521 - val_recall: 0.6820\n",
            "Epoch 47/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9420 - precision: 0.8131 - recall: 0.7227 - val_loss: 0.9634 - val_precision: 0.7526 - val_recall: 0.6857\n",
            "Epoch 48/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9416 - precision: 0.8122 - recall: 0.7257 - val_loss: 0.9623 - val_precision: 0.7542 - val_recall: 0.6895\n",
            "Epoch 49/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9411 - precision: 0.8117 - recall: 0.7283 - val_loss: 0.9614 - val_precision: 0.7552 - val_recall: 0.6927\n",
            "Epoch 50/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9406 - precision: 0.8112 - recall: 0.7309 - val_loss: 0.9608 - val_precision: 0.7552 - val_recall: 0.6947\n",
            "Epoch 51/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9402 - precision: 0.8111 - recall: 0.7328 - val_loss: 0.9600 - val_precision: 0.7560 - val_recall: 0.6971\n",
            "Epoch 52/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9397 - precision: 0.8112 - recall: 0.7352 - val_loss: 0.9589 - val_precision: 0.7573 - val_recall: 0.6996\n",
            "Epoch 53/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9392 - precision: 0.8115 - recall: 0.7371 - val_loss: 0.9583 - val_precision: 0.7579 - val_recall: 0.7014\n",
            "Epoch 54/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9388 - precision: 0.8117 - recall: 0.7389 - val_loss: 0.9575 - val_precision: 0.7586 - val_recall: 0.7030\n",
            "Epoch 55/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9384 - precision: 0.8121 - recall: 0.7407 - val_loss: 0.9567 - val_precision: 0.7598 - val_recall: 0.7053\n",
            "Epoch 56/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9380 - precision: 0.8125 - recall: 0.7426 - val_loss: 0.9565 - val_precision: 0.7595 - val_recall: 0.7062\n",
            "Epoch 57/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9376 - precision: 0.8128 - recall: 0.7441 - val_loss: 0.9553 - val_precision: 0.7617 - val_recall: 0.7090\n",
            "Epoch 58/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9372 - precision: 0.8133 - recall: 0.7458 - val_loss: 0.9546 - val_precision: 0.7630 - val_recall: 0.7115\n",
            "Epoch 59/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9369 - precision: 0.8137 - recall: 0.7472 - val_loss: 0.9539 - val_precision: 0.7643 - val_recall: 0.7134\n",
            "Epoch 60/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9365 - precision: 0.8140 - recall: 0.7485 - val_loss: 0.9532 - val_precision: 0.7655 - val_recall: 0.7155\n",
            "Epoch 61/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9361 - precision: 0.8144 - recall: 0.7498 - val_loss: 0.9531 - val_precision: 0.7655 - val_recall: 0.7165\n",
            "Epoch 62/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9358 - precision: 0.8147 - recall: 0.7510 - val_loss: 0.9527 - val_precision: 0.7657 - val_recall: 0.7172\n",
            "Epoch 63/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9355 - precision: 0.8151 - recall: 0.7521 - val_loss: 0.9518 - val_precision: 0.7683 - val_recall: 0.7207\n",
            "Epoch 64/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9352 - precision: 0.8153 - recall: 0.7531 - val_loss: 0.9514 - val_precision: 0.7689 - val_recall: 0.7218\n",
            "Epoch 65/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9349 - precision: 0.8161 - recall: 0.7546 - val_loss: 0.9515 - val_precision: 0.7686 - val_recall: 0.7223\n",
            "Epoch 66/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9346 - precision: 0.8163 - recall: 0.7555 - val_loss: 0.9507 - val_precision: 0.7701 - val_recall: 0.7242\n",
            "Epoch 67/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9343 - precision: 0.8167 - recall: 0.7564 - val_loss: 0.9501 - val_precision: 0.7715 - val_recall: 0.7261\n",
            "Epoch 68/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9341 - precision: 0.8169 - recall: 0.7571 - val_loss: 0.9493 - val_precision: 0.7730 - val_recall: 0.7279\n",
            "Epoch 69/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9338 - precision: 0.8174 - recall: 0.7581 - val_loss: 0.9494 - val_precision: 0.7729 - val_recall: 0.7285\n",
            "Epoch 70/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9336 - precision: 0.8177 - recall: 0.7590 - val_loss: 0.9488 - val_precision: 0.7741 - val_recall: 0.7298\n",
            "Epoch 71/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9333 - precision: 0.8182 - recall: 0.7600 - val_loss: 0.9487 - val_precision: 0.7743 - val_recall: 0.7306\n",
            "Epoch 72/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9331 - precision: 0.8185 - recall: 0.7606 - val_loss: 0.9482 - val_precision: 0.7754 - val_recall: 0.7319\n",
            "Epoch 73/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9328 - precision: 0.8190 - recall: 0.7617 - val_loss: 0.9476 - val_precision: 0.7772 - val_recall: 0.7341\n",
            "Epoch 74/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9326 - precision: 0.8194 - recall: 0.7626 - val_loss: 0.9473 - val_precision: 0.7777 - val_recall: 0.7350\n",
            "Epoch 75/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9324 - precision: 0.8198 - recall: 0.7634 - val_loss: 0.9470 - val_precision: 0.7787 - val_recall: 0.7364\n",
            "Config Space:\n",
            " {'batch_size': 11, 'learning_rate': 0.00393196591281057, 'optimizer': 'adam', 'sgd_momentum': 0.392466295122575}\n",
            "Epoch 1/25\n",
            "95/95 [==============================] - 6s 43ms/step - loss: 0.9919 - precision: 0.8230 - recall: 0.4241 - val_loss: 0.9673 - val_precision: 0.8652 - val_recall: 0.5637\n",
            "Epoch 2/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9613 - precision: 0.8277 - recall: 0.5940 - val_loss: 0.9545 - val_precision: 0.7987 - val_recall: 0.6749\n",
            "Epoch 3/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9533 - precision: 0.8001 - recall: 0.6606 - val_loss: 0.9482 - val_precision: 0.7995 - val_recall: 0.7038\n",
            "Epoch 4/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9466 - precision: 0.8028 - recall: 0.7043 - val_loss: 0.9463 - val_precision: 0.7880 - val_recall: 0.7166\n",
            "Epoch 5/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9417 - precision: 0.8069 - recall: 0.7297 - val_loss: 0.9391 - val_precision: 0.8126 - val_recall: 0.7262\n",
            "Epoch 6/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9390 - precision: 0.8144 - recall: 0.7370 - val_loss: 0.9362 - val_precision: 0.8088 - val_recall: 0.7327\n",
            "Epoch 7/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9343 - precision: 0.8207 - recall: 0.7574 - val_loss: 0.9368 - val_precision: 0.8047 - val_recall: 0.7265\n",
            "Epoch 8/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9310 - precision: 0.8259 - recall: 0.7718 - val_loss: 0.9360 - val_precision: 0.8008 - val_recall: 0.7392\n",
            "Epoch 9/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9277 - precision: 0.8320 - recall: 0.7833 - val_loss: 0.9339 - val_precision: 0.7996 - val_recall: 0.7521\n",
            "Epoch 10/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9263 - precision: 0.8345 - recall: 0.7891 - val_loss: 0.9318 - val_precision: 0.8070 - val_recall: 0.7632\n",
            "Epoch 11/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9244 - precision: 0.8383 - recall: 0.7951 - val_loss: 0.9246 - val_precision: 0.8272 - val_recall: 0.7885\n",
            "Epoch 12/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9227 - precision: 0.8416 - recall: 0.8005 - val_loss: 0.9233 - val_precision: 0.8294 - val_recall: 0.7944\n",
            "Epoch 13/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9214 - precision: 0.8449 - recall: 0.8033 - val_loss: 0.9212 - val_precision: 0.8328 - val_recall: 0.8007\n",
            "Epoch 14/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9213 - precision: 0.8462 - recall: 0.8031 - val_loss: 0.9216 - val_precision: 0.8328 - val_recall: 0.8013\n",
            "Epoch 15/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9200 - precision: 0.8491 - recall: 0.8072 - val_loss: 0.9200 - val_precision: 0.8364 - val_recall: 0.8070\n",
            "Epoch 16/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9185 - precision: 0.8519 - recall: 0.8111 - val_loss: 0.9200 - val_precision: 0.8353 - val_recall: 0.8041\n",
            "Epoch 17/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9188 - precision: 0.8510 - recall: 0.8096 - val_loss: 0.9200 - val_precision: 0.8354 - val_recall: 0.8031\n",
            "Epoch 18/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9184 - precision: 0.8516 - recall: 0.8110 - val_loss: 0.9195 - val_precision: 0.8360 - val_recall: 0.8024\n",
            "Epoch 19/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9167 - precision: 0.8555 - recall: 0.8154 - val_loss: 0.9195 - val_precision: 0.8357 - val_recall: 0.8047\n",
            "Epoch 20/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9166 - precision: 0.8556 - recall: 0.8162 - val_loss: 0.9201 - val_precision: 0.8350 - val_recall: 0.8050\n",
            "Epoch 21/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9165 - precision: 0.8558 - recall: 0.8156 - val_loss: 0.9205 - val_precision: 0.8341 - val_recall: 0.8018\n",
            "Epoch 22/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9158 - precision: 0.8565 - recall: 0.8183 - val_loss: 0.9184 - val_precision: 0.8384 - val_recall: 0.8086\n",
            "Epoch 23/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9152 - precision: 0.8576 - recall: 0.8194 - val_loss: 0.9196 - val_precision: 0.8348 - val_recall: 0.8059\n",
            "Epoch 24/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9146 - precision: 0.8582 - recall: 0.8201 - val_loss: 0.9186 - val_precision: 0.8358 - val_recall: 0.8049\n",
            "Epoch 25/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9144 - precision: 0.8568 - recall: 0.8208 - val_loss: 0.9203 - val_precision: 0.8297 - val_recall: 0.7990\n",
            "Config Space:\n",
            " {'batch_size': 7, 'learning_rate': 0.005020592553323891, 'optimizer': 'adam', 'sgd_momentum': 0.4285698435087847}\n",
            "Epoch 1/25\n",
            "150/150 [==============================] - 8s 31ms/step - loss: 0.9761 - precision: 0.7994 - recall: 0.5376 - val_loss: 0.9641 - val_precision: 0.7829 - val_recall: 0.6312\n",
            "Epoch 2/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9557 - precision: 0.8077 - recall: 0.6545 - val_loss: 0.9522 - val_precision: 0.8105 - val_recall: 0.6952\n",
            "Epoch 3/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9475 - precision: 0.8098 - recall: 0.7115 - val_loss: 0.9518 - val_precision: 0.7831 - val_recall: 0.7145\n",
            "Epoch 4/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9424 - precision: 0.8081 - recall: 0.7349 - val_loss: 0.9582 - val_precision: 0.7628 - val_recall: 0.7019\n",
            "Epoch 5/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9392 - precision: 0.8128 - recall: 0.7481 - val_loss: 0.9576 - val_precision: 0.7637 - val_recall: 0.7058\n",
            "Epoch 6/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9378 - precision: 0.8158 - recall: 0.7553 - val_loss: 0.9497 - val_precision: 0.7833 - val_recall: 0.7240\n",
            "Epoch 7/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9368 - precision: 0.8169 - recall: 0.7582 - val_loss: 0.9434 - val_precision: 0.7974 - val_recall: 0.7411\n",
            "Epoch 8/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9348 - precision: 0.8208 - recall: 0.7655 - val_loss: 0.9398 - val_precision: 0.8050 - val_recall: 0.7536\n",
            "Epoch 9/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9340 - precision: 0.8226 - recall: 0.7681 - val_loss: 0.9386 - val_precision: 0.8101 - val_recall: 0.7580\n",
            "Epoch 10/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9328 - precision: 0.8254 - recall: 0.7728 - val_loss: 0.9389 - val_precision: 0.8059 - val_recall: 0.7556\n",
            "Epoch 11/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9322 - precision: 0.8269 - recall: 0.7739 - val_loss: 0.9379 - val_precision: 0.8111 - val_recall: 0.7640\n",
            "Epoch 12/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9473 - precision: 0.8045 - recall: 0.7121 - val_loss: 0.9537 - val_precision: 0.7774 - val_recall: 0.6984\n",
            "Epoch 13/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9489 - precision: 0.7879 - recall: 0.7012 - val_loss: 0.9483 - val_precision: 0.7861 - val_recall: 0.7095\n",
            "Epoch 14/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9460 - precision: 0.7906 - recall: 0.7154 - val_loss: 0.9460 - val_precision: 0.7923 - val_recall: 0.7214\n",
            "Epoch 15/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9446 - precision: 0.7927 - recall: 0.7212 - val_loss: 0.9444 - val_precision: 0.7952 - val_recall: 0.7292\n",
            "Epoch 16/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9435 - precision: 0.7946 - recall: 0.7257 - val_loss: 0.9439 - val_precision: 0.7976 - val_recall: 0.7331\n",
            "Epoch 17/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9428 - precision: 0.7959 - recall: 0.7281 - val_loss: 0.9431 - val_precision: 0.7976 - val_recall: 0.7357\n",
            "Epoch 18/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9423 - precision: 0.7965 - recall: 0.7298 - val_loss: 0.9428 - val_precision: 0.7973 - val_recall: 0.7363\n",
            "Epoch 19/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9418 - precision: 0.7974 - recall: 0.7316 - val_loss: 0.9416 - val_precision: 0.7984 - val_recall: 0.7378\n",
            "Epoch 20/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9413 - precision: 0.7986 - recall: 0.7342 - val_loss: 0.9410 - val_precision: 0.7988 - val_recall: 0.7389\n",
            "Epoch 21/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9407 - precision: 0.7997 - recall: 0.7361 - val_loss: 0.9409 - val_precision: 0.7990 - val_recall: 0.7387\n",
            "Epoch 22/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9404 - precision: 0.8007 - recall: 0.7374 - val_loss: 0.9404 - val_precision: 0.8004 - val_recall: 0.7409\n",
            "Epoch 23/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9401 - precision: 0.8014 - recall: 0.7386 - val_loss: 0.9401 - val_precision: 0.8012 - val_recall: 0.7421\n",
            "Epoch 24/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9398 - precision: 0.8020 - recall: 0.7396 - val_loss: 0.9394 - val_precision: 0.8025 - val_recall: 0.7448\n",
            "Epoch 25/25\n",
            "150/150 [==============================] - 4s 24ms/step - loss: 0.9395 - precision: 0.8025 - recall: 0.7409 - val_loss: 0.9389 - val_precision: 0.8032 - val_recall: 0.7463\n",
            "Config Space:\n",
            " {'batch_size': 25, 'learning_rate': 0.033130188028715805, 'optimizer': 'sgd', 'sgd_momentum': 0.7767336836177672}\n",
            "Epoch 1/25\n",
            "42/42 [==============================] - 6s 89ms/step - loss: 1.0157 - precision: 0.7746 - recall: 0.1404 - val_loss: 1.0011 - val_precision: 0.8778 - val_recall: 0.3230\n",
            "Epoch 2/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9999 - precision: 0.8025 - recall: 0.3820 - val_loss: 0.9960 - val_precision: 0.8478 - val_recall: 0.4256\n",
            "Epoch 3/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9961 - precision: 0.8130 - recall: 0.4098 - val_loss: 0.9929 - val_precision: 0.8383 - val_recall: 0.4389\n",
            "Epoch 4/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 0.9931 - precision: 0.8195 - recall: 0.4214 - val_loss: 0.9903 - val_precision: 0.8343 - val_recall: 0.4444\n",
            "Epoch 5/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 0.9905 - precision: 0.8232 - recall: 0.4282 - val_loss: 0.9880 - val_precision: 0.8323 - val_recall: 0.4476\n",
            "Epoch 6/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9882 - precision: 0.8252 - recall: 0.4323 - val_loss: 0.9861 - val_precision: 0.8310 - val_recall: 0.4500\n",
            "Epoch 7/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9860 - precision: 0.8261 - recall: 0.4344 - val_loss: 0.9843 - val_precision: 0.8306 - val_recall: 0.4514\n",
            "Epoch 8/25\n",
            "42/42 [==============================] - 3s 70ms/step - loss: 0.9840 - precision: 0.8262 - recall: 0.4350 - val_loss: 0.9824 - val_precision: 0.8312 - val_recall: 0.4517\n",
            "Epoch 9/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9817 - precision: 0.8257 - recall: 0.4345 - val_loss: 0.9802 - val_precision: 0.8335 - val_recall: 0.4504\n",
            "Epoch 10/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9791 - precision: 0.8248 - recall: 0.4340 - val_loss: 0.9779 - val_precision: 0.8382 - val_recall: 0.4471\n",
            "Epoch 11/25\n",
            "42/42 [==============================] - 3s 70ms/step - loss: 0.9762 - precision: 0.8281 - recall: 0.4579 - val_loss: 0.9756 - val_precision: 0.8530 - val_recall: 0.5089\n",
            "Epoch 12/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9732 - precision: 0.8328 - recall: 0.5049 - val_loss: 0.9736 - val_precision: 0.8488 - val_recall: 0.5152\n",
            "Epoch 13/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9704 - precision: 0.8307 - recall: 0.5229 - val_loss: 0.9723 - val_precision: 0.8447 - val_recall: 0.5139\n",
            "Epoch 14/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9682 - precision: 0.8275 - recall: 0.5311 - val_loss: 0.9716 - val_precision: 0.8252 - val_recall: 0.5156\n",
            "Epoch 15/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9665 - precision: 0.8246 - recall: 0.5386 - val_loss: 0.9713 - val_precision: 0.7959 - val_recall: 0.5236\n",
            "Epoch 16/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9651 - precision: 0.8223 - recall: 0.5460 - val_loss: 0.9712 - val_precision: 0.7752 - val_recall: 0.5304\n",
            "Epoch 17/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9639 - precision: 0.8204 - recall: 0.5533 - val_loss: 0.9711 - val_precision: 0.7610 - val_recall: 0.5363\n",
            "Epoch 18/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9628 - precision: 0.8189 - recall: 0.5606 - val_loss: 0.9709 - val_precision: 0.7513 - val_recall: 0.5420\n",
            "Epoch 19/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9618 - precision: 0.8174 - recall: 0.5679 - val_loss: 0.9708 - val_precision: 0.7434 - val_recall: 0.5477\n",
            "Epoch 20/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9608 - precision: 0.8156 - recall: 0.5760 - val_loss: 0.9707 - val_precision: 0.7370 - val_recall: 0.5542\n",
            "Epoch 21/25\n",
            "42/42 [==============================] - 3s 70ms/step - loss: 0.9597 - precision: 0.8139 - recall: 0.5851 - val_loss: 0.9704 - val_precision: 0.7324 - val_recall: 0.5623\n",
            "Epoch 22/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9584 - precision: 0.8119 - recall: 0.5954 - val_loss: 0.9697 - val_precision: 0.7311 - val_recall: 0.5722\n",
            "Epoch 23/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9570 - precision: 0.8101 - recall: 0.6073 - val_loss: 0.9686 - val_precision: 0.7333 - val_recall: 0.5841\n",
            "Epoch 24/25\n",
            "42/42 [==============================] - 3s 69ms/step - loss: 0.9553 - precision: 0.8090 - recall: 0.6200 - val_loss: 0.9673 - val_precision: 0.7371 - val_recall: 0.5970\n",
            "Epoch 25/25\n",
            "42/42 [==============================] - 3s 68ms/step - loss: 0.9536 - precision: 0.8087 - recall: 0.6317 - val_loss: 0.9662 - val_precision: 0.7420 - val_recall: 0.6090\n",
            "Config Space:\n",
            " {'batch_size': 11, 'learning_rate': 0.00393196591281057, 'optimizer': 'adam', 'sgd_momentum': 0.392466295122575}\n",
            "Epoch 1/75\n",
            "95/95 [==============================] - 6s 44ms/step - loss: 0.9916 - precision: 0.8327 - recall: 0.4293 - val_loss: 0.9812 - val_precision: 0.8545 - val_recall: 0.4823\n",
            "Epoch 2/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9631 - precision: 0.8450 - recall: 0.5899 - val_loss: 0.9558 - val_precision: 0.8357 - val_recall: 0.6368\n",
            "Epoch 3/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9520 - precision: 0.8270 - recall: 0.6514 - val_loss: 0.9506 - val_precision: 0.8001 - val_recall: 0.6917\n",
            "Epoch 4/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9447 - precision: 0.8124 - recall: 0.7105 - val_loss: 0.9496 - val_precision: 0.7753 - val_recall: 0.7076\n",
            "Epoch 5/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9386 - precision: 0.8127 - recall: 0.7387 - val_loss: 0.9480 - val_precision: 0.7699 - val_recall: 0.7106\n",
            "Epoch 6/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9370 - precision: 0.8145 - recall: 0.7452 - val_loss: 0.9379 - val_precision: 0.7993 - val_recall: 0.7420\n",
            "Epoch 7/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9352 - precision: 0.8159 - recall: 0.7522 - val_loss: 0.9362 - val_precision: 0.7960 - val_recall: 0.7454\n",
            "Epoch 8/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9335 - precision: 0.8188 - recall: 0.7587 - val_loss: 0.9361 - val_precision: 0.7970 - val_recall: 0.7465\n",
            "Epoch 9/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9317 - precision: 0.8218 - recall: 0.7650 - val_loss: 0.9359 - val_precision: 0.7980 - val_recall: 0.7460\n",
            "Epoch 10/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9305 - precision: 0.8250 - recall: 0.7688 - val_loss: 0.9331 - val_precision: 0.8067 - val_recall: 0.7575\n",
            "Epoch 11/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9296 - precision: 0.8264 - recall: 0.7713 - val_loss: 0.9329 - val_precision: 0.8089 - val_recall: 0.7564\n",
            "Epoch 12/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9290 - precision: 0.8281 - recall: 0.7726 - val_loss: 0.9324 - val_precision: 0.8102 - val_recall: 0.7539\n",
            "Epoch 13/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9281 - precision: 0.8300 - recall: 0.7754 - val_loss: 0.9306 - val_precision: 0.8165 - val_recall: 0.7625\n",
            "Epoch 14/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9266 - precision: 0.8335 - recall: 0.7806 - val_loss: 0.9296 - val_precision: 0.8183 - val_recall: 0.7647\n",
            "Epoch 15/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9258 - precision: 0.8358 - recall: 0.7829 - val_loss: 0.9287 - val_precision: 0.8183 - val_recall: 0.7680\n",
            "Epoch 16/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9249 - precision: 0.8371 - recall: 0.7858 - val_loss: 0.9268 - val_precision: 0.8225 - val_recall: 0.7759\n",
            "Epoch 17/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9242 - precision: 0.8390 - recall: 0.7881 - val_loss: 0.9272 - val_precision: 0.8213 - val_recall: 0.7769\n",
            "Epoch 18/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9233 - precision: 0.8410 - recall: 0.7912 - val_loss: 0.9260 - val_precision: 0.8245 - val_recall: 0.7834\n",
            "Epoch 19/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9229 - precision: 0.8409 - recall: 0.7924 - val_loss: 0.9257 - val_precision: 0.8236 - val_recall: 0.7829\n",
            "Epoch 20/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9226 - precision: 0.8418 - recall: 0.7941 - val_loss: 0.9261 - val_precision: 0.8252 - val_recall: 0.7839\n",
            "Epoch 21/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9213 - precision: 0.8445 - recall: 0.7976 - val_loss: 0.9237 - val_precision: 0.8301 - val_recall: 0.7893\n",
            "Epoch 22/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9210 - precision: 0.8457 - recall: 0.7986 - val_loss: 0.9238 - val_precision: 0.8276 - val_recall: 0.7873\n",
            "Epoch 23/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9209 - precision: 0.8453 - recall: 0.7983 - val_loss: 0.9240 - val_precision: 0.8257 - val_recall: 0.7854\n",
            "Epoch 24/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9206 - precision: 0.8459 - recall: 0.7997 - val_loss: 0.9232 - val_precision: 0.8286 - val_recall: 0.7874\n",
            "Epoch 25/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9201 - precision: 0.8472 - recall: 0.8011 - val_loss: 0.9235 - val_precision: 0.8280 - val_recall: 0.7873\n",
            "Epoch 26/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9200 - precision: 0.8472 - recall: 0.8014 - val_loss: 0.9227 - val_precision: 0.8313 - val_recall: 0.7901\n",
            "Epoch 27/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9194 - precision: 0.8488 - recall: 0.8031 - val_loss: 0.9222 - val_precision: 0.8293 - val_recall: 0.7906\n",
            "Epoch 28/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9192 - precision: 0.8492 - recall: 0.8041 - val_loss: 0.9222 - val_precision: 0.8307 - val_recall: 0.7917\n",
            "Epoch 29/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9188 - precision: 0.8500 - recall: 0.8052 - val_loss: 0.9196 - val_precision: 0.8346 - val_recall: 0.7981\n",
            "Epoch 30/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9183 - precision: 0.8504 - recall: 0.8062 - val_loss: 0.9193 - val_precision: 0.8347 - val_recall: 0.7983\n",
            "Epoch 31/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9180 - precision: 0.8508 - recall: 0.8071 - val_loss: 0.9190 - val_precision: 0.8353 - val_recall: 0.7988\n",
            "Epoch 32/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9177 - precision: 0.8511 - recall: 0.8076 - val_loss: 0.9185 - val_precision: 0.8366 - val_recall: 0.8005\n",
            "Epoch 33/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9172 - precision: 0.8524 - recall: 0.8095 - val_loss: 0.9177 - val_precision: 0.8384 - val_recall: 0.8033\n",
            "Epoch 34/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9171 - precision: 0.8521 - recall: 0.8095 - val_loss: 0.9179 - val_precision: 0.8380 - val_recall: 0.8021\n",
            "Epoch 35/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9169 - precision: 0.8526 - recall: 0.8103 - val_loss: 0.9175 - val_precision: 0.8383 - val_recall: 0.8028\n",
            "Epoch 36/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9167 - precision: 0.8527 - recall: 0.8106 - val_loss: 0.9177 - val_precision: 0.8380 - val_recall: 0.8025\n",
            "Epoch 37/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9167 - precision: 0.8527 - recall: 0.8108 - val_loss: 0.9179 - val_precision: 0.8375 - val_recall: 0.8013\n",
            "Epoch 38/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9166 - precision: 0.8531 - recall: 0.8108 - val_loss: 0.9175 - val_precision: 0.8386 - val_recall: 0.8026\n",
            "Epoch 39/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9164 - precision: 0.8533 - recall: 0.8118 - val_loss: 0.9168 - val_precision: 0.8405 - val_recall: 0.8061\n",
            "Epoch 40/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9161 - precision: 0.8536 - recall: 0.8123 - val_loss: 0.9170 - val_precision: 0.8396 - val_recall: 0.8051\n",
            "Epoch 41/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9161 - precision: 0.8536 - recall: 0.8127 - val_loss: 0.9164 - val_precision: 0.8418 - val_recall: 0.8071\n",
            "Epoch 42/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9158 - precision: 0.8546 - recall: 0.8139 - val_loss: 0.9161 - val_precision: 0.8419 - val_recall: 0.8077\n",
            "Epoch 43/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9155 - precision: 0.8548 - recall: 0.8144 - val_loss: 0.9162 - val_precision: 0.8426 - val_recall: 0.8076\n",
            "Epoch 44/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9156 - precision: 0.8549 - recall: 0.8146 - val_loss: 0.9157 - val_precision: 0.8428 - val_recall: 0.8081\n",
            "Epoch 45/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9153 - precision: 0.8551 - recall: 0.8153 - val_loss: 0.9155 - val_precision: 0.8441 - val_recall: 0.8090\n",
            "Epoch 46/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9152 - precision: 0.8555 - recall: 0.8156 - val_loss: 0.9151 - val_precision: 0.8454 - val_recall: 0.8102\n",
            "Epoch 47/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9149 - precision: 0.8558 - recall: 0.8162 - val_loss: 0.9159 - val_precision: 0.8427 - val_recall: 0.8057\n",
            "Epoch 48/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9149 - precision: 0.8562 - recall: 0.8169 - val_loss: 0.9153 - val_precision: 0.8446 - val_recall: 0.8090\n",
            "Epoch 49/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9150 - precision: 0.8556 - recall: 0.8164 - val_loss: 0.9153 - val_precision: 0.8445 - val_recall: 0.8087\n",
            "Epoch 50/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9148 - precision: 0.8559 - recall: 0.8170 - val_loss: 0.9152 - val_precision: 0.8444 - val_recall: 0.8099\n",
            "Epoch 51/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9149 - precision: 0.8560 - recall: 0.8167 - val_loss: 0.9152 - val_precision: 0.8438 - val_recall: 0.8095\n",
            "Epoch 52/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9154 - precision: 0.8549 - recall: 0.8156 - val_loss: 0.9165 - val_precision: 0.8402 - val_recall: 0.8060\n",
            "Epoch 53/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9152 - precision: 0.8548 - recall: 0.8162 - val_loss: 0.9150 - val_precision: 0.8438 - val_recall: 0.8122\n",
            "Epoch 54/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9145 - precision: 0.8562 - recall: 0.8181 - val_loss: 0.9145 - val_precision: 0.8462 - val_recall: 0.8128\n",
            "Epoch 55/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9144 - precision: 0.8566 - recall: 0.8184 - val_loss: 0.9146 - val_precision: 0.8455 - val_recall: 0.8126\n",
            "Epoch 56/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9147 - precision: 0.8559 - recall: 0.8179 - val_loss: 0.9151 - val_precision: 0.8442 - val_recall: 0.8105\n",
            "Epoch 57/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9143 - precision: 0.8562 - recall: 0.8185 - val_loss: 0.9146 - val_precision: 0.8451 - val_recall: 0.8123\n",
            "Epoch 58/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9140 - precision: 0.8570 - recall: 0.8194 - val_loss: 0.9143 - val_precision: 0.8466 - val_recall: 0.8138\n",
            "Epoch 59/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9140 - precision: 0.8574 - recall: 0.8202 - val_loss: 0.9144 - val_precision: 0.8464 - val_recall: 0.8125\n",
            "Epoch 60/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9143 - precision: 0.8565 - recall: 0.8196 - val_loss: 0.9149 - val_precision: 0.8445 - val_recall: 0.8093\n",
            "Epoch 61/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9140 - precision: 0.8566 - recall: 0.8198 - val_loss: 0.9145 - val_precision: 0.8463 - val_recall: 0.8120\n",
            "Epoch 62/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9140 - precision: 0.8567 - recall: 0.8200 - val_loss: 0.9150 - val_precision: 0.8445 - val_recall: 0.8082\n",
            "Epoch 63/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9138 - precision: 0.8574 - recall: 0.8207 - val_loss: 0.9146 - val_precision: 0.8460 - val_recall: 0.8121\n",
            "Epoch 64/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9136 - precision: 0.8572 - recall: 0.8208 - val_loss: 0.9146 - val_precision: 0.8453 - val_recall: 0.8120\n",
            "Epoch 65/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9134 - precision: 0.8576 - recall: 0.8220 - val_loss: 0.9144 - val_precision: 0.8458 - val_recall: 0.8111\n",
            "Epoch 66/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9133 - precision: 0.8581 - recall: 0.8223 - val_loss: 0.9143 - val_precision: 0.8464 - val_recall: 0.8117\n",
            "Epoch 67/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9132 - precision: 0.8579 - recall: 0.8222 - val_loss: 0.9144 - val_precision: 0.8464 - val_recall: 0.8125\n",
            "Epoch 68/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9133 - precision: 0.8580 - recall: 0.8224 - val_loss: 0.9145 - val_precision: 0.8450 - val_recall: 0.8123\n",
            "Epoch 69/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9132 - precision: 0.8578 - recall: 0.8225 - val_loss: 0.9148 - val_precision: 0.8448 - val_recall: 0.8088\n",
            "Epoch 70/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9131 - precision: 0.8578 - recall: 0.8230 - val_loss: 0.9144 - val_precision: 0.8458 - val_recall: 0.8111\n",
            "Epoch 71/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9133 - precision: 0.8577 - recall: 0.8225 - val_loss: 0.9143 - val_precision: 0.8460 - val_recall: 0.8114\n",
            "Epoch 72/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9132 - precision: 0.8573 - recall: 0.8228 - val_loss: 0.9146 - val_precision: 0.8445 - val_recall: 0.8107\n",
            "Epoch 73/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9131 - precision: 0.8572 - recall: 0.8229 - val_loss: 0.9145 - val_precision: 0.8453 - val_recall: 0.8119\n",
            "Epoch 74/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9130 - precision: 0.8573 - recall: 0.8232 - val_loss: 0.9143 - val_precision: 0.8457 - val_recall: 0.8128\n",
            "Epoch 75/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9130 - precision: 0.8575 - recall: 0.8238 - val_loss: 0.9147 - val_precision: 0.8437 - val_recall: 0.8106\n",
            "Config Space:\n",
            " {'batch_size': 23, 'learning_rate': 0.0032847542515781567, 'optimizer': 'adam', 'sgd_momentum': 0.8016755715024376}\n",
            "Epoch 1/75\n",
            "46/46 [==============================] - 6s 82ms/step - loss: 0.9963 - precision: 0.8214 - recall: 0.3932 - val_loss: 0.9838 - val_precision: 0.9024 - val_recall: 0.4407\n",
            "Epoch 2/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9786 - precision: 0.8550 - recall: 0.5011 - val_loss: 0.9769 - val_precision: 0.8899 - val_recall: 0.4859\n",
            "Epoch 3/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9656 - precision: 0.8543 - recall: 0.5553 - val_loss: 0.9525 - val_precision: 0.8379 - val_recall: 0.6592\n",
            "Epoch 4/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9483 - precision: 0.8237 - recall: 0.6754 - val_loss: 0.9568 - val_precision: 0.7504 - val_recall: 0.6316\n",
            "Epoch 5/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9430 - precision: 0.8142 - recall: 0.7133 - val_loss: 0.9414 - val_precision: 0.8018 - val_recall: 0.7252\n",
            "Epoch 6/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9378 - precision: 0.8200 - recall: 0.7436 - val_loss: 0.9412 - val_precision: 0.7665 - val_recall: 0.7142\n",
            "Epoch 7/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9327 - precision: 0.8239 - recall: 0.7563 - val_loss: 0.9330 - val_precision: 0.8093 - val_recall: 0.7624\n",
            "Epoch 8/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9257 - precision: 0.8361 - recall: 0.7818 - val_loss: 0.9420 - val_precision: 0.7788 - val_recall: 0.7307\n",
            "Epoch 9/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9259 - precision: 0.8347 - recall: 0.7829 - val_loss: 0.9341 - val_precision: 0.7923 - val_recall: 0.7544\n",
            "Epoch 10/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9236 - precision: 0.8396 - recall: 0.7894 - val_loss: 0.9283 - val_precision: 0.8071 - val_recall: 0.7726\n",
            "Epoch 11/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9212 - precision: 0.8417 - recall: 0.7947 - val_loss: 0.9246 - val_precision: 0.8165 - val_recall: 0.7822\n",
            "Epoch 12/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9187 - precision: 0.8478 - recall: 0.8034 - val_loss: 0.9260 - val_precision: 0.8117 - val_recall: 0.7816\n",
            "Epoch 13/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9182 - precision: 0.8479 - recall: 0.8046 - val_loss: 0.9229 - val_precision: 0.8194 - val_recall: 0.7892\n",
            "Epoch 14/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9165 - precision: 0.8519 - recall: 0.8098 - val_loss: 0.9248 - val_precision: 0.8150 - val_recall: 0.7843\n",
            "Epoch 15/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9156 - precision: 0.8530 - recall: 0.8120 - val_loss: 0.9223 - val_precision: 0.8231 - val_recall: 0.7929\n",
            "Epoch 16/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9141 - precision: 0.8560 - recall: 0.8164 - val_loss: 0.9205 - val_precision: 0.8297 - val_recall: 0.7993\n",
            "Epoch 17/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9140 - precision: 0.8568 - recall: 0.8161 - val_loss: 0.9208 - val_precision: 0.8281 - val_recall: 0.7993\n",
            "Epoch 18/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9127 - precision: 0.8593 - recall: 0.8200 - val_loss: 0.9213 - val_precision: 0.8281 - val_recall: 0.7987\n",
            "Epoch 19/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9121 - precision: 0.8607 - recall: 0.8222 - val_loss: 0.9214 - val_precision: 0.8274 - val_recall: 0.7969\n",
            "Epoch 20/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9130 - precision: 0.8591 - recall: 0.8179 - val_loss: 0.9204 - val_precision: 0.8321 - val_recall: 0.8026\n",
            "Epoch 21/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9116 - precision: 0.8619 - recall: 0.8226 - val_loss: 0.9191 - val_precision: 0.8333 - val_recall: 0.8015\n",
            "Epoch 22/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9110 - precision: 0.8621 - recall: 0.8219 - val_loss: 0.9177 - val_precision: 0.8386 - val_recall: 0.8079\n",
            "Epoch 23/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9106 - precision: 0.8617 - recall: 0.8231 - val_loss: 0.9198 - val_precision: 0.8331 - val_recall: 0.8032\n",
            "Epoch 24/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9102 - precision: 0.8619 - recall: 0.8249 - val_loss: 0.9178 - val_precision: 0.8360 - val_recall: 0.8085\n",
            "Epoch 25/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9094 - precision: 0.8615 - recall: 0.8275 - val_loss: 0.9176 - val_precision: 0.8364 - val_recall: 0.8072\n",
            "Epoch 26/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9095 - precision: 0.8605 - recall: 0.8277 - val_loss: 0.9174 - val_precision: 0.8419 - val_recall: 0.8116\n",
            "Epoch 27/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9103 - precision: 0.8608 - recall: 0.8273 - val_loss: 0.9189 - val_precision: 0.8323 - val_recall: 0.8060\n",
            "Epoch 28/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9099 - precision: 0.8589 - recall: 0.8266 - val_loss: 0.9234 - val_precision: 0.8230 - val_recall: 0.7917\n",
            "Epoch 29/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9106 - precision: 0.8619 - recall: 0.8282 - val_loss: 0.9175 - val_precision: 0.8336 - val_recall: 0.8045\n",
            "Epoch 30/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9089 - precision: 0.8615 - recall: 0.8308 - val_loss: 0.9167 - val_precision: 0.8322 - val_recall: 0.8056\n",
            "Epoch 31/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9094 - precision: 0.8606 - recall: 0.8301 - val_loss: 0.9180 - val_precision: 0.8319 - val_recall: 0.8070\n",
            "Epoch 32/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9092 - precision: 0.8606 - recall: 0.8306 - val_loss: 0.9181 - val_precision: 0.8279 - val_recall: 0.8011\n",
            "Epoch 33/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9078 - precision: 0.8631 - recall: 0.8352 - val_loss: 0.9148 - val_precision: 0.8424 - val_recall: 0.8169\n",
            "Epoch 34/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9070 - precision: 0.8648 - recall: 0.8386 - val_loss: 0.9128 - val_precision: 0.8490 - val_recall: 0.8261\n",
            "Epoch 35/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9066 - precision: 0.8662 - recall: 0.8392 - val_loss: 0.9146 - val_precision: 0.8413 - val_recall: 0.8162\n",
            "Epoch 36/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9070 - precision: 0.8647 - recall: 0.8388 - val_loss: 0.9153 - val_precision: 0.8427 - val_recall: 0.8176\n",
            "Epoch 37/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9071 - precision: 0.8655 - recall: 0.8388 - val_loss: 0.9182 - val_precision: 0.8327 - val_recall: 0.8058\n",
            "Epoch 38/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9068 - precision: 0.8636 - recall: 0.8369 - val_loss: 0.9185 - val_precision: 0.8365 - val_recall: 0.8132\n",
            "Epoch 39/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9062 - precision: 0.8660 - recall: 0.8410 - val_loss: 0.9141 - val_precision: 0.8418 - val_recall: 0.8206\n",
            "Epoch 40/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9066 - precision: 0.8643 - recall: 0.8397 - val_loss: 0.9166 - val_precision: 0.8376 - val_recall: 0.8145\n",
            "Epoch 41/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9066 - precision: 0.8645 - recall: 0.8390 - val_loss: 0.9219 - val_precision: 0.8203 - val_recall: 0.7921\n",
            "Epoch 42/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9070 - precision: 0.8641 - recall: 0.8388 - val_loss: 0.9181 - val_precision: 0.8396 - val_recall: 0.8146\n",
            "Epoch 43/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9079 - precision: 0.8636 - recall: 0.8382 - val_loss: 0.9142 - val_precision: 0.8448 - val_recall: 0.8207\n",
            "Epoch 44/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9055 - precision: 0.8675 - recall: 0.8420 - val_loss: 0.9169 - val_precision: 0.8391 - val_recall: 0.8185\n",
            "Epoch 45/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9057 - precision: 0.8665 - recall: 0.8412 - val_loss: 0.9162 - val_precision: 0.8395 - val_recall: 0.8173\n",
            "Epoch 46/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9053 - precision: 0.8670 - recall: 0.8417 - val_loss: 0.9150 - val_precision: 0.8426 - val_recall: 0.8241\n",
            "Epoch 47/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9044 - precision: 0.8679 - recall: 0.8443 - val_loss: 0.9193 - val_precision: 0.8331 - val_recall: 0.8122\n",
            "Epoch 48/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9050 - precision: 0.8672 - recall: 0.8422 - val_loss: 0.9176 - val_precision: 0.8385 - val_recall: 0.8202\n",
            "Epoch 49/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9042 - precision: 0.8668 - recall: 0.8430 - val_loss: 0.9153 - val_precision: 0.8409 - val_recall: 0.8218\n",
            "Epoch 50/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9045 - precision: 0.8683 - recall: 0.8439 - val_loss: 0.9165 - val_precision: 0.8386 - val_recall: 0.8199\n",
            "Epoch 51/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9051 - precision: 0.8664 - recall: 0.8426 - val_loss: 0.9162 - val_precision: 0.8359 - val_recall: 0.8186\n",
            "Epoch 52/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9038 - precision: 0.8676 - recall: 0.8442 - val_loss: 0.9133 - val_precision: 0.8459 - val_recall: 0.8304\n",
            "Epoch 53/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9044 - precision: 0.8668 - recall: 0.8429 - val_loss: 0.9163 - val_precision: 0.8317 - val_recall: 0.8124\n",
            "Epoch 54/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9042 - precision: 0.8658 - recall: 0.8424 - val_loss: 0.9163 - val_precision: 0.8321 - val_recall: 0.8161\n",
            "Epoch 55/75\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 0.9041 - precision: 0.8652 - recall: 0.8410 - val_loss: 0.9174 - val_precision: 0.8285 - val_recall: 0.8117\n",
            "Epoch 56/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9049 - precision: 0.8645 - recall: 0.8405 - val_loss: 0.9184 - val_precision: 0.8267 - val_recall: 0.8070\n",
            "Epoch 57/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9057 - precision: 0.8635 - recall: 0.8382 - val_loss: 0.9191 - val_precision: 0.8283 - val_recall: 0.8077\n",
            "Epoch 58/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9054 - precision: 0.8646 - recall: 0.8401 - val_loss: 0.9214 - val_precision: 0.8127 - val_recall: 0.7905\n",
            "Epoch 59/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9060 - precision: 0.8627 - recall: 0.8370 - val_loss: 0.9215 - val_precision: 0.8233 - val_recall: 0.8046\n",
            "Epoch 60/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9036 - precision: 0.8674 - recall: 0.8443 - val_loss: 0.9188 - val_precision: 0.8289 - val_recall: 0.8084\n",
            "Epoch 61/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9027 - precision: 0.8693 - recall: 0.8454 - val_loss: 0.9178 - val_precision: 0.8299 - val_recall: 0.8075\n",
            "Epoch 62/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9030 - precision: 0.8684 - recall: 0.8441 - val_loss: 0.9198 - val_precision: 0.8333 - val_recall: 0.8147\n",
            "Epoch 63/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9042 - precision: 0.8674 - recall: 0.8440 - val_loss: 0.9202 - val_precision: 0.8324 - val_recall: 0.8085\n",
            "Epoch 64/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9027 - precision: 0.8688 - recall: 0.8455 - val_loss: 0.9235 - val_precision: 0.8168 - val_recall: 0.7982\n",
            "Epoch 65/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9035 - precision: 0.8690 - recall: 0.8444 - val_loss: 0.9172 - val_precision: 0.8334 - val_recall: 0.8157\n",
            "Epoch 66/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9012 - precision: 0.8717 - recall: 0.8489 - val_loss: 0.9189 - val_precision: 0.8313 - val_recall: 0.8098\n",
            "Epoch 67/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9016 - precision: 0.8703 - recall: 0.8470 - val_loss: 0.9194 - val_precision: 0.8315 - val_recall: 0.8092\n",
            "Epoch 68/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9042 - precision: 0.8657 - recall: 0.8411 - val_loss: 0.9175 - val_precision: 0.8354 - val_recall: 0.8147\n",
            "Epoch 69/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9024 - precision: 0.8702 - recall: 0.8471 - val_loss: 0.9231 - val_precision: 0.8179 - val_recall: 0.7935\n",
            "Epoch 70/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9013 - precision: 0.8712 - recall: 0.8486 - val_loss: 0.9184 - val_precision: 0.8318 - val_recall: 0.8116\n",
            "Epoch 71/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9020 - precision: 0.8709 - recall: 0.8474 - val_loss: 0.9193 - val_precision: 0.8296 - val_recall: 0.8070\n",
            "Epoch 72/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9015 - precision: 0.8710 - recall: 0.8491 - val_loss: 0.9164 - val_precision: 0.8395 - val_recall: 0.8196\n",
            "Epoch 73/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.9004 - precision: 0.8716 - recall: 0.8503 - val_loss: 0.9164 - val_precision: 0.8375 - val_recall: 0.8200\n",
            "Epoch 74/75\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 0.8997 - precision: 0.8744 - recall: 0.8530 - val_loss: 0.9164 - val_precision: 0.8326 - val_recall: 0.8153\n",
            "Epoch 75/75\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 0.9001 - precision: 0.8728 - recall: 0.8510 - val_loss: 0.9171 - val_precision: 0.8321 - val_recall: 0.8160\n",
            "Config Space:\n",
            " {'batch_size': 26, 'learning_rate': 0.004794279849735609, 'optimizer': 'sgd', 'sgd_momentum': 0.12276821185304304}\n",
            "Epoch 1/75\n",
            "41/41 [==============================] - 6s 90ms/step - loss: 1.0469 - precision: 0.0079 - recall: 0.0012 - val_loss: 1.0361 - val_precision: 0.0030 - val_recall: 1.2570e-05\n",
            "Epoch 2/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0369 - precision: 0.0072 - recall: 4.6729e-04 - val_loss: 1.0281 - val_precision: 0.0345 - val_recall: 5.8463e-08\n",
            "Epoch 3/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0290 - precision: 0.0339 - recall: 0.0010 - val_loss: 1.0204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0215 - precision: 0.3253 - recall: 0.0074 - val_loss: 1.0132 - val_precision: 0.0261 - val_recall: 3.5078e-07\n",
            "Epoch 5/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0150 - precision: 0.7509 - recall: 0.0396 - val_loss: 1.0078 - val_precision: 0.7542 - val_recall: 0.0057\n",
            "Epoch 6/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0103 - precision: 0.8359 - recall: 0.1132 - val_loss: 1.0043 - val_precision: 0.8831 - val_recall: 0.1365\n",
            "Epoch 7/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0073 - precision: 0.8404 - recall: 0.1983 - val_loss: 1.0023 - val_precision: 0.8803 - val_recall: 0.3148\n",
            "Epoch 8/75\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 1.0056 - precision: 0.8324 - recall: 0.2644 - val_loss: 1.0012 - val_precision: 0.8627 - val_recall: 0.3943\n",
            "Epoch 9/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0046 - precision: 0.8240 - recall: 0.3080 - val_loss: 1.0006 - val_precision: 0.8469 - val_recall: 0.4220\n",
            "Epoch 10/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0039 - precision: 0.8175 - recall: 0.3363 - val_loss: 1.0002 - val_precision: 0.8355 - val_recall: 0.4352\n",
            "Epoch 11/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0034 - precision: 0.8125 - recall: 0.3546 - val_loss: 0.9999 - val_precision: 0.8278 - val_recall: 0.4427\n",
            "Epoch 12/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0030 - precision: 0.8091 - recall: 0.3671 - val_loss: 0.9997 - val_precision: 0.8225 - val_recall: 0.4474\n",
            "Epoch 13/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0027 - precision: 0.8069 - recall: 0.3759 - val_loss: 0.9995 - val_precision: 0.8188 - val_recall: 0.4505\n",
            "Epoch 14/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0024 - precision: 0.8054 - recall: 0.3822 - val_loss: 0.9993 - val_precision: 0.8162 - val_recall: 0.4527\n",
            "Epoch 15/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0021 - precision: 0.8047 - recall: 0.3869 - val_loss: 0.9992 - val_precision: 0.8142 - val_recall: 0.4543\n",
            "Epoch 16/75\n",
            "41/41 [==============================] - 3s 72ms/step - loss: 1.0019 - precision: 0.8041 - recall: 0.3905 - val_loss: 0.9991 - val_precision: 0.8127 - val_recall: 0.4555\n",
            "Epoch 17/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0017 - precision: 0.8038 - recall: 0.3934 - val_loss: 0.9989 - val_precision: 0.8115 - val_recall: 0.4564\n",
            "Epoch 18/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0015 - precision: 0.8038 - recall: 0.3957 - val_loss: 0.9988 - val_precision: 0.8106 - val_recall: 0.4572\n",
            "Epoch 19/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0013 - precision: 0.8037 - recall: 0.3976 - val_loss: 0.9987 - val_precision: 0.8099 - val_recall: 0.4577\n",
            "Epoch 20/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0011 - precision: 0.8039 - recall: 0.3993 - val_loss: 0.9986 - val_precision: 0.8093 - val_recall: 0.4582\n",
            "Epoch 21/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0009 - precision: 0.8040 - recall: 0.4007 - val_loss: 0.9985 - val_precision: 0.8089 - val_recall: 0.4586\n",
            "Epoch 22/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0007 - precision: 0.8042 - recall: 0.4019 - val_loss: 0.9983 - val_precision: 0.8085 - val_recall: 0.4589\n",
            "Epoch 23/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0006 - precision: 0.8044 - recall: 0.4030 - val_loss: 0.9982 - val_precision: 0.8082 - val_recall: 0.4592\n",
            "Epoch 24/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 1.0004 - precision: 0.8047 - recall: 0.4041 - val_loss: 0.9981 - val_precision: 0.8079 - val_recall: 0.4594\n",
            "Epoch 25/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0003 - precision: 0.8047 - recall: 0.4050 - val_loss: 0.9980 - val_precision: 0.8077 - val_recall: 0.4596\n",
            "Epoch 26/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0001 - precision: 0.8051 - recall: 0.4058 - val_loss: 0.9979 - val_precision: 0.8075 - val_recall: 0.4598\n",
            "Epoch 27/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 1.0000 - precision: 0.8052 - recall: 0.4066 - val_loss: 0.9978 - val_precision: 0.8074 - val_recall: 0.4600\n",
            "Epoch 28/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9999 - precision: 0.8056 - recall: 0.4073 - val_loss: 0.9977 - val_precision: 0.8072 - val_recall: 0.4601\n",
            "Epoch 29/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9997 - precision: 0.8057 - recall: 0.4080 - val_loss: 0.9976 - val_precision: 0.8071 - val_recall: 0.4602\n",
            "Epoch 30/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9996 - precision: 0.8060 - recall: 0.4086 - val_loss: 0.9975 - val_precision: 0.8071 - val_recall: 0.4603\n",
            "Epoch 31/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9995 - precision: 0.8063 - recall: 0.4093 - val_loss: 0.9974 - val_precision: 0.8070 - val_recall: 0.4604\n",
            "Epoch 32/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9993 - precision: 0.8065 - recall: 0.4099 - val_loss: 0.9974 - val_precision: 0.8069 - val_recall: 0.4605\n",
            "Epoch 33/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9992 - precision: 0.8068 - recall: 0.4104 - val_loss: 0.9973 - val_precision: 0.8069 - val_recall: 0.4606\n",
            "Epoch 34/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9991 - precision: 0.8069 - recall: 0.4110 - val_loss: 0.9972 - val_precision: 0.8069 - val_recall: 0.4607\n",
            "Epoch 35/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9990 - precision: 0.8072 - recall: 0.4115 - val_loss: 0.9971 - val_precision: 0.8069 - val_recall: 0.4607\n",
            "Epoch 36/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9989 - precision: 0.8075 - recall: 0.4119 - val_loss: 0.9970 - val_precision: 0.8068 - val_recall: 0.4608\n",
            "Epoch 37/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9988 - precision: 0.8076 - recall: 0.4123 - val_loss: 0.9969 - val_precision: 0.8068 - val_recall: 0.4609\n",
            "Epoch 38/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9986 - precision: 0.8079 - recall: 0.4128 - val_loss: 0.9968 - val_precision: 0.8068 - val_recall: 0.4609\n",
            "Epoch 39/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9985 - precision: 0.8080 - recall: 0.4133 - val_loss: 0.9967 - val_precision: 0.8068 - val_recall: 0.4610\n",
            "Epoch 40/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9984 - precision: 0.8083 - recall: 0.4137 - val_loss: 0.9966 - val_precision: 0.8068 - val_recall: 0.4610\n",
            "Epoch 41/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9983 - precision: 0.8084 - recall: 0.4141 - val_loss: 0.9966 - val_precision: 0.8068 - val_recall: 0.4611\n",
            "Epoch 42/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9982 - precision: 0.8086 - recall: 0.4146 - val_loss: 0.9965 - val_precision: 0.8068 - val_recall: 0.4611\n",
            "Epoch 43/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9981 - precision: 0.8088 - recall: 0.4150 - val_loss: 0.9964 - val_precision: 0.8069 - val_recall: 0.4611\n",
            "Epoch 44/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9980 - precision: 0.8090 - recall: 0.4154 - val_loss: 0.9963 - val_precision: 0.8069 - val_recall: 0.4612\n",
            "Epoch 45/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9979 - precision: 0.8092 - recall: 0.4158 - val_loss: 0.9962 - val_precision: 0.8069 - val_recall: 0.4612\n",
            "Epoch 46/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9978 - precision: 0.8094 - recall: 0.4161 - val_loss: 0.9962 - val_precision: 0.8069 - val_recall: 0.4612\n",
            "Epoch 47/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9977 - precision: 0.8095 - recall: 0.4165 - val_loss: 0.9961 - val_precision: 0.8069 - val_recall: 0.4613\n",
            "Epoch 48/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9976 - precision: 0.8097 - recall: 0.4169 - val_loss: 0.9960 - val_precision: 0.8070 - val_recall: 0.4613\n",
            "Epoch 49/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9975 - precision: 0.8100 - recall: 0.4172 - val_loss: 0.9959 - val_precision: 0.8070 - val_recall: 0.4613\n",
            "Epoch 50/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9974 - precision: 0.8101 - recall: 0.4175 - val_loss: 0.9958 - val_precision: 0.8070 - val_recall: 0.4614\n",
            "Epoch 51/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9973 - precision: 0.8104 - recall: 0.4180 - val_loss: 0.9958 - val_precision: 0.8070 - val_recall: 0.4614\n",
            "Epoch 52/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9972 - precision: 0.8103 - recall: 0.4183 - val_loss: 0.9957 - val_precision: 0.8071 - val_recall: 0.4614\n",
            "Epoch 53/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9971 - precision: 0.8105 - recall: 0.4186 - val_loss: 0.9956 - val_precision: 0.8071 - val_recall: 0.4614\n",
            "Epoch 54/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9970 - precision: 0.8107 - recall: 0.4189 - val_loss: 0.9955 - val_precision: 0.8071 - val_recall: 0.4614\n",
            "Epoch 55/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9969 - precision: 0.8109 - recall: 0.4193 - val_loss: 0.9955 - val_precision: 0.8072 - val_recall: 0.4615\n",
            "Epoch 56/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9969 - precision: 0.8110 - recall: 0.4196 - val_loss: 0.9954 - val_precision: 0.8072 - val_recall: 0.4615\n",
            "Epoch 57/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9968 - precision: 0.8112 - recall: 0.4199 - val_loss: 0.9953 - val_precision: 0.8072 - val_recall: 0.4615\n",
            "Epoch 58/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9967 - precision: 0.8113 - recall: 0.4202 - val_loss: 0.9952 - val_precision: 0.8073 - val_recall: 0.4615\n",
            "Epoch 59/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9966 - precision: 0.8115 - recall: 0.4205 - val_loss: 0.9952 - val_precision: 0.8073 - val_recall: 0.4615\n",
            "Epoch 60/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9965 - precision: 0.8116 - recall: 0.4208 - val_loss: 0.9951 - val_precision: 0.8073 - val_recall: 0.4615\n",
            "Epoch 61/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9964 - precision: 0.8118 - recall: 0.4211 - val_loss: 0.9950 - val_precision: 0.8074 - val_recall: 0.4616\n",
            "Epoch 62/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9963 - precision: 0.8118 - recall: 0.4214 - val_loss: 0.9949 - val_precision: 0.8074 - val_recall: 0.4616\n",
            "Epoch 63/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9962 - precision: 0.8120 - recall: 0.4217 - val_loss: 0.9949 - val_precision: 0.8075 - val_recall: 0.4616\n",
            "Epoch 64/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9962 - precision: 0.8123 - recall: 0.4219 - val_loss: 0.9948 - val_precision: 0.8075 - val_recall: 0.4616\n",
            "Epoch 65/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9961 - precision: 0.8124 - recall: 0.4222 - val_loss: 0.9947 - val_precision: 0.8076 - val_recall: 0.4616\n",
            "Epoch 66/75\n",
            "41/41 [==============================] - 3s 70ms/step - loss: 0.9960 - precision: 0.8124 - recall: 0.4225 - val_loss: 0.9947 - val_precision: 0.8076 - val_recall: 0.4616\n",
            "Epoch 67/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9959 - precision: 0.8127 - recall: 0.4228 - val_loss: 0.9946 - val_precision: 0.8076 - val_recall: 0.4616\n",
            "Epoch 68/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9958 - precision: 0.8128 - recall: 0.4231 - val_loss: 0.9945 - val_precision: 0.8077 - val_recall: 0.4617\n",
            "Epoch 69/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9957 - precision: 0.8130 - recall: 0.4234 - val_loss: 0.9944 - val_precision: 0.8077 - val_recall: 0.4617\n",
            "Epoch 70/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9956 - precision: 0.8132 - recall: 0.4236 - val_loss: 0.9944 - val_precision: 0.8078 - val_recall: 0.4617\n",
            "Epoch 71/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9956 - precision: 0.8132 - recall: 0.4239 - val_loss: 0.9943 - val_precision: 0.8078 - val_recall: 0.4617\n",
            "Epoch 72/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9955 - precision: 0.8134 - recall: 0.4241 - val_loss: 0.9942 - val_precision: 0.8079 - val_recall: 0.4617\n",
            "Epoch 73/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9954 - precision: 0.8135 - recall: 0.4244 - val_loss: 0.9942 - val_precision: 0.8079 - val_recall: 0.4617\n",
            "Epoch 74/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9953 - precision: 0.8136 - recall: 0.4246 - val_loss: 0.9941 - val_precision: 0.8080 - val_recall: 0.4617\n",
            "Epoch 75/75\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.9952 - precision: 0.8138 - recall: 0.4249 - val_loss: 0.9940 - val_precision: 0.8080 - val_recall: 0.4617\n",
            "Config Space:\n",
            " {'batch_size': 1, 'learning_rate': 0.035252990416093734, 'optimizer': 'adam', 'sgd_momentum': 0.9226147983361845}\n",
            "Epoch 1/25\n",
            "1044/1044 [==============================] - 16s 14ms/step - loss: 1.5113 - precision: 0.1349 - recall: 0.1348 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 2/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 3/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 4/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 5/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 6/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 7/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 8/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 9/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 10/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 11/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 12/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 13/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 14/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 15/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 16/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 17/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 18/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 19/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 20/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 21/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 22/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 23/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 24/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Epoch 25/25\n",
            "1044/1044 [==============================] - 13s 13ms/step - loss: 1.5115 - precision: 0.1354 - recall: 0.1354 - val_loss: 1.5067 - val_precision: 0.1425 - val_recall: 0.1425\n",
            "Config Space:\n",
            " {'batch_size': 24, 'learning_rate': 0.000504924978646984, 'optimizer': 'sgd', 'sgd_momentum': 0.9886347100920375}\n",
            "Epoch 1/25\n",
            "44/44 [==============================] - 6s 85ms/step - loss: 1.0414 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0372 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0339 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0299 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0286 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0261 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 1.0251 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0219 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.0198 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0185 - precision: 0.8684 - recall: 4.8232e-07 - val_loss: 1.0160 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0147 - precision: 0.8565 - recall: 0.0013 - val_loss: 1.0119 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0113 - precision: 0.8694 - recall: 0.0744 - val_loss: 1.0086 - val_precision: 0.8825 - val_recall: 0.0984\n",
            "Epoch 9/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0092 - precision: 0.8448 - recall: 0.3014 - val_loss: 1.0069 - val_precision: 0.8540 - val_recall: 0.4229\n",
            "Epoch 10/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0079 - precision: 0.8128 - recall: 0.4093 - val_loss: 1.0054 - val_precision: 0.8240 - val_recall: 0.4490\n",
            "Epoch 11/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0062 - precision: 0.8129 - recall: 0.4197 - val_loss: 1.0039 - val_precision: 0.8401 - val_recall: 0.4373\n",
            "Epoch 12/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0047 - precision: 0.8327 - recall: 0.3971 - val_loss: 1.0028 - val_precision: 0.8635 - val_recall: 0.4140\n",
            "Epoch 13/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0036 - precision: 0.8465 - recall: 0.3771 - val_loss: 1.0020 - val_precision: 0.8695 - val_recall: 0.4067\n",
            "Epoch 14/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0026 - precision: 0.8458 - recall: 0.3846 - val_loss: 1.0009 - val_precision: 0.8577 - val_recall: 0.4226\n",
            "Epoch 15/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0015 - precision: 0.8353 - recall: 0.4089 - val_loss: 0.9999 - val_precision: 0.8398 - val_recall: 0.4399\n",
            "Epoch 16/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0006 - precision: 0.8254 - recall: 0.4271 - val_loss: 0.9991 - val_precision: 0.8295 - val_recall: 0.4482\n",
            "Epoch 17/25\n",
            "44/44 [==============================] - 3s 65ms/step - loss: 0.9998 - precision: 0.8234 - recall: 0.4330 - val_loss: 0.9983 - val_precision: 0.8302 - val_recall: 0.4482\n",
            "Epoch 18/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9989 - precision: 0.8280 - recall: 0.4309 - val_loss: 0.9975 - val_precision: 0.8353 - val_recall: 0.4448\n",
            "Epoch 19/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9981 - precision: 0.8327 - recall: 0.4280 - val_loss: 0.9968 - val_precision: 0.8375 - val_recall: 0.4436\n",
            "Epoch 20/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9974 - precision: 0.8335 - recall: 0.4291 - val_loss: 0.9961 - val_precision: 0.8348 - val_recall: 0.4461\n",
            "Epoch 21/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9967 - precision: 0.8317 - recall: 0.4332 - val_loss: 0.9954 - val_precision: 0.8309 - val_recall: 0.4495\n",
            "Epoch 22/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9961 - precision: 0.8301 - recall: 0.4365 - val_loss: 0.9948 - val_precision: 0.8290 - val_recall: 0.4512\n",
            "Epoch 23/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9954 - precision: 0.8305 - recall: 0.4376 - val_loss: 0.9942 - val_precision: 0.8294 - val_recall: 0.4512\n",
            "Epoch 24/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9949 - precision: 0.8320 - recall: 0.4374 - val_loss: 0.9937 - val_precision: 0.8301 - val_recall: 0.4511\n",
            "Epoch 25/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9943 - precision: 0.8327 - recall: 0.4377 - val_loss: 0.9932 - val_precision: 0.8296 - val_recall: 0.4517\n",
            "Config Space:\n",
            " {'batch_size': 28, 'learning_rate': 0.061566996059290544, 'optimizer': 'sgd', 'sgd_momentum': 0.9387601099445818}\n",
            "Epoch 1/25\n",
            "38/38 [==============================] - 7s 106ms/step - loss: 1.0017 - precision: 0.7467 - recall: 0.3553 - val_loss: 0.9920 - val_precision: 0.7876 - val_recall: 0.4735\n",
            "Epoch 2/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9884 - precision: 0.8176 - recall: 0.4432 - val_loss: 0.9843 - val_precision: 0.8091 - val_recall: 0.4659\n",
            "Epoch 3/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9794 - precision: 0.8229 - recall: 0.4696 - val_loss: 0.9748 - val_precision: 0.8418 - val_recall: 0.5150\n",
            "Epoch 4/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9712 - precision: 0.8305 - recall: 0.5284 - val_loss: 0.9711 - val_precision: 0.8491 - val_recall: 0.5129\n",
            "Epoch 5/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9661 - precision: 0.8379 - recall: 0.5375 - val_loss: 0.9755 - val_precision: 0.8159 - val_recall: 0.4946\n",
            "Epoch 6/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9622 - precision: 0.8293 - recall: 0.5568 - val_loss: 0.9690 - val_precision: 0.8164 - val_recall: 0.5225\n",
            "Epoch 7/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9576 - precision: 0.8144 - recall: 0.5974 - val_loss: 0.9647 - val_precision: 0.7615 - val_recall: 0.6058\n",
            "Epoch 8/25\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9523 - precision: 0.8123 - recall: 0.6356 - val_loss: 0.9537 - val_precision: 0.8007 - val_recall: 0.6378\n",
            "Epoch 9/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9495 - precision: 0.8154 - recall: 0.6515 - val_loss: 0.9545 - val_precision: 0.7935 - val_recall: 0.6363\n",
            "Epoch 10/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9481 - precision: 0.8157 - recall: 0.6596 - val_loss: 0.9589 - val_precision: 0.7730 - val_recall: 0.6333\n",
            "Epoch 11/25\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9461 - precision: 0.8156 - recall: 0.6700 - val_loss: 0.9545 - val_precision: 0.7762 - val_recall: 0.6481\n",
            "Epoch 12/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9456 - precision: 0.8097 - recall: 0.6775 - val_loss: 0.9543 - val_precision: 0.7734 - val_recall: 0.6512\n",
            "Epoch 13/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9445 - precision: 0.8071 - recall: 0.6855 - val_loss: 0.9518 - val_precision: 0.7757 - val_recall: 0.6622\n",
            "Epoch 14/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9437 - precision: 0.8064 - recall: 0.6897 - val_loss: 0.9519 - val_precision: 0.7733 - val_recall: 0.6685\n",
            "Epoch 15/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9430 - precision: 0.8053 - recall: 0.6945 - val_loss: 0.9536 - val_precision: 0.7663 - val_recall: 0.6668\n",
            "Epoch 16/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9425 - precision: 0.8043 - recall: 0.6974 - val_loss: 0.9577 - val_precision: 0.7556 - val_recall: 0.6604\n",
            "Epoch 17/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9426 - precision: 0.8032 - recall: 0.6990 - val_loss: 0.9663 - val_precision: 0.7343 - val_recall: 0.6415\n",
            "Epoch 18/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9432 - precision: 0.8046 - recall: 0.6963 - val_loss: 0.9556 - val_precision: 0.7601 - val_recall: 0.6640\n",
            "Epoch 19/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9409 - precision: 0.8047 - recall: 0.7074 - val_loss: 0.9639 - val_precision: 0.7451 - val_recall: 0.6557\n",
            "Epoch 20/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9410 - precision: 0.8055 - recall: 0.7087 - val_loss: 0.9572 - val_precision: 0.7638 - val_recall: 0.6721\n",
            "Epoch 21/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9391 - precision: 0.8093 - recall: 0.7188 - val_loss: 0.9524 - val_precision: 0.7740 - val_recall: 0.6908\n",
            "Epoch 22/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9380 - precision: 0.8099 - recall: 0.7247 - val_loss: 0.9538 - val_precision: 0.7698 - val_recall: 0.6867\n",
            "Epoch 23/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9381 - precision: 0.8105 - recall: 0.7243 - val_loss: 0.9561 - val_precision: 0.7671 - val_recall: 0.6802\n",
            "Epoch 24/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9379 - precision: 0.8117 - recall: 0.7254 - val_loss: 0.9564 - val_precision: 0.7670 - val_recall: 0.6807\n",
            "Epoch 25/25\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9362 - precision: 0.8163 - recall: 0.7308 - val_loss: 0.9512 - val_precision: 0.7744 - val_recall: 0.6954\n",
            "Config Space:\n",
            " {'batch_size': 28, 'learning_rate': 0.061566996059290544, 'optimizer': 'sgd', 'sgd_momentum': 0.9387601099445818}\n",
            "Epoch 1/75\n",
            "38/38 [==============================] - 6s 98ms/step - loss: 1.0073 - precision: 0.7474 - recall: 0.2977 - val_loss: 0.9967 - val_precision: 0.8230 - val_recall: 0.4507\n",
            "Epoch 2/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9934 - precision: 0.8117 - recall: 0.4399 - val_loss: 0.9895 - val_precision: 0.8253 - val_recall: 0.4539\n",
            "Epoch 3/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9874 - precision: 0.8239 - recall: 0.4446 - val_loss: 0.9852 - val_precision: 0.8249 - val_recall: 0.4566\n",
            "Epoch 4/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9831 - precision: 0.8291 - recall: 0.4443 - val_loss: 0.9819 - val_precision: 0.8276 - val_recall: 0.4564\n",
            "Epoch 5/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9793 - precision: 0.8322 - recall: 0.4433 - val_loss: 0.9783 - val_precision: 0.8549 - val_recall: 0.4360\n",
            "Epoch 6/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9744 - precision: 0.8405 - recall: 0.5092 - val_loss: 0.9752 - val_precision: 0.8678 - val_recall: 0.4871\n",
            "Epoch 7/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9688 - precision: 0.8390 - recall: 0.5338 - val_loss: 0.9770 - val_precision: 0.7748 - val_recall: 0.4872\n",
            "Epoch 8/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9650 - precision: 0.8282 - recall: 0.5485 - val_loss: 0.9772 - val_precision: 0.7000 - val_recall: 0.5341\n",
            "Epoch 9/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9625 - precision: 0.8198 - recall: 0.5656 - val_loss: 0.9786 - val_precision: 0.6741 - val_recall: 0.5620\n",
            "Epoch 10/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9588 - precision: 0.8239 - recall: 0.5817 - val_loss: 0.9733 - val_precision: 0.6885 - val_recall: 0.5864\n",
            "Epoch 11/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9535 - precision: 0.8090 - recall: 0.6337 - val_loss: 0.9685 - val_precision: 0.7167 - val_recall: 0.6076\n",
            "Epoch 12/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9488 - precision: 0.8076 - recall: 0.6651 - val_loss: 0.9651 - val_precision: 0.7417 - val_recall: 0.6214\n",
            "Epoch 13/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9465 - precision: 0.8158 - recall: 0.6717 - val_loss: 0.9587 - val_precision: 0.7673 - val_recall: 0.6384\n",
            "Epoch 14/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9457 - precision: 0.8148 - recall: 0.6772 - val_loss: 0.9559 - val_precision: 0.7780 - val_recall: 0.6471\n",
            "Epoch 15/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9454 - precision: 0.8130 - recall: 0.6795 - val_loss: 0.9530 - val_precision: 0.7819 - val_recall: 0.6559\n",
            "Epoch 16/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9446 - precision: 0.8119 - recall: 0.6854 - val_loss: 0.9551 - val_precision: 0.7743 - val_recall: 0.6582\n",
            "Epoch 17/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9435 - precision: 0.8113 - recall: 0.6911 - val_loss: 0.9527 - val_precision: 0.7703 - val_recall: 0.6686\n",
            "Epoch 18/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9430 - precision: 0.8075 - recall: 0.6965 - val_loss: 0.9509 - val_precision: 0.7833 - val_recall: 0.6736\n",
            "Epoch 19/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9424 - precision: 0.8072 - recall: 0.7008 - val_loss: 0.9505 - val_precision: 0.7808 - val_recall: 0.6782\n",
            "Epoch 20/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9416 - precision: 0.8069 - recall: 0.7060 - val_loss: 0.9495 - val_precision: 0.7814 - val_recall: 0.6841\n",
            "Epoch 21/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9409 - precision: 0.8059 - recall: 0.7109 - val_loss: 0.9493 - val_precision: 0.7831 - val_recall: 0.6873\n",
            "Epoch 22/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9405 - precision: 0.8052 - recall: 0.7147 - val_loss: 0.9501 - val_precision: 0.7823 - val_recall: 0.6886\n",
            "Epoch 23/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9399 - precision: 0.8046 - recall: 0.7187 - val_loss: 0.9481 - val_precision: 0.7856 - val_recall: 0.6937\n",
            "Epoch 24/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9391 - precision: 0.8059 - recall: 0.7224 - val_loss: 0.9482 - val_precision: 0.7793 - val_recall: 0.6945\n",
            "Epoch 25/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9382 - precision: 0.8075 - recall: 0.7270 - val_loss: 0.9463 - val_precision: 0.7761 - val_recall: 0.7012\n",
            "Epoch 26/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9374 - precision: 0.8070 - recall: 0.7318 - val_loss: 0.9476 - val_precision: 0.7791 - val_recall: 0.7069\n",
            "Epoch 27/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9373 - precision: 0.8105 - recall: 0.7308 - val_loss: 0.9488 - val_precision: 0.7658 - val_recall: 0.6910\n",
            "Epoch 28/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9361 - precision: 0.8099 - recall: 0.7373 - val_loss: 0.9397 - val_precision: 0.8009 - val_recall: 0.7246\n",
            "Epoch 29/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9353 - precision: 0.8137 - recall: 0.7388 - val_loss: 0.9423 - val_precision: 0.7955 - val_recall: 0.7224\n",
            "Epoch 30/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9354 - precision: 0.8134 - recall: 0.7383 - val_loss: 0.9515 - val_precision: 0.7799 - val_recall: 0.6988\n",
            "Epoch 31/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9357 - precision: 0.8158 - recall: 0.7376 - val_loss: 0.9434 - val_precision: 0.7830 - val_recall: 0.7179\n",
            "Epoch 32/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9334 - precision: 0.8170 - recall: 0.7470 - val_loss: 0.9452 - val_precision: 0.7881 - val_recall: 0.7159\n",
            "Epoch 33/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9330 - precision: 0.8197 - recall: 0.7479 - val_loss: 0.9407 - val_precision: 0.7941 - val_recall: 0.7350\n",
            "Epoch 34/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9314 - precision: 0.8229 - recall: 0.7545 - val_loss: 0.9435 - val_precision: 0.7859 - val_recall: 0.7286\n",
            "Epoch 35/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9308 - precision: 0.8233 - recall: 0.7557 - val_loss: 0.9432 - val_precision: 0.7885 - val_recall: 0.7295\n",
            "Epoch 36/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9300 - precision: 0.8246 - recall: 0.7586 - val_loss: 0.9425 - val_precision: 0.7907 - val_recall: 0.7338\n",
            "Epoch 37/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9292 - precision: 0.8258 - recall: 0.7625 - val_loss: 0.9400 - val_precision: 0.7945 - val_recall: 0.7406\n",
            "Epoch 38/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9280 - precision: 0.8279 - recall: 0.7672 - val_loss: 0.9409 - val_precision: 0.7924 - val_recall: 0.7383\n",
            "Epoch 39/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9269 - precision: 0.8296 - recall: 0.7707 - val_loss: 0.9325 - val_precision: 0.8121 - val_recall: 0.7613\n",
            "Epoch 40/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9250 - precision: 0.8339 - recall: 0.7769 - val_loss: 0.9446 - val_precision: 0.7838 - val_recall: 0.7273\n",
            "Epoch 41/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9285 - precision: 0.8255 - recall: 0.7638 - val_loss: 0.9344 - val_precision: 0.8117 - val_recall: 0.7580\n",
            "Epoch 42/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9248 - precision: 0.8361 - recall: 0.7800 - val_loss: 0.9369 - val_precision: 0.8014 - val_recall: 0.7467\n",
            "Epoch 43/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9256 - precision: 0.8323 - recall: 0.7748 - val_loss: 0.9358 - val_precision: 0.8061 - val_recall: 0.7439\n",
            "Epoch 44/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9228 - precision: 0.8387 - recall: 0.7833 - val_loss: 0.9316 - val_precision: 0.8140 - val_recall: 0.7650\n",
            "Epoch 45/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9224 - precision: 0.8394 - recall: 0.7858 - val_loss: 0.9299 - val_precision: 0.8155 - val_recall: 0.7716\n",
            "Epoch 46/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9216 - precision: 0.8407 - recall: 0.7878 - val_loss: 0.9300 - val_precision: 0.8129 - val_recall: 0.7705\n",
            "Epoch 47/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9215 - precision: 0.8407 - recall: 0.7884 - val_loss: 0.9306 - val_precision: 0.8122 - val_recall: 0.7701\n",
            "Epoch 48/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9224 - precision: 0.8378 - recall: 0.7845 - val_loss: 0.9244 - val_precision: 0.8325 - val_recall: 0.7921\n",
            "Epoch 49/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9205 - precision: 0.8434 - recall: 0.7916 - val_loss: 0.9297 - val_precision: 0.8131 - val_recall: 0.7696\n",
            "Epoch 50/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9214 - precision: 0.8403 - recall: 0.7877 - val_loss: 0.9260 - val_precision: 0.8259 - val_recall: 0.7882\n",
            "Epoch 51/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9207 - precision: 0.8422 - recall: 0.7915 - val_loss: 0.9283 - val_precision: 0.8192 - val_recall: 0.7755\n",
            "Epoch 52/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9221 - precision: 0.8378 - recall: 0.7858 - val_loss: 0.9281 - val_precision: 0.8213 - val_recall: 0.7839\n",
            "Epoch 53/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9206 - precision: 0.8428 - recall: 0.7917 - val_loss: 0.9327 - val_precision: 0.8048 - val_recall: 0.7576\n",
            "Epoch 54/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9216 - precision: 0.8396 - recall: 0.7868 - val_loss: 0.9375 - val_precision: 0.7968 - val_recall: 0.7548\n",
            "Epoch 55/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9237 - precision: 0.8328 - recall: 0.7801 - val_loss: 0.9263 - val_precision: 0.8240 - val_recall: 0.7790\n",
            "Epoch 56/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9223 - precision: 0.8390 - recall: 0.7874 - val_loss: 0.9272 - val_precision: 0.8228 - val_recall: 0.7749\n",
            "Epoch 57/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9192 - precision: 0.8441 - recall: 0.7964 - val_loss: 0.9321 - val_precision: 0.8124 - val_recall: 0.7694\n",
            "Epoch 58/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9194 - precision: 0.8443 - recall: 0.7960 - val_loss: 0.9295 - val_precision: 0.8173 - val_recall: 0.7732\n",
            "Epoch 59/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9187 - precision: 0.8463 - recall: 0.7995 - val_loss: 0.9346 - val_precision: 0.8019 - val_recall: 0.7631\n",
            "Epoch 60/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9212 - precision: 0.8402 - recall: 0.7914 - val_loss: 0.9342 - val_precision: 0.8085 - val_recall: 0.7633\n",
            "Epoch 61/75\n",
            "38/38 [==============================] - 3s 77ms/step - loss: 0.9195 - precision: 0.8434 - recall: 0.7964 - val_loss: 0.9307 - val_precision: 0.8172 - val_recall: 0.7719\n",
            "Epoch 62/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9185 - precision: 0.8457 - recall: 0.7982 - val_loss: 0.9303 - val_precision: 0.8159 - val_recall: 0.7733\n",
            "Epoch 63/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9175 - precision: 0.8483 - recall: 0.8018 - val_loss: 0.9299 - val_precision: 0.8159 - val_recall: 0.7750\n",
            "Epoch 64/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9175 - precision: 0.8475 - recall: 0.8022 - val_loss: 0.9323 - val_precision: 0.8102 - val_recall: 0.7694\n",
            "Epoch 65/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9178 - precision: 0.8469 - recall: 0.8013 - val_loss: 0.9295 - val_precision: 0.8155 - val_recall: 0.7772\n",
            "Epoch 66/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9172 - precision: 0.8480 - recall: 0.8026 - val_loss: 0.9292 - val_precision: 0.8176 - val_recall: 0.7782\n",
            "Epoch 67/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9166 - precision: 0.8493 - recall: 0.8044 - val_loss: 0.9284 - val_precision: 0.8202 - val_recall: 0.7813\n",
            "Epoch 68/75\n",
            "38/38 [==============================] - 3s 75ms/step - loss: 0.9164 - precision: 0.8499 - recall: 0.8051 - val_loss: 0.9306 - val_precision: 0.8159 - val_recall: 0.7768\n",
            "Epoch 69/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9168 - precision: 0.8490 - recall: 0.8034 - val_loss: 0.9290 - val_precision: 0.8190 - val_recall: 0.7800\n",
            "Epoch 70/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9157 - precision: 0.8517 - recall: 0.8073 - val_loss: 0.9282 - val_precision: 0.8196 - val_recall: 0.7824\n",
            "Epoch 71/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9158 - precision: 0.8513 - recall: 0.8070 - val_loss: 0.9303 - val_precision: 0.8162 - val_recall: 0.7782\n",
            "Epoch 72/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9158 - precision: 0.8511 - recall: 0.8063 - val_loss: 0.9296 - val_precision: 0.8182 - val_recall: 0.7798\n",
            "Epoch 73/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9156 - precision: 0.8516 - recall: 0.8070 - val_loss: 0.9273 - val_precision: 0.8230 - val_recall: 0.7860\n",
            "Epoch 74/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9149 - precision: 0.8536 - recall: 0.8099 - val_loss: 0.9267 - val_precision: 0.8255 - val_recall: 0.7874\n",
            "Epoch 75/75\n",
            "38/38 [==============================] - 3s 76ms/step - loss: 0.9148 - precision: 0.8535 - recall: 0.8100 - val_loss: 0.9287 - val_precision: 0.8206 - val_recall: 0.7839\n",
            "Config Space:\n",
            " {'batch_size': 24, 'learning_rate': 0.00012765657043279643, 'optimizer': 'adam', 'sgd_momentum': 0.06482325264227154}\n",
            "Epoch 1/75\n",
            "44/44 [==============================] - 6s 93ms/step - loss: 1.0139 - precision: 0.7402 - recall: 0.2233 - val_loss: 1.0062 - val_precision: 0.7811 - val_recall: 0.0973\n",
            "Epoch 2/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0014 - precision: 0.8050 - recall: 0.4121 - val_loss: 0.9976 - val_precision: 0.8758 - val_recall: 0.4203\n",
            "Epoch 3/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9947 - precision: 0.8963 - recall: 0.4150 - val_loss: 0.9930 - val_precision: 0.8755 - val_recall: 0.4486\n",
            "Epoch 4/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9924 - precision: 0.9053 - recall: 0.4266 - val_loss: 0.9917 - val_precision: 0.8936 - val_recall: 0.4416\n",
            "Epoch 5/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9910 - precision: 0.9107 - recall: 0.4282 - val_loss: 0.9908 - val_precision: 0.9037 - val_recall: 0.4359\n",
            "Epoch 6/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9875 - precision: 0.9071 - recall: 0.4327 - val_loss: 0.9851 - val_precision: 0.8715 - val_recall: 0.4609\n",
            "Epoch 7/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9728 - precision: 0.8703 - recall: 0.5096 - val_loss: 0.9746 - val_precision: 0.8485 - val_recall: 0.5362\n",
            "Epoch 8/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9632 - precision: 0.8810 - recall: 0.5522 - val_loss: 0.9699 - val_precision: 0.8533 - val_recall: 0.5462\n",
            "Epoch 9/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9611 - precision: 0.8694 - recall: 0.5811 - val_loss: 0.9676 - val_precision: 0.8715 - val_recall: 0.5323\n",
            "Epoch 10/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9590 - precision: 0.8644 - recall: 0.6026 - val_loss: 0.9661 - val_precision: 0.8698 - val_recall: 0.5438\n",
            "Epoch 11/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9576 - precision: 0.8618 - recall: 0.6137 - val_loss: 0.9647 - val_precision: 0.8670 - val_recall: 0.5532\n",
            "Epoch 12/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9555 - precision: 0.8563 - recall: 0.6273 - val_loss: 0.9634 - val_precision: 0.8532 - val_recall: 0.5705\n",
            "Epoch 13/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9531 - precision: 0.8467 - recall: 0.6481 - val_loss: 0.9615 - val_precision: 0.8408 - val_recall: 0.5839\n",
            "Epoch 14/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9500 - precision: 0.8431 - recall: 0.6712 - val_loss: 0.9576 - val_precision: 0.8283 - val_recall: 0.6313\n",
            "Epoch 15/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9469 - precision: 0.8434 - recall: 0.6892 - val_loss: 0.9542 - val_precision: 0.8218 - val_recall: 0.6571\n",
            "Epoch 16/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9459 - precision: 0.8449 - recall: 0.6919 - val_loss: 0.9542 - val_precision: 0.8090 - val_recall: 0.6606\n",
            "Epoch 17/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9451 - precision: 0.8468 - recall: 0.6925 - val_loss: 0.9634 - val_precision: 0.7588 - val_recall: 0.6332\n",
            "Epoch 18/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9431 - precision: 0.8486 - recall: 0.6983 - val_loss: 0.9578 - val_precision: 0.7876 - val_recall: 0.6474\n",
            "Epoch 19/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9416 - precision: 0.8507 - recall: 0.7015 - val_loss: 0.9568 - val_precision: 0.7960 - val_recall: 0.6415\n",
            "Epoch 20/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9404 - precision: 0.8513 - recall: 0.7054 - val_loss: 0.9578 - val_precision: 0.7934 - val_recall: 0.6360\n",
            "Epoch 21/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9397 - precision: 0.8521 - recall: 0.7052 - val_loss: 0.9595 - val_precision: 0.7854 - val_recall: 0.6362\n",
            "Epoch 22/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9387 - precision: 0.8531 - recall: 0.7070 - val_loss: 0.9568 - val_precision: 0.7969 - val_recall: 0.6500\n",
            "Epoch 23/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9368 - precision: 0.8561 - recall: 0.7117 - val_loss: 0.9577 - val_precision: 0.8004 - val_recall: 0.6547\n",
            "Epoch 24/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9344 - precision: 0.8565 - recall: 0.7192 - val_loss: 0.9572 - val_precision: 0.7893 - val_recall: 0.6712\n",
            "Epoch 25/75\n",
            "44/44 [==============================] - 3s 65ms/step - loss: 0.9347 - precision: 0.8447 - recall: 0.7258 - val_loss: 0.9620 - val_precision: 0.7710 - val_recall: 0.6687\n",
            "Epoch 26/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9308 - precision: 0.8405 - recall: 0.7505 - val_loss: 0.9616 - val_precision: 0.7653 - val_recall: 0.6736\n",
            "Epoch 27/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9280 - precision: 0.8422 - recall: 0.7639 - val_loss: 0.9631 - val_precision: 0.7516 - val_recall: 0.6733\n",
            "Epoch 28/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9265 - precision: 0.8416 - recall: 0.7721 - val_loss: 0.9740 - val_precision: 0.7257 - val_recall: 0.6595\n",
            "Epoch 29/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9263 - precision: 0.8413 - recall: 0.7733 - val_loss: 0.9704 - val_precision: 0.7232 - val_recall: 0.6596\n",
            "Epoch 30/75\n",
            "44/44 [==============================] - 3s 68ms/step - loss: 0.9250 - precision: 0.8446 - recall: 0.7782 - val_loss: 0.9678 - val_precision: 0.7321 - val_recall: 0.6672\n",
            "Epoch 31/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9229 - precision: 0.8473 - recall: 0.7850 - val_loss: 0.9600 - val_precision: 0.7487 - val_recall: 0.6901\n",
            "Epoch 32/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9213 - precision: 0.8505 - recall: 0.7909 - val_loss: 0.9652 - val_precision: 0.7278 - val_recall: 0.6745\n",
            "Epoch 33/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9202 - precision: 0.8524 - recall: 0.7952 - val_loss: 0.9638 - val_precision: 0.7321 - val_recall: 0.6781\n",
            "Epoch 34/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9192 - precision: 0.8540 - recall: 0.7984 - val_loss: 0.9644 - val_precision: 0.7283 - val_recall: 0.6758\n",
            "Epoch 35/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9179 - precision: 0.8567 - recall: 0.8023 - val_loss: 0.9643 - val_precision: 0.7289 - val_recall: 0.6809\n",
            "Epoch 36/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9169 - precision: 0.8580 - recall: 0.8064 - val_loss: 0.9661 - val_precision: 0.7290 - val_recall: 0.6836\n",
            "Epoch 37/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9164 - precision: 0.8585 - recall: 0.8080 - val_loss: 0.9737 - val_precision: 0.7080 - val_recall: 0.6675\n",
            "Epoch 38/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9154 - precision: 0.8609 - recall: 0.8113 - val_loss: 0.9733 - val_precision: 0.7124 - val_recall: 0.6728\n",
            "Epoch 39/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9147 - precision: 0.8623 - recall: 0.8139 - val_loss: 0.9782 - val_precision: 0.6990 - val_recall: 0.6647\n",
            "Epoch 40/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9140 - precision: 0.8636 - recall: 0.8157 - val_loss: 0.9697 - val_precision: 0.7251 - val_recall: 0.6869\n",
            "Epoch 41/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9136 - precision: 0.8640 - recall: 0.8183 - val_loss: 0.9781 - val_precision: 0.7016 - val_recall: 0.6670\n",
            "Epoch 42/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9129 - precision: 0.8655 - recall: 0.8203 - val_loss: 0.9673 - val_precision: 0.7303 - val_recall: 0.6917\n",
            "Epoch 43/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9121 - precision: 0.8672 - recall: 0.8238 - val_loss: 0.9743 - val_precision: 0.7149 - val_recall: 0.6792\n",
            "Epoch 44/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9116 - precision: 0.8681 - recall: 0.8250 - val_loss: 0.9742 - val_precision: 0.7187 - val_recall: 0.6841\n",
            "Epoch 45/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9108 - precision: 0.8694 - recall: 0.8278 - val_loss: 0.9765 - val_precision: 0.7165 - val_recall: 0.6831\n",
            "Epoch 46/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9105 - precision: 0.8702 - recall: 0.8288 - val_loss: 0.9724 - val_precision: 0.7288 - val_recall: 0.6946\n",
            "Epoch 47/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9101 - precision: 0.8705 - recall: 0.8297 - val_loss: 0.9736 - val_precision: 0.7251 - val_recall: 0.6937\n",
            "Epoch 48/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9112 - precision: 0.8686 - recall: 0.8267 - val_loss: 0.9650 - val_precision: 0.7395 - val_recall: 0.6997\n",
            "Epoch 49/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9095 - precision: 0.8718 - recall: 0.8314 - val_loss: 0.9720 - val_precision: 0.7288 - val_recall: 0.6940\n",
            "Epoch 50/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9092 - precision: 0.8721 - recall: 0.8332 - val_loss: 0.9701 - val_precision: 0.7336 - val_recall: 0.6947\n",
            "Epoch 51/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9092 - precision: 0.8721 - recall: 0.8329 - val_loss: 0.9661 - val_precision: 0.7401 - val_recall: 0.7001\n",
            "Epoch 52/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9089 - precision: 0.8725 - recall: 0.8330 - val_loss: 0.9687 - val_precision: 0.7403 - val_recall: 0.7049\n",
            "Epoch 53/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9075 - precision: 0.8758 - recall: 0.8382 - val_loss: 0.9684 - val_precision: 0.7290 - val_recall: 0.6914\n",
            "Epoch 54/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9074 - precision: 0.8758 - recall: 0.8381 - val_loss: 0.9711 - val_precision: 0.7271 - val_recall: 0.6880\n",
            "Epoch 55/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9068 - precision: 0.8775 - recall: 0.8399 - val_loss: 0.9749 - val_precision: 0.7223 - val_recall: 0.6818\n",
            "Epoch 56/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9063 - precision: 0.8781 - recall: 0.8407 - val_loss: 0.9723 - val_precision: 0.7272 - val_recall: 0.6876\n",
            "Epoch 57/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9065 - precision: 0.8775 - recall: 0.8396 - val_loss: 0.9809 - val_precision: 0.6995 - val_recall: 0.6597\n",
            "Epoch 58/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9057 - precision: 0.8795 - recall: 0.8418 - val_loss: 0.9732 - val_precision: 0.7216 - val_recall: 0.6834\n",
            "Epoch 59/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9053 - precision: 0.8792 - recall: 0.8416 - val_loss: 0.9739 - val_precision: 0.7257 - val_recall: 0.6836\n",
            "Epoch 60/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9047 - precision: 0.8790 - recall: 0.8428 - val_loss: 0.9790 - val_precision: 0.7176 - val_recall: 0.6765\n",
            "Epoch 61/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9059 - precision: 0.8757 - recall: 0.8390 - val_loss: 0.9743 - val_precision: 0.7225 - val_recall: 0.6844\n",
            "Epoch 62/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9046 - precision: 0.8769 - recall: 0.8422 - val_loss: 0.9604 - val_precision: 0.7536 - val_recall: 0.7204\n",
            "Epoch 63/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9034 - precision: 0.8774 - recall: 0.8444 - val_loss: 0.9738 - val_precision: 0.7247 - val_recall: 0.6921\n",
            "Epoch 64/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9033 - precision: 0.8756 - recall: 0.8443 - val_loss: 0.9632 - val_precision: 0.7480 - val_recall: 0.7154\n",
            "Epoch 65/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9024 - precision: 0.8763 - recall: 0.8465 - val_loss: 0.9572 - val_precision: 0.7637 - val_recall: 0.7334\n",
            "Epoch 66/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9026 - precision: 0.8748 - recall: 0.8464 - val_loss: 0.9522 - val_precision: 0.7753 - val_recall: 0.7435\n",
            "Epoch 67/75\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9013 - precision: 0.8768 - recall: 0.8487 - val_loss: 0.9570 - val_precision: 0.7667 - val_recall: 0.7364\n",
            "Epoch 68/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8997 - precision: 0.8771 - recall: 0.8511 - val_loss: 0.9586 - val_precision: 0.7541 - val_recall: 0.7266\n",
            "Epoch 69/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8987 - precision: 0.8775 - recall: 0.8521 - val_loss: 0.9637 - val_precision: 0.7429 - val_recall: 0.7181\n",
            "Epoch 70/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8994 - precision: 0.8765 - recall: 0.8502 - val_loss: 0.9622 - val_precision: 0.7558 - val_recall: 0.7289\n",
            "Epoch 71/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9000 - precision: 0.8752 - recall: 0.8494 - val_loss: 0.9508 - val_precision: 0.7747 - val_recall: 0.7472\n",
            "Epoch 72/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8975 - precision: 0.8793 - recall: 0.8553 - val_loss: 0.9614 - val_precision: 0.7527 - val_recall: 0.7254\n",
            "Epoch 73/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9005 - precision: 0.8734 - recall: 0.8479 - val_loss: 0.9577 - val_precision: 0.7563 - val_recall: 0.7280\n",
            "Epoch 74/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8968 - precision: 0.8788 - recall: 0.8540 - val_loss: 0.9630 - val_precision: 0.7388 - val_recall: 0.7110\n",
            "Epoch 75/75\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.8963 - precision: 0.8787 - recall: 0.8542 - val_loss: 0.9619 - val_precision: 0.7486 - val_recall: 0.7206\n",
            "Config Space:\n",
            " {'batch_size': 29, 'learning_rate': 0.000362997661710239, 'optimizer': 'adam', 'sgd_momentum': 0.980606513386686}\n",
            "Epoch 1/75\n",
            "36/36 [==============================] - 7s 105ms/step - loss: 1.0176 - precision: 0.7741 - recall: 0.1531 - val_loss: 1.0028 - val_precision: 0.8581 - val_recall: 0.4182\n",
            "Epoch 2/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 1.0015 - precision: 0.8142 - recall: 0.3949 - val_loss: 0.9979 - val_precision: 0.8502 - val_recall: 0.4388\n",
            "Epoch 3/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9939 - precision: 0.8615 - recall: 0.4138 - val_loss: 0.9886 - val_precision: 0.8619 - val_recall: 0.4602\n",
            "Epoch 4/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9852 - precision: 0.8820 - recall: 0.4440 - val_loss: 0.9746 - val_precision: 0.8692 - val_recall: 0.5235\n",
            "Epoch 5/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9673 - precision: 0.8691 - recall: 0.5478 - val_loss: 0.9628 - val_precision: 0.8660 - val_recall: 0.5833\n",
            "Epoch 6/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9595 - precision: 0.8527 - recall: 0.5902 - val_loss: 0.9598 - val_precision: 0.8460 - val_recall: 0.6116\n",
            "Epoch 7/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9538 - precision: 0.8353 - recall: 0.6298 - val_loss: 0.9576 - val_precision: 0.8146 - val_recall: 0.6304\n",
            "Epoch 8/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9478 - precision: 0.8213 - recall: 0.6767 - val_loss: 0.9560 - val_precision: 0.7582 - val_recall: 0.6523\n",
            "Epoch 9/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9429 - precision: 0.8191 - recall: 0.7092 - val_loss: 0.9504 - val_precision: 0.7639 - val_recall: 0.6851\n",
            "Epoch 10/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9391 - precision: 0.8188 - recall: 0.7314 - val_loss: 0.9478 - val_precision: 0.7563 - val_recall: 0.6979\n",
            "Epoch 11/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9359 - precision: 0.8218 - recall: 0.7469 - val_loss: 0.9489 - val_precision: 0.7486 - val_recall: 0.7057\n",
            "Epoch 12/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9324 - precision: 0.8251 - recall: 0.7605 - val_loss: 0.9420 - val_precision: 0.7763 - val_recall: 0.7301\n",
            "Epoch 13/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9302 - precision: 0.8305 - recall: 0.7681 - val_loss: 0.9408 - val_precision: 0.7846 - val_recall: 0.7406\n",
            "Epoch 14/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9282 - precision: 0.8349 - recall: 0.7744 - val_loss: 0.9480 - val_precision: 0.7607 - val_recall: 0.7139\n",
            "Epoch 15/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9263 - precision: 0.8390 - recall: 0.7803 - val_loss: 0.9471 - val_precision: 0.7661 - val_recall: 0.7100\n",
            "Epoch 16/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9254 - precision: 0.8410 - recall: 0.7816 - val_loss: 0.9412 - val_precision: 0.7838 - val_recall: 0.7322\n",
            "Epoch 17/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9228 - precision: 0.8468 - recall: 0.7918 - val_loss: 0.9427 - val_precision: 0.7867 - val_recall: 0.7221\n",
            "Epoch 18/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9214 - precision: 0.8497 - recall: 0.7952 - val_loss: 0.9483 - val_precision: 0.7673 - val_recall: 0.6993\n",
            "Epoch 19/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9201 - precision: 0.8506 - recall: 0.7997 - val_loss: 0.9496 - val_precision: 0.7680 - val_recall: 0.7039\n",
            "Epoch 20/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9177 - precision: 0.8559 - recall: 0.8075 - val_loss: 0.9456 - val_precision: 0.7792 - val_recall: 0.7249\n",
            "Epoch 21/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9158 - precision: 0.8587 - recall: 0.8144 - val_loss: 0.9385 - val_precision: 0.7923 - val_recall: 0.7440\n",
            "Epoch 22/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9140 - precision: 0.8622 - recall: 0.8202 - val_loss: 0.9383 - val_precision: 0.8005 - val_recall: 0.7567\n",
            "Epoch 23/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9125 - precision: 0.8650 - recall: 0.8258 - val_loss: 0.9352 - val_precision: 0.7990 - val_recall: 0.7604\n",
            "Epoch 24/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9110 - precision: 0.8681 - recall: 0.8303 - val_loss: 0.9341 - val_precision: 0.8072 - val_recall: 0.7687\n",
            "Epoch 25/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9104 - precision: 0.8685 - recall: 0.8318 - val_loss: 0.9327 - val_precision: 0.8063 - val_recall: 0.7703\n",
            "Epoch 26/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.9095 - precision: 0.8704 - recall: 0.8348 - val_loss: 0.9293 - val_precision: 0.8154 - val_recall: 0.7791\n",
            "Epoch 27/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9087 - precision: 0.8721 - recall: 0.8379 - val_loss: 0.9259 - val_precision: 0.8269 - val_recall: 0.7901\n",
            "Epoch 28/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9080 - precision: 0.8730 - recall: 0.8396 - val_loss: 0.9274 - val_precision: 0.8242 - val_recall: 0.7877\n",
            "Epoch 29/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9074 - precision: 0.8748 - recall: 0.8419 - val_loss: 0.9227 - val_precision: 0.8308 - val_recall: 0.7991\n",
            "Epoch 30/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9073 - precision: 0.8748 - recall: 0.8419 - val_loss: 0.9171 - val_precision: 0.8490 - val_recall: 0.8158\n",
            "Epoch 31/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9069 - precision: 0.8755 - recall: 0.8432 - val_loss: 0.9203 - val_precision: 0.8461 - val_recall: 0.8097\n",
            "Epoch 32/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9076 - precision: 0.8746 - recall: 0.8423 - val_loss: 0.9224 - val_precision: 0.8372 - val_recall: 0.8021\n",
            "Epoch 33/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9128 - precision: 0.8644 - recall: 0.8248 - val_loss: 0.9323 - val_precision: 0.8090 - val_recall: 0.7577\n",
            "Epoch 34/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9090 - precision: 0.8726 - recall: 0.8372 - val_loss: 0.9225 - val_precision: 0.8335 - val_recall: 0.7946\n",
            "Epoch 35/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9046 - precision: 0.8810 - recall: 0.8511 - val_loss: 0.9235 - val_precision: 0.8329 - val_recall: 0.8026\n",
            "Epoch 36/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9037 - precision: 0.8821 - recall: 0.8541 - val_loss: 0.9230 - val_precision: 0.8343 - val_recall: 0.8059\n",
            "Epoch 37/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9028 - precision: 0.8845 - recall: 0.8562 - val_loss: 0.9254 - val_precision: 0.8264 - val_recall: 0.8008\n",
            "Epoch 38/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9024 - precision: 0.8852 - recall: 0.8581 - val_loss: 0.9237 - val_precision: 0.8287 - val_recall: 0.7991\n",
            "Epoch 39/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9019 - precision: 0.8867 - recall: 0.8577 - val_loss: 0.9207 - val_precision: 0.8404 - val_recall: 0.8108\n",
            "Epoch 40/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9047 - precision: 0.8805 - recall: 0.8494 - val_loss: 0.9243 - val_precision: 0.8322 - val_recall: 0.7933\n",
            "Epoch 41/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.9015 - precision: 0.8862 - recall: 0.8567 - val_loss: 0.9229 - val_precision: 0.8395 - val_recall: 0.8077\n",
            "Epoch 42/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8995 - precision: 0.8899 - recall: 0.8619 - val_loss: 0.9219 - val_precision: 0.8421 - val_recall: 0.8113\n",
            "Epoch 43/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8984 - precision: 0.8894 - recall: 0.8635 - val_loss: 0.9197 - val_precision: 0.8470 - val_recall: 0.8194\n",
            "Epoch 44/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8980 - precision: 0.8874 - recall: 0.8632 - val_loss: 0.9171 - val_precision: 0.8479 - val_recall: 0.8231\n",
            "Epoch 45/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8968 - precision: 0.8862 - recall: 0.8647 - val_loss: 0.9196 - val_precision: 0.8404 - val_recall: 0.8166\n",
            "Epoch 46/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8980 - precision: 0.8835 - recall: 0.8617 - val_loss: 0.9148 - val_precision: 0.8476 - val_recall: 0.8226\n",
            "Epoch 47/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8966 - precision: 0.8838 - recall: 0.8621 - val_loss: 0.9173 - val_precision: 0.8415 - val_recall: 0.8188\n",
            "Epoch 48/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.9006 - precision: 0.8739 - recall: 0.8469 - val_loss: 0.9216 - val_precision: 0.8251 - val_recall: 0.7987\n",
            "Epoch 49/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8964 - precision: 0.8806 - recall: 0.8589 - val_loss: 0.9183 - val_precision: 0.8446 - val_recall: 0.8217\n",
            "Epoch 50/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8937 - precision: 0.8844 - recall: 0.8642 - val_loss: 0.9201 - val_precision: 0.8400 - val_recall: 0.8136\n",
            "Epoch 51/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8950 - precision: 0.8823 - recall: 0.8599 - val_loss: 0.9214 - val_precision: 0.8329 - val_recall: 0.8055\n",
            "Epoch 52/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8947 - precision: 0.8844 - recall: 0.8646 - val_loss: 0.9198 - val_precision: 0.8350 - val_recall: 0.8109\n",
            "Epoch 53/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8932 - precision: 0.8843 - recall: 0.8621 - val_loss: 0.9207 - val_precision: 0.8380 - val_recall: 0.8143\n",
            "Epoch 54/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8894 - precision: 0.8886 - recall: 0.8692 - val_loss: 0.9227 - val_precision: 0.8375 - val_recall: 0.8161\n",
            "Epoch 55/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8899 - precision: 0.8875 - recall: 0.8666 - val_loss: 0.9185 - val_precision: 0.8391 - val_recall: 0.8150\n",
            "Epoch 56/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8874 - precision: 0.8891 - recall: 0.8699 - val_loss: 0.9218 - val_precision: 0.8402 - val_recall: 0.8181\n",
            "Epoch 57/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8847 - precision: 0.8932 - recall: 0.8758 - val_loss: 0.9217 - val_precision: 0.8392 - val_recall: 0.8181\n",
            "Epoch 58/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8853 - precision: 0.8926 - recall: 0.8751 - val_loss: 0.9232 - val_precision: 0.8360 - val_recall: 0.8158\n",
            "Epoch 59/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8842 - precision: 0.8949 - recall: 0.8784 - val_loss: 0.9219 - val_precision: 0.8343 - val_recall: 0.8136\n",
            "Epoch 60/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8848 - precision: 0.8934 - recall: 0.8762 - val_loss: 0.9302 - val_precision: 0.8186 - val_recall: 0.7921\n",
            "Epoch 61/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8823 - precision: 0.8971 - recall: 0.8817 - val_loss: 0.9319 - val_precision: 0.8254 - val_recall: 0.8041\n",
            "Epoch 62/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8810 - precision: 0.9007 - recall: 0.8865 - val_loss: 0.9262 - val_precision: 0.8345 - val_recall: 0.8165\n",
            "Epoch 63/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8802 - precision: 0.9001 - recall: 0.8860 - val_loss: 0.9297 - val_precision: 0.8270 - val_recall: 0.8088\n",
            "Epoch 64/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8787 - precision: 0.9016 - recall: 0.8879 - val_loss: 0.9324 - val_precision: 0.8223 - val_recall: 0.8045\n",
            "Epoch 65/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8777 - precision: 0.9040 - recall: 0.8907 - val_loss: 0.9370 - val_precision: 0.8168 - val_recall: 0.8011\n",
            "Epoch 66/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8770 - precision: 0.9049 - recall: 0.8919 - val_loss: 0.9267 - val_precision: 0.8308 - val_recall: 0.8148\n",
            "Epoch 67/75\n",
            "36/36 [==============================] - 3s 82ms/step - loss: 0.8758 - precision: 0.9073 - recall: 0.8953 - val_loss: 0.9233 - val_precision: 0.8332 - val_recall: 0.8178\n",
            "Epoch 68/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8759 - precision: 0.9070 - recall: 0.8951 - val_loss: 0.9305 - val_precision: 0.8245 - val_recall: 0.8097\n",
            "Epoch 69/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8759 - precision: 0.9079 - recall: 0.8960 - val_loss: 0.9267 - val_precision: 0.8301 - val_recall: 0.8168\n",
            "Epoch 70/75\n",
            "36/36 [==============================] - 3s 83ms/step - loss: 0.8748 - precision: 0.9098 - recall: 0.8984 - val_loss: 0.9241 - val_precision: 0.8314 - val_recall: 0.8185\n",
            "Epoch 71/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8744 - precision: 0.9102 - recall: 0.8993 - val_loss: 0.9268 - val_precision: 0.8289 - val_recall: 0.8163\n",
            "Epoch 72/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8746 - precision: 0.9097 - recall: 0.8989 - val_loss: 0.9328 - val_precision: 0.8146 - val_recall: 0.8003\n",
            "Epoch 73/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8744 - precision: 0.9105 - recall: 0.8994 - val_loss: 0.9347 - val_precision: 0.8151 - val_recall: 0.8023\n",
            "Epoch 74/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8731 - precision: 0.9124 - recall: 0.9017 - val_loss: 0.9221 - val_precision: 0.8371 - val_recall: 0.8249\n",
            "Epoch 75/75\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.8727 - precision: 0.9134 - recall: 0.9030 - val_loss: 0.9247 - val_precision: 0.8294 - val_recall: 0.8178\n",
            "Config Space:\n",
            " {'batch_size': 27, 'learning_rate': 0.000559449566703158, 'optimizer': 'adam', 'sgd_momentum': 0.8351797515182519}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/nonparametric/kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "39/39 [==============================] - 8s 118ms/step - loss: 1.0004 - precision: 0.7910 - recall: 0.3795 - val_loss: 0.9923 - val_precision: 0.8003 - val_recall: 0.4781\n",
            "Epoch 2/25\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9859 - precision: 0.8750 - recall: 0.4494 - val_loss: 0.9858 - val_precision: 0.7988 - val_recall: 0.5003\n",
            "Epoch 3/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9726 - precision: 0.8453 - recall: 0.5307 - val_loss: 0.9679 - val_precision: 0.8196 - val_recall: 0.5908\n",
            "Epoch 4/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9574 - precision: 0.8515 - recall: 0.6197 - val_loss: 0.9674 - val_precision: 0.8126 - val_recall: 0.5927\n",
            "Epoch 5/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9528 - precision: 0.8528 - recall: 0.6326 - val_loss: 0.9639 - val_precision: 0.8277 - val_recall: 0.5997\n",
            "Epoch 6/25\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9487 - precision: 0.8430 - recall: 0.6533 - val_loss: 0.9581 - val_precision: 0.8134 - val_recall: 0.6224\n",
            "Epoch 7/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9434 - precision: 0.8221 - recall: 0.7030 - val_loss: 0.9498 - val_precision: 0.8050 - val_recall: 0.6862\n",
            "Epoch 8/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9374 - precision: 0.8247 - recall: 0.7333 - val_loss: 0.9432 - val_precision: 0.7944 - val_recall: 0.7204\n",
            "Epoch 9/25\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.9336 - precision: 0.8268 - recall: 0.7503 - val_loss: 0.9389 - val_precision: 0.8040 - val_recall: 0.7344\n",
            "Epoch 10/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9311 - precision: 0.8283 - recall: 0.7601 - val_loss: 0.9430 - val_precision: 0.7910 - val_recall: 0.7264\n",
            "Epoch 11/25\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.9276 - precision: 0.8335 - recall: 0.7739 - val_loss: 0.9365 - val_precision: 0.8086 - val_recall: 0.7477\n",
            "Epoch 12/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9255 - precision: 0.8371 - recall: 0.7814 - val_loss: 0.9393 - val_precision: 0.7941 - val_recall: 0.7403\n",
            "Epoch 13/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9236 - precision: 0.8398 - recall: 0.7889 - val_loss: 0.9374 - val_precision: 0.7996 - val_recall: 0.7496\n",
            "Epoch 14/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9219 - precision: 0.8433 - recall: 0.7936 - val_loss: 0.9347 - val_precision: 0.8028 - val_recall: 0.7578\n",
            "Epoch 15/25\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9209 - precision: 0.8446 - recall: 0.7967 - val_loss: 0.9373 - val_precision: 0.7926 - val_recall: 0.7508\n",
            "Epoch 16/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9200 - precision: 0.8470 - recall: 0.7977 - val_loss: 0.9345 - val_precision: 0.8037 - val_recall: 0.7582\n",
            "Epoch 17/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9174 - precision: 0.8521 - recall: 0.8069 - val_loss: 0.9328 - val_precision: 0.8072 - val_recall: 0.7656\n",
            "Epoch 18/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9148 - precision: 0.8575 - recall: 0.8159 - val_loss: 0.9282 - val_precision: 0.8175 - val_recall: 0.7807\n",
            "Epoch 19/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9135 - precision: 0.8610 - recall: 0.8204 - val_loss: 0.9314 - val_precision: 0.8118 - val_recall: 0.7755\n",
            "Epoch 20/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9130 - precision: 0.8618 - recall: 0.8224 - val_loss: 0.9318 - val_precision: 0.8141 - val_recall: 0.7733\n",
            "Epoch 21/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9138 - precision: 0.8593 - recall: 0.8190 - val_loss: 0.9310 - val_precision: 0.8178 - val_recall: 0.7794\n",
            "Epoch 22/25\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9111 - precision: 0.8647 - recall: 0.8279 - val_loss: 0.9333 - val_precision: 0.8095 - val_recall: 0.7742\n",
            "Epoch 23/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9098 - precision: 0.8680 - recall: 0.8321 - val_loss: 0.9288 - val_precision: 0.8231 - val_recall: 0.7861\n",
            "Epoch 24/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9085 - precision: 0.8701 - recall: 0.8350 - val_loss: 0.9320 - val_precision: 0.8158 - val_recall: 0.7808\n",
            "Epoch 25/25\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9087 - precision: 0.8700 - recall: 0.8343 - val_loss: 0.9307 - val_precision: 0.8155 - val_recall: 0.7799\n",
            "Config Space:\n",
            " {'batch_size': 30, 'learning_rate': 0.00020648284618882698, 'optimizer': 'sgd', 'sgd_momentum': 0.15901342208840763}\n",
            "Epoch 1/25\n",
            "35/35 [==============================] - 6s 106ms/step - loss: 1.0242 - precision: 0.7657 - recall: 0.0019 - val_loss: 1.0261 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0241 - precision: 0.7714 - recall: 0.0020 - val_loss: 1.0260 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/25\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0240 - precision: 0.7757 - recall: 0.0021 - val_loss: 1.0258 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0238 - precision: 0.7806 - recall: 0.0022 - val_loss: 1.0257 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0237 - precision: 0.7850 - recall: 0.0022 - val_loss: 1.0255 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0236 - precision: 0.7895 - recall: 0.0023 - val_loss: 1.0254 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0234 - precision: 0.7934 - recall: 0.0024 - val_loss: 1.0252 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0233 - precision: 0.7977 - recall: 0.0025 - val_loss: 1.0251 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0232 - precision: 0.7995 - recall: 0.0026 - val_loss: 1.0249 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0231 - precision: 0.8043 - recall: 0.0027 - val_loss: 1.0248 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0229 - precision: 0.8063 - recall: 0.0028 - val_loss: 1.0246 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0228 - precision: 0.8105 - recall: 0.0029 - val_loss: 1.0245 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/25\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0227 - precision: 0.8120 - recall: 0.0030 - val_loss: 1.0244 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0226 - precision: 0.8141 - recall: 0.0031 - val_loss: 1.0242 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0224 - precision: 0.8188 - recall: 0.0032 - val_loss: 1.0241 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0223 - precision: 0.8202 - recall: 0.0034 - val_loss: 1.0239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/25\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 1.0222 - precision: 0.8234 - recall: 0.0035 - val_loss: 1.0238 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0221 - precision: 0.8279 - recall: 0.0036 - val_loss: 1.0236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0219 - precision: 0.8280 - recall: 0.0037 - val_loss: 1.0235 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0218 - precision: 0.8299 - recall: 0.0039 - val_loss: 1.0233 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0217 - precision: 0.8318 - recall: 0.0040 - val_loss: 1.0232 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0216 - precision: 0.8329 - recall: 0.0042 - val_loss: 1.0230 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0214 - precision: 0.8349 - recall: 0.0043 - val_loss: 1.0229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/25\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 1.0213 - precision: 0.8366 - recall: 0.0045 - val_loss: 1.0227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/25\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0212 - precision: 0.8392 - recall: 0.0047 - val_loss: 1.0226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Config Space:\n",
            " {'batch_size': 24, 'learning_rate': 0.02619168430040626, 'optimizer': 'sgd', 'sgd_momentum': 0.08896231525961767}\n",
            "Epoch 1/25\n",
            "44/44 [==============================] - 6s 85ms/step - loss: 1.0288 - precision: 0.0422 - recall: 1.7697e-04 - val_loss: 1.0229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0181 - precision: 0.6833 - recall: 0.0030 - val_loss: 1.0113 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0092 - precision: 0.8372 - recall: 0.1097 - val_loss: 1.0039 - val_precision: 0.8899 - val_recall: 0.3084\n",
            "Epoch 4/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 1.0052 - precision: 0.8316 - recall: 0.2841 - val_loss: 1.0018 - val_precision: 0.8548 - val_recall: 0.4143\n",
            "Epoch 5/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0034 - precision: 0.8238 - recall: 0.3442 - val_loss: 1.0006 - val_precision: 0.8442 - val_recall: 0.4275\n",
            "Epoch 6/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0021 - precision: 0.8214 - recall: 0.3660 - val_loss: 0.9995 - val_precision: 0.8407 - val_recall: 0.4317\n",
            "Epoch 7/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0010 - precision: 0.8203 - recall: 0.3782 - val_loss: 0.9987 - val_precision: 0.8389 - val_recall: 0.4341\n",
            "Epoch 8/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 1.0001 - precision: 0.8200 - recall: 0.3867 - val_loss: 0.9979 - val_precision: 0.8375 - val_recall: 0.4358\n",
            "Epoch 9/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9993 - precision: 0.8197 - recall: 0.3932 - val_loss: 0.9972 - val_precision: 0.8364 - val_recall: 0.4373\n",
            "Epoch 10/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9986 - precision: 0.8198 - recall: 0.3983 - val_loss: 0.9966 - val_precision: 0.8355 - val_recall: 0.4385\n",
            "Epoch 11/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9979 - precision: 0.8200 - recall: 0.4028 - val_loss: 0.9960 - val_precision: 0.8345 - val_recall: 0.4397\n",
            "Epoch 12/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9973 - precision: 0.8204 - recall: 0.4066 - val_loss: 0.9955 - val_precision: 0.8337 - val_recall: 0.4408\n",
            "Epoch 13/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9967 - precision: 0.8207 - recall: 0.4099 - val_loss: 0.9950 - val_precision: 0.8331 - val_recall: 0.4417\n",
            "Epoch 14/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9961 - precision: 0.8212 - recall: 0.4127 - val_loss: 0.9945 - val_precision: 0.8324 - val_recall: 0.4425\n",
            "Epoch 15/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9955 - precision: 0.8217 - recall: 0.4154 - val_loss: 0.9940 - val_precision: 0.8319 - val_recall: 0.4433\n",
            "Epoch 16/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9950 - precision: 0.8222 - recall: 0.4178 - val_loss: 0.9936 - val_precision: 0.8314 - val_recall: 0.4439\n",
            "Epoch 17/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9945 - precision: 0.8228 - recall: 0.4200 - val_loss: 0.9932 - val_precision: 0.8310 - val_recall: 0.4445\n",
            "Epoch 18/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9940 - precision: 0.8233 - recall: 0.4218 - val_loss: 0.9927 - val_precision: 0.8307 - val_recall: 0.4451\n",
            "Epoch 19/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9935 - precision: 0.8239 - recall: 0.4237 - val_loss: 0.9923 - val_precision: 0.8304 - val_recall: 0.4456\n",
            "Epoch 20/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9930 - precision: 0.8244 - recall: 0.4252 - val_loss: 0.9919 - val_precision: 0.8301 - val_recall: 0.4461\n",
            "Epoch 21/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9926 - precision: 0.8250 - recall: 0.4267 - val_loss: 0.9915 - val_precision: 0.8298 - val_recall: 0.4466\n",
            "Epoch 22/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9921 - precision: 0.8255 - recall: 0.4280 - val_loss: 0.9911 - val_precision: 0.8297 - val_recall: 0.4471\n",
            "Epoch 23/25\n",
            "44/44 [==============================] - 3s 67ms/step - loss: 0.9917 - precision: 0.8260 - recall: 0.4292 - val_loss: 0.9907 - val_precision: 0.8295 - val_recall: 0.4475\n",
            "Epoch 24/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9913 - precision: 0.8265 - recall: 0.4303 - val_loss: 0.9904 - val_precision: 0.8294 - val_recall: 0.4479\n",
            "Epoch 25/25\n",
            "44/44 [==============================] - 3s 66ms/step - loss: 0.9909 - precision: 0.8269 - recall: 0.4313 - val_loss: 0.9900 - val_precision: 0.8293 - val_recall: 0.4482\n",
            "Config Space:\n",
            " {'batch_size': 27, 'learning_rate': 0.000559449566703158, 'optimizer': 'adam', 'sgd_momentum': 0.8351797515182519}\n",
            "Epoch 1/75\n",
            "39/39 [==============================] - 6s 96ms/step - loss: 1.0049 - precision: 0.7770 - recall: 0.3291 - val_loss: 0.9957 - val_precision: 0.8246 - val_recall: 0.4535\n",
            "Epoch 2/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9924 - precision: 0.8468 - recall: 0.4306 - val_loss: 0.9815 - val_precision: 0.8197 - val_recall: 0.5279\n",
            "Epoch 3/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9729 - precision: 0.8651 - recall: 0.5159 - val_loss: 0.9708 - val_precision: 0.8337 - val_recall: 0.5536\n",
            "Epoch 4/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9633 - precision: 0.8734 - recall: 0.5505 - val_loss: 0.9695 - val_precision: 0.8027 - val_recall: 0.5745\n",
            "Epoch 5/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9581 - precision: 0.8405 - recall: 0.6019 - val_loss: 0.9644 - val_precision: 0.8027 - val_recall: 0.5801\n",
            "Epoch 6/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9521 - precision: 0.8318 - recall: 0.6605 - val_loss: 0.9609 - val_precision: 0.7678 - val_recall: 0.6430\n",
            "Epoch 7/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9483 - precision: 0.8353 - recall: 0.6799 - val_loss: 0.9601 - val_precision: 0.7663 - val_recall: 0.6473\n",
            "Epoch 8/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9443 - precision: 0.8377 - recall: 0.6905 - val_loss: 0.9575 - val_precision: 0.7609 - val_recall: 0.6714\n",
            "Epoch 9/75\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.9390 - precision: 0.8219 - recall: 0.7324 - val_loss: 0.9583 - val_precision: 0.7387 - val_recall: 0.6775\n",
            "Epoch 10/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9364 - precision: 0.8231 - recall: 0.7436 - val_loss: 0.9609 - val_precision: 0.7289 - val_recall: 0.6722\n",
            "Epoch 11/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9331 - precision: 0.8266 - recall: 0.7551 - val_loss: 0.9600 - val_precision: 0.7234 - val_recall: 0.6743\n",
            "Epoch 12/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9311 - precision: 0.8296 - recall: 0.7639 - val_loss: 0.9578 - val_precision: 0.7282 - val_recall: 0.6828\n",
            "Epoch 13/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9274 - precision: 0.8349 - recall: 0.7754 - val_loss: 0.9534 - val_precision: 0.7501 - val_recall: 0.7071\n",
            "Epoch 14/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9252 - precision: 0.8388 - recall: 0.7819 - val_loss: 0.9479 - val_precision: 0.7671 - val_recall: 0.7251\n",
            "Epoch 15/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9246 - precision: 0.8399 - recall: 0.7830 - val_loss: 0.9527 - val_precision: 0.7572 - val_recall: 0.7138\n",
            "Epoch 16/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9236 - precision: 0.8408 - recall: 0.7865 - val_loss: 0.9479 - val_precision: 0.7674 - val_recall: 0.7278\n",
            "Epoch 17/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9214 - precision: 0.8455 - recall: 0.7942 - val_loss: 0.9431 - val_precision: 0.7851 - val_recall: 0.7507\n",
            "Epoch 18/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9215 - precision: 0.8441 - recall: 0.7940 - val_loss: 0.9414 - val_precision: 0.7824 - val_recall: 0.7413\n",
            "Epoch 19/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9184 - precision: 0.8509 - recall: 0.8037 - val_loss: 0.9443 - val_precision: 0.7781 - val_recall: 0.7420\n",
            "Epoch 20/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9163 - precision: 0.8543 - recall: 0.8100 - val_loss: 0.9408 - val_precision: 0.7870 - val_recall: 0.7508\n",
            "Epoch 21/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9145 - precision: 0.8583 - recall: 0.8156 - val_loss: 0.9399 - val_precision: 0.7893 - val_recall: 0.7549\n",
            "Epoch 22/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9135 - precision: 0.8603 - recall: 0.8182 - val_loss: 0.9370 - val_precision: 0.7981 - val_recall: 0.7628\n",
            "Epoch 23/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9124 - precision: 0.8628 - recall: 0.8223 - val_loss: 0.9395 - val_precision: 0.7915 - val_recall: 0.7582\n",
            "Epoch 24/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9120 - precision: 0.8632 - recall: 0.8232 - val_loss: 0.9392 - val_precision: 0.7901 - val_recall: 0.7569\n",
            "Epoch 25/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9114 - precision: 0.8645 - recall: 0.8251 - val_loss: 0.9385 - val_precision: 0.7926 - val_recall: 0.7614\n",
            "Epoch 26/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9113 - precision: 0.8650 - recall: 0.8266 - val_loss: 0.9410 - val_precision: 0.7852 - val_recall: 0.7530\n",
            "Epoch 27/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9104 - precision: 0.8663 - recall: 0.8292 - val_loss: 0.9354 - val_precision: 0.8010 - val_recall: 0.7669\n",
            "Epoch 28/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9098 - precision: 0.8674 - recall: 0.8304 - val_loss: 0.9381 - val_precision: 0.7965 - val_recall: 0.7652\n",
            "Epoch 29/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9100 - precision: 0.8675 - recall: 0.8299 - val_loss: 0.9445 - val_precision: 0.7851 - val_recall: 0.7524\n",
            "Epoch 30/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9089 - precision: 0.8696 - recall: 0.8333 - val_loss: 0.9444 - val_precision: 0.7815 - val_recall: 0.7512\n",
            "Epoch 31/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9074 - precision: 0.8728 - recall: 0.8377 - val_loss: 0.9489 - val_precision: 0.7772 - val_recall: 0.7477\n",
            "Epoch 32/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9079 - precision: 0.8724 - recall: 0.8373 - val_loss: 0.9420 - val_precision: 0.7881 - val_recall: 0.7593\n",
            "Epoch 33/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9054 - precision: 0.8779 - recall: 0.8447 - val_loss: 0.9426 - val_precision: 0.7882 - val_recall: 0.7615\n",
            "Epoch 34/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9051 - precision: 0.8782 - recall: 0.8453 - val_loss: 0.9401 - val_precision: 0.7932 - val_recall: 0.7638\n",
            "Epoch 35/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9041 - precision: 0.8805 - recall: 0.8466 - val_loss: 0.9424 - val_precision: 0.7889 - val_recall: 0.7616\n",
            "Epoch 36/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9038 - precision: 0.8806 - recall: 0.8466 - val_loss: 0.9384 - val_precision: 0.7980 - val_recall: 0.7724\n",
            "Epoch 37/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9031 - precision: 0.8804 - recall: 0.8501 - val_loss: 0.9327 - val_precision: 0.8075 - val_recall: 0.7784\n",
            "Epoch 38/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9021 - precision: 0.8815 - recall: 0.8529 - val_loss: 0.9303 - val_precision: 0.8166 - val_recall: 0.7904\n",
            "Epoch 39/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9012 - precision: 0.8800 - recall: 0.8542 - val_loss: 0.9285 - val_precision: 0.8205 - val_recall: 0.7957\n",
            "Epoch 40/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.9031 - precision: 0.8759 - recall: 0.8497 - val_loss: 0.9298 - val_precision: 0.8162 - val_recall: 0.7930\n",
            "Epoch 41/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9005 - precision: 0.8763 - recall: 0.8522 - val_loss: 0.9284 - val_precision: 0.8242 - val_recall: 0.7987\n",
            "Epoch 42/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9006 - precision: 0.8748 - recall: 0.8496 - val_loss: 0.9364 - val_precision: 0.8049 - val_recall: 0.7821\n",
            "Epoch 43/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9006 - precision: 0.8755 - recall: 0.8506 - val_loss: 0.9303 - val_precision: 0.8172 - val_recall: 0.7931\n",
            "Epoch 44/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8999 - precision: 0.8743 - recall: 0.8494 - val_loss: 0.9312 - val_precision: 0.8167 - val_recall: 0.7917\n",
            "Epoch 45/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8997 - precision: 0.8784 - recall: 0.8537 - val_loss: 0.9412 - val_precision: 0.7948 - val_recall: 0.7744\n",
            "Epoch 46/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.9002 - precision: 0.8767 - recall: 0.8513 - val_loss: 0.9330 - val_precision: 0.8046 - val_recall: 0.7776\n",
            "Epoch 47/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8971 - precision: 0.8809 - recall: 0.8578 - val_loss: 0.9304 - val_precision: 0.8109 - val_recall: 0.7866\n",
            "Epoch 48/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8958 - precision: 0.8829 - recall: 0.8612 - val_loss: 0.9320 - val_precision: 0.8086 - val_recall: 0.7856\n",
            "Epoch 49/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8949 - precision: 0.8832 - recall: 0.8606 - val_loss: 0.9270 - val_precision: 0.8199 - val_recall: 0.7958\n",
            "Epoch 50/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8928 - precision: 0.8853 - recall: 0.8640 - val_loss: 0.9379 - val_precision: 0.8007 - val_recall: 0.7779\n",
            "Epoch 51/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8942 - precision: 0.8862 - recall: 0.8655 - val_loss: 0.9198 - val_precision: 0.8338 - val_recall: 0.8106\n",
            "Epoch 52/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8961 - precision: 0.8813 - recall: 0.8585 - val_loss: 0.9259 - val_precision: 0.8207 - val_recall: 0.7977\n",
            "Epoch 53/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8919 - precision: 0.8872 - recall: 0.8673 - val_loss: 0.9208 - val_precision: 0.8306 - val_recall: 0.8113\n",
            "Epoch 54/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8941 - precision: 0.8834 - recall: 0.8616 - val_loss: 0.9280 - val_precision: 0.8177 - val_recall: 0.7934\n",
            "Epoch 55/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8917 - precision: 0.8861 - recall: 0.8668 - val_loss: 0.9164 - val_precision: 0.8408 - val_recall: 0.8190\n",
            "Epoch 56/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8894 - precision: 0.8912 - recall: 0.8731 - val_loss: 0.9171 - val_precision: 0.8423 - val_recall: 0.8240\n",
            "Epoch 57/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8870 - precision: 0.8933 - recall: 0.8762 - val_loss: 0.9179 - val_precision: 0.8410 - val_recall: 0.8219\n",
            "Epoch 58/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8859 - precision: 0.8962 - recall: 0.8800 - val_loss: 0.9168 - val_precision: 0.8453 - val_recall: 0.8274\n",
            "Epoch 59/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8844 - precision: 0.8980 - recall: 0.8823 - val_loss: 0.9164 - val_precision: 0.8465 - val_recall: 0.8297\n",
            "Epoch 60/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8827 - precision: 0.9003 - recall: 0.8852 - val_loss: 0.9171 - val_precision: 0.8469 - val_recall: 0.8319\n",
            "Epoch 61/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8847 - precision: 0.8974 - recall: 0.8822 - val_loss: 0.9166 - val_precision: 0.8474 - val_recall: 0.8300\n",
            "Epoch 62/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8843 - precision: 0.8987 - recall: 0.8831 - val_loss: 0.9178 - val_precision: 0.8399 - val_recall: 0.8244\n",
            "Epoch 63/75\n",
            "39/39 [==============================] - 3s 75ms/step - loss: 0.8840 - precision: 0.9000 - recall: 0.8855 - val_loss: 0.9262 - val_precision: 0.8249 - val_recall: 0.8110\n",
            "Epoch 64/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8874 - precision: 0.8918 - recall: 0.8748 - val_loss: 0.9192 - val_precision: 0.8419 - val_recall: 0.8260\n",
            "Epoch 65/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8832 - precision: 0.8998 - recall: 0.8855 - val_loss: 0.9164 - val_precision: 0.8434 - val_recall: 0.8283\n",
            "Epoch 66/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8858 - precision: 0.8967 - recall: 0.8819 - val_loss: 0.9204 - val_precision: 0.8336 - val_recall: 0.8181\n",
            "Epoch 67/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8853 - precision: 0.8947 - recall: 0.8795 - val_loss: 0.9171 - val_precision: 0.8447 - val_recall: 0.8289\n",
            "Epoch 68/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8815 - precision: 0.9023 - recall: 0.8888 - val_loss: 0.9144 - val_precision: 0.8485 - val_recall: 0.8346\n",
            "Epoch 69/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8815 - precision: 0.9019 - recall: 0.8885 - val_loss: 0.9161 - val_precision: 0.8472 - val_recall: 0.8335\n",
            "Epoch 70/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8811 - precision: 0.9025 - recall: 0.8892 - val_loss: 0.9143 - val_precision: 0.8520 - val_recall: 0.8389\n",
            "Epoch 71/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8801 - precision: 0.9048 - recall: 0.8920 - val_loss: 0.9166 - val_precision: 0.8474 - val_recall: 0.8347\n",
            "Epoch 72/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8794 - precision: 0.9067 - recall: 0.8940 - val_loss: 0.9181 - val_precision: 0.8437 - val_recall: 0.8312\n",
            "Epoch 73/75\n",
            "39/39 [==============================] - 3s 74ms/step - loss: 0.8780 - precision: 0.9072 - recall: 0.8953 - val_loss: 0.9155 - val_precision: 0.8480 - val_recall: 0.8363\n",
            "Epoch 74/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8775 - precision: 0.9092 - recall: 0.8976 - val_loss: 0.9184 - val_precision: 0.8437 - val_recall: 0.8324\n",
            "Epoch 75/75\n",
            "39/39 [==============================] - 3s 73ms/step - loss: 0.8792 - precision: 0.9060 - recall: 0.8939 - val_loss: 0.9177 - val_precision: 0.8431 - val_recall: 0.8303\n",
            "Config Space:\n",
            " {'batch_size': 30, 'learning_rate': 0.0003735348770269236, 'optimizer': 'adam', 'sgd_momentum': 0.8584977116587138}\n",
            "Epoch 1/75\n",
            "35/35 [==============================] - 6s 105ms/step - loss: 1.0172 - precision: 0.7927 - recall: 0.1315 - val_loss: 1.0064 - val_precision: 0.8431 - val_recall: 0.0393\n",
            "Epoch 2/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 1.0021 - precision: 0.8364 - recall: 0.3676 - val_loss: 0.9982 - val_precision: 0.8140 - val_recall: 0.4655\n",
            "Epoch 3/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9879 - precision: 0.8403 - recall: 0.4856 - val_loss: 0.9814 - val_precision: 0.8163 - val_recall: 0.5521\n",
            "Epoch 4/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 0.9775 - precision: 0.8608 - recall: 0.5333 - val_loss: 0.9777 - val_precision: 0.8346 - val_recall: 0.5489\n",
            "Epoch 5/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9741 - precision: 0.8680 - recall: 0.5377 - val_loss: 0.9754 - val_precision: 0.8371 - val_recall: 0.5462\n",
            "Epoch 6/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9710 - precision: 0.8648 - recall: 0.5392 - val_loss: 0.9727 - val_precision: 0.8429 - val_recall: 0.5345\n",
            "Epoch 7/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9667 - precision: 0.8637 - recall: 0.5378 - val_loss: 0.9683 - val_precision: 0.8343 - val_recall: 0.5642\n",
            "Epoch 8/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9620 - precision: 0.8563 - recall: 0.5556 - val_loss: 0.9623 - val_precision: 0.8152 - val_recall: 0.5954\n",
            "Epoch 9/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9581 - precision: 0.8572 - recall: 0.5709 - val_loss: 0.9644 - val_precision: 0.7748 - val_recall: 0.6211\n",
            "Epoch 10/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9552 - precision: 0.8534 - recall: 0.5913 - val_loss: 0.9637 - val_precision: 0.7610 - val_recall: 0.6276\n",
            "Epoch 11/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9521 - precision: 0.8444 - recall: 0.6194 - val_loss: 0.9630 - val_precision: 0.7527 - val_recall: 0.6334\n",
            "Epoch 12/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9488 - precision: 0.8369 - recall: 0.6519 - val_loss: 0.9548 - val_precision: 0.7811 - val_recall: 0.6486\n",
            "Epoch 13/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9467 - precision: 0.8292 - recall: 0.6736 - val_loss: 0.9638 - val_precision: 0.7367 - val_recall: 0.6365\n",
            "Epoch 14/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9433 - precision: 0.8249 - recall: 0.6935 - val_loss: 0.9618 - val_precision: 0.7382 - val_recall: 0.6472\n",
            "Epoch 15/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9378 - precision: 0.8205 - recall: 0.7321 - val_loss: 0.9572 - val_precision: 0.7403 - val_recall: 0.6770\n",
            "Epoch 16/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9341 - precision: 0.8215 - recall: 0.7510 - val_loss: 0.9547 - val_precision: 0.7458 - val_recall: 0.6831\n",
            "Epoch 17/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9322 - precision: 0.8270 - recall: 0.7573 - val_loss: 0.9574 - val_precision: 0.7425 - val_recall: 0.6891\n",
            "Epoch 18/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9290 - precision: 0.8322 - recall: 0.7687 - val_loss: 0.9572 - val_precision: 0.7447 - val_recall: 0.6987\n",
            "Epoch 19/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9288 - precision: 0.8325 - recall: 0.7698 - val_loss: 0.9602 - val_precision: 0.7350 - val_recall: 0.6877\n",
            "Epoch 20/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9273 - precision: 0.8366 - recall: 0.7738 - val_loss: 0.9587 - val_precision: 0.7400 - val_recall: 0.7012\n",
            "Epoch 21/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9258 - precision: 0.8382 - recall: 0.7795 - val_loss: 0.9548 - val_precision: 0.7560 - val_recall: 0.7149\n",
            "Epoch 22/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9235 - precision: 0.8429 - recall: 0.7868 - val_loss: 0.9550 - val_precision: 0.7527 - val_recall: 0.7134\n",
            "Epoch 23/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9220 - precision: 0.8453 - recall: 0.7928 - val_loss: 0.9539 - val_precision: 0.7568 - val_recall: 0.7150\n",
            "Epoch 24/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9213 - precision: 0.8465 - recall: 0.7944 - val_loss: 0.9538 - val_precision: 0.7545 - val_recall: 0.7172\n",
            "Epoch 25/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9195 - precision: 0.8499 - recall: 0.7997 - val_loss: 0.9522 - val_precision: 0.7606 - val_recall: 0.7229\n",
            "Epoch 26/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9187 - precision: 0.8514 - recall: 0.8030 - val_loss: 0.9453 - val_precision: 0.7749 - val_recall: 0.7379\n",
            "Epoch 27/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9207 - precision: 0.8476 - recall: 0.7961 - val_loss: 0.9511 - val_precision: 0.7554 - val_recall: 0.7212\n",
            "Epoch 28/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9183 - precision: 0.8510 - recall: 0.8041 - val_loss: 0.9551 - val_precision: 0.7535 - val_recall: 0.7224\n",
            "Epoch 29/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9164 - precision: 0.8548 - recall: 0.8089 - val_loss: 0.9527 - val_precision: 0.7542 - val_recall: 0.7224\n",
            "Epoch 30/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9155 - precision: 0.8561 - recall: 0.8125 - val_loss: 0.9471 - val_precision: 0.7687 - val_recall: 0.7364\n",
            "Epoch 31/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9147 - precision: 0.8578 - recall: 0.8146 - val_loss: 0.9469 - val_precision: 0.7677 - val_recall: 0.7357\n",
            "Epoch 32/75\n",
            "35/35 [==============================] - 3s 83ms/step - loss: 0.9132 - precision: 0.8609 - recall: 0.8186 - val_loss: 0.9461 - val_precision: 0.7716 - val_recall: 0.7418\n",
            "Epoch 33/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9124 - precision: 0.8622 - recall: 0.8219 - val_loss: 0.9447 - val_precision: 0.7754 - val_recall: 0.7439\n",
            "Epoch 34/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9114 - precision: 0.8647 - recall: 0.8251 - val_loss: 0.9440 - val_precision: 0.7772 - val_recall: 0.7465\n",
            "Epoch 35/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9118 - precision: 0.8631 - recall: 0.8241 - val_loss: 0.9405 - val_precision: 0.7837 - val_recall: 0.7494\n",
            "Epoch 36/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9112 - precision: 0.8649 - recall: 0.8252 - val_loss: 0.9478 - val_precision: 0.7691 - val_recall: 0.7414\n",
            "Epoch 37/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9099 - precision: 0.8671 - recall: 0.8286 - val_loss: 0.9427 - val_precision: 0.7853 - val_recall: 0.7562\n",
            "Epoch 38/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9089 - precision: 0.8697 - recall: 0.8328 - val_loss: 0.9395 - val_precision: 0.7940 - val_recall: 0.7616\n",
            "Epoch 39/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9079 - precision: 0.8719 - recall: 0.8361 - val_loss: 0.9384 - val_precision: 0.7976 - val_recall: 0.7627\n",
            "Epoch 40/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9069 - precision: 0.8743 - recall: 0.8396 - val_loss: 0.9400 - val_precision: 0.7931 - val_recall: 0.7610\n",
            "Epoch 41/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9063 - precision: 0.8754 - recall: 0.8413 - val_loss: 0.9380 - val_precision: 0.7992 - val_recall: 0.7667\n",
            "Epoch 42/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9056 - precision: 0.8774 - recall: 0.8434 - val_loss: 0.9375 - val_precision: 0.8004 - val_recall: 0.7684\n",
            "Epoch 43/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9052 - precision: 0.8783 - recall: 0.8450 - val_loss: 0.9379 - val_precision: 0.8010 - val_recall: 0.7668\n",
            "Epoch 44/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9047 - precision: 0.8797 - recall: 0.8470 - val_loss: 0.9382 - val_precision: 0.8006 - val_recall: 0.7670\n",
            "Epoch 45/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9040 - precision: 0.8811 - recall: 0.8486 - val_loss: 0.9337 - val_precision: 0.8087 - val_recall: 0.7742\n",
            "Epoch 46/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9034 - precision: 0.8825 - recall: 0.8511 - val_loss: 0.9335 - val_precision: 0.8099 - val_recall: 0.7798\n",
            "Epoch 47/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9032 - precision: 0.8833 - recall: 0.8521 - val_loss: 0.9307 - val_precision: 0.8182 - val_recall: 0.7868\n",
            "Epoch 48/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9044 - precision: 0.8819 - recall: 0.8497 - val_loss: 0.9366 - val_precision: 0.8028 - val_recall: 0.7708\n",
            "Epoch 49/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9053 - precision: 0.8798 - recall: 0.8455 - val_loss: 0.9302 - val_precision: 0.8156 - val_recall: 0.7823\n",
            "Epoch 50/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9014 - precision: 0.8878 - recall: 0.8567 - val_loss: 0.9334 - val_precision: 0.8090 - val_recall: 0.7802\n",
            "Epoch 51/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.9012 - precision: 0.8883 - recall: 0.8579 - val_loss: 0.9343 - val_precision: 0.8095 - val_recall: 0.7791\n",
            "Epoch 52/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.9002 - precision: 0.8908 - recall: 0.8588 - val_loss: 0.9361 - val_precision: 0.8035 - val_recall: 0.7775\n",
            "Epoch 53/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8997 - precision: 0.8911 - recall: 0.8590 - val_loss: 0.9309 - val_precision: 0.8155 - val_recall: 0.7907\n",
            "Epoch 54/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8994 - precision: 0.8894 - recall: 0.8592 - val_loss: 0.9265 - val_precision: 0.8264 - val_recall: 0.8032\n",
            "Epoch 55/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8992 - precision: 0.8877 - recall: 0.8594 - val_loss: 0.9259 - val_precision: 0.8252 - val_recall: 0.8004\n",
            "Epoch 56/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8999 - precision: 0.8841 - recall: 0.8583 - val_loss: 0.9253 - val_precision: 0.8245 - val_recall: 0.8016\n",
            "Epoch 57/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8980 - precision: 0.8857 - recall: 0.8625 - val_loss: 0.9210 - val_precision: 0.8337 - val_recall: 0.8120\n",
            "Epoch 58/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8964 - precision: 0.8861 - recall: 0.8650 - val_loss: 0.9298 - val_precision: 0.8121 - val_recall: 0.7942\n",
            "Epoch 59/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8959 - precision: 0.8840 - recall: 0.8621 - val_loss: 0.9264 - val_precision: 0.8221 - val_recall: 0.8038\n",
            "Epoch 60/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8962 - precision: 0.8844 - recall: 0.8638 - val_loss: 0.9241 - val_precision: 0.8243 - val_recall: 0.8050\n",
            "Epoch 61/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8942 - precision: 0.8845 - recall: 0.8641 - val_loss: 0.9210 - val_precision: 0.8311 - val_recall: 0.8132\n",
            "Epoch 62/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8928 - precision: 0.8852 - recall: 0.8654 - val_loss: 0.9256 - val_precision: 0.8206 - val_recall: 0.8026\n",
            "Epoch 63/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8933 - precision: 0.8850 - recall: 0.8645 - val_loss: 0.9343 - val_precision: 0.8029 - val_recall: 0.7855\n",
            "Epoch 64/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8949 - precision: 0.8842 - recall: 0.8631 - val_loss: 0.9372 - val_precision: 0.7936 - val_recall: 0.7752\n",
            "Epoch 65/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8958 - precision: 0.8807 - recall: 0.8602 - val_loss: 0.9227 - val_precision: 0.8260 - val_recall: 0.8062\n",
            "Epoch 66/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8912 - precision: 0.8871 - recall: 0.8669 - val_loss: 0.9304 - val_precision: 0.8104 - val_recall: 0.7952\n",
            "Epoch 67/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8900 - precision: 0.8903 - recall: 0.8716 - val_loss: 0.9281 - val_precision: 0.8120 - val_recall: 0.7953\n",
            "Epoch 68/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8914 - precision: 0.8869 - recall: 0.8670 - val_loss: 0.9346 - val_precision: 0.8011 - val_recall: 0.7851\n",
            "Epoch 69/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8885 - precision: 0.8925 - recall: 0.8737 - val_loss: 0.9260 - val_precision: 0.8222 - val_recall: 0.8064\n",
            "Epoch 70/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8873 - precision: 0.8942 - recall: 0.8769 - val_loss: 0.9314 - val_precision: 0.8102 - val_recall: 0.7962\n",
            "Epoch 71/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8855 - precision: 0.8962 - recall: 0.8795 - val_loss: 0.9289 - val_precision: 0.8153 - val_recall: 0.7997\n",
            "Epoch 72/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8871 - precision: 0.8934 - recall: 0.8763 - val_loss: 0.9280 - val_precision: 0.8178 - val_recall: 0.8030\n",
            "Epoch 73/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8849 - precision: 0.8977 - recall: 0.8820 - val_loss: 0.9241 - val_precision: 0.8260 - val_recall: 0.8127\n",
            "Epoch 74/75\n",
            "35/35 [==============================] - 3s 81ms/step - loss: 0.8853 - precision: 0.8969 - recall: 0.8806 - val_loss: 0.9236 - val_precision: 0.8291 - val_recall: 0.8155\n",
            "Epoch 75/75\n",
            "35/35 [==============================] - 3s 82ms/step - loss: 0.8828 - precision: 0.9005 - recall: 0.8853 - val_loss: 0.9210 - val_precision: 0.8303 - val_recall: 0.8167\n",
            "Config Space:\n",
            " {'batch_size': 31, 'learning_rate': 0.0003401549016294108, 'optimizer': 'adam', 'sgd_momentum': 0.9254391870088128}\n",
            "Epoch 1/75\n",
            "34/34 [==============================] - 8s 134ms/step - loss: 1.0229 - precision: 0.8129 - recall: 0.0230 - val_loss: 1.0091 - val_precision: 0.9276 - val_recall: 0.0930\n",
            "Epoch 2/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 1.0015 - precision: 0.8832 - recall: 0.3535 - val_loss: 0.9956 - val_precision: 0.8646 - val_recall: 0.4589\n",
            "Epoch 3/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9928 - precision: 0.9159 - recall: 0.4095 - val_loss: 0.9895 - val_precision: 0.9013 - val_recall: 0.4324\n",
            "Epoch 4/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9863 - precision: 0.8939 - recall: 0.4428 - val_loss: 0.9786 - val_precision: 0.8931 - val_recall: 0.4981\n",
            "Epoch 5/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9706 - precision: 0.8996 - recall: 0.5410 - val_loss: 0.9688 - val_precision: 0.8688 - val_recall: 0.5586\n",
            "Epoch 6/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9630 - precision: 0.8773 - recall: 0.5862 - val_loss: 0.9651 - val_precision: 0.8720 - val_recall: 0.5699\n",
            "Epoch 7/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9575 - precision: 0.8594 - recall: 0.6100 - val_loss: 0.9613 - val_precision: 0.8682 - val_recall: 0.5880\n",
            "Epoch 8/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9515 - precision: 0.8430 - recall: 0.6375 - val_loss: 0.9576 - val_precision: 0.8614 - val_recall: 0.5941\n",
            "Epoch 9/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.9463 - precision: 0.8266 - recall: 0.6688 - val_loss: 0.9540 - val_precision: 0.7953 - val_recall: 0.6543\n",
            "Epoch 10/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9396 - precision: 0.8227 - recall: 0.7199 - val_loss: 0.9533 - val_precision: 0.7673 - val_recall: 0.6806\n",
            "Epoch 11/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9362 - precision: 0.8284 - recall: 0.7346 - val_loss: 0.9592 - val_precision: 0.7427 - val_recall: 0.6685\n",
            "Epoch 12/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.9332 - precision: 0.8309 - recall: 0.7502 - val_loss: 0.9583 - val_precision: 0.7383 - val_recall: 0.6772\n",
            "Epoch 13/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9306 - precision: 0.8347 - recall: 0.7593 - val_loss: 0.9563 - val_precision: 0.7467 - val_recall: 0.6841\n",
            "Epoch 14/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9281 - precision: 0.8391 - recall: 0.7689 - val_loss: 0.9614 - val_precision: 0.7342 - val_recall: 0.6790\n",
            "Epoch 15/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9262 - precision: 0.8431 - recall: 0.7737 - val_loss: 0.9578 - val_precision: 0.7456 - val_recall: 0.6957\n",
            "Epoch 16/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9240 - precision: 0.8459 - recall: 0.7816 - val_loss: 0.9539 - val_precision: 0.7558 - val_recall: 0.7122\n",
            "Epoch 17/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.9239 - precision: 0.8450 - recall: 0.7829 - val_loss: 0.9450 - val_precision: 0.7844 - val_recall: 0.7220\n",
            "Epoch 18/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9223 - precision: 0.8485 - recall: 0.7879 - val_loss: 0.9609 - val_precision: 0.7382 - val_recall: 0.6945\n",
            "Epoch 19/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9199 - precision: 0.8529 - recall: 0.7944 - val_loss: 0.9542 - val_precision: 0.7547 - val_recall: 0.7147\n",
            "Epoch 20/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9182 - precision: 0.8554 - recall: 0.8012 - val_loss: 0.9516 - val_precision: 0.7654 - val_recall: 0.7270\n",
            "Epoch 21/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9167 - precision: 0.8587 - recall: 0.8063 - val_loss: 0.9530 - val_precision: 0.7609 - val_recall: 0.7231\n",
            "Epoch 22/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9156 - precision: 0.8601 - recall: 0.8115 - val_loss: 0.9480 - val_precision: 0.7725 - val_recall: 0.7302\n",
            "Epoch 23/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9138 - precision: 0.8633 - recall: 0.8174 - val_loss: 0.9497 - val_precision: 0.7673 - val_recall: 0.7270\n",
            "Epoch 24/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9129 - precision: 0.8640 - recall: 0.8203 - val_loss: 0.9476 - val_precision: 0.7729 - val_recall: 0.7332\n",
            "Epoch 25/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9117 - precision: 0.8664 - recall: 0.8235 - val_loss: 0.9437 - val_precision: 0.7853 - val_recall: 0.7448\n",
            "Epoch 26/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9103 - precision: 0.8690 - recall: 0.8285 - val_loss: 0.9443 - val_precision: 0.7833 - val_recall: 0.7463\n",
            "Epoch 27/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9094 - precision: 0.8706 - recall: 0.8314 - val_loss: 0.9422 - val_precision: 0.7918 - val_recall: 0.7552\n",
            "Epoch 28/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9089 - precision: 0.8720 - recall: 0.8330 - val_loss: 0.9394 - val_precision: 0.7958 - val_recall: 0.7592\n",
            "Epoch 29/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9099 - precision: 0.8695 - recall: 0.8303 - val_loss: 0.9436 - val_precision: 0.7863 - val_recall: 0.7500\n",
            "Epoch 30/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9083 - precision: 0.8726 - recall: 0.8345 - val_loss: 0.9369 - val_precision: 0.8033 - val_recall: 0.7677\n",
            "Epoch 31/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9073 - precision: 0.8750 - recall: 0.8390 - val_loss: 0.9349 - val_precision: 0.8115 - val_recall: 0.7755\n",
            "Epoch 32/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9069 - precision: 0.8752 - recall: 0.8397 - val_loss: 0.9368 - val_precision: 0.8025 - val_recall: 0.7625\n",
            "Epoch 33/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9064 - precision: 0.8771 - recall: 0.8419 - val_loss: 0.9347 - val_precision: 0.8095 - val_recall: 0.7709\n",
            "Epoch 34/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.9063 - precision: 0.8774 - recall: 0.8419 - val_loss: 0.9366 - val_precision: 0.8065 - val_recall: 0.7668\n",
            "Epoch 35/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9154 - precision: 0.8614 - recall: 0.8172 - val_loss: 0.9371 - val_precision: 0.8110 - val_recall: 0.7573\n",
            "Epoch 36/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9147 - precision: 0.8625 - recall: 0.8120 - val_loss: 0.9412 - val_precision: 0.7965 - val_recall: 0.7472\n",
            "Epoch 37/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9086 - precision: 0.8726 - recall: 0.8340 - val_loss: 0.9391 - val_precision: 0.7945 - val_recall: 0.7518\n",
            "Epoch 38/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9057 - precision: 0.8787 - recall: 0.8443 - val_loss: 0.9336 - val_precision: 0.8103 - val_recall: 0.7735\n",
            "Epoch 39/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9041 - precision: 0.8822 - recall: 0.8499 - val_loss: 0.9337 - val_precision: 0.8102 - val_recall: 0.7758\n",
            "Epoch 40/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9030 - precision: 0.8847 - recall: 0.8531 - val_loss: 0.9315 - val_precision: 0.8196 - val_recall: 0.7859\n",
            "Epoch 41/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9019 - precision: 0.8871 - recall: 0.8571 - val_loss: 0.9278 - val_precision: 0.8295 - val_recall: 0.7971\n",
            "Epoch 42/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.9012 - precision: 0.8889 - recall: 0.8589 - val_loss: 0.9289 - val_precision: 0.8274 - val_recall: 0.7955\n",
            "Epoch 43/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.9004 - precision: 0.8905 - recall: 0.8620 - val_loss: 0.9263 - val_precision: 0.8346 - val_recall: 0.8037\n",
            "Epoch 44/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8996 - precision: 0.8923 - recall: 0.8645 - val_loss: 0.9274 - val_precision: 0.8297 - val_recall: 0.7971\n",
            "Epoch 45/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8994 - precision: 0.8924 - recall: 0.8652 - val_loss: 0.9273 - val_precision: 0.8343 - val_recall: 0.8027\n",
            "Epoch 46/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8985 - precision: 0.8945 - recall: 0.8676 - val_loss: 0.9290 - val_precision: 0.8287 - val_recall: 0.7982\n",
            "Epoch 47/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8981 - precision: 0.8950 - recall: 0.8682 - val_loss: 0.9274 - val_precision: 0.8342 - val_recall: 0.8041\n",
            "Epoch 48/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8972 - precision: 0.8966 - recall: 0.8697 - val_loss: 0.9270 - val_precision: 0.8345 - val_recall: 0.8042\n",
            "Epoch 49/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8969 - precision: 0.8968 - recall: 0.8694 - val_loss: 0.9255 - val_precision: 0.8386 - val_recall: 0.8095\n",
            "Epoch 50/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.8973 - precision: 0.8948 - recall: 0.8666 - val_loss: 0.9248 - val_precision: 0.8395 - val_recall: 0.8102\n",
            "Epoch 51/75\n",
            "34/34 [==============================] - 3s 85ms/step - loss: 0.8965 - precision: 0.8915 - recall: 0.8656 - val_loss: 0.9273 - val_precision: 0.8316 - val_recall: 0.8065\n",
            "Epoch 52/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8962 - precision: 0.8892 - recall: 0.8663 - val_loss: 0.9345 - val_precision: 0.8181 - val_recall: 0.7943\n",
            "Epoch 53/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8954 - precision: 0.8868 - recall: 0.8638 - val_loss: 0.9328 - val_precision: 0.8215 - val_recall: 0.7998\n",
            "Epoch 54/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8967 - precision: 0.8843 - recall: 0.8616 - val_loss: 0.9339 - val_precision: 0.8091 - val_recall: 0.7831\n",
            "Epoch 55/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8944 - precision: 0.8862 - recall: 0.8643 - val_loss: 0.9356 - val_precision: 0.8053 - val_recall: 0.7815\n",
            "Epoch 56/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8926 - precision: 0.8868 - recall: 0.8643 - val_loss: 0.9225 - val_precision: 0.8332 - val_recall: 0.8079\n",
            "Epoch 57/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8890 - precision: 0.8883 - recall: 0.8688 - val_loss: 0.9276 - val_precision: 0.8164 - val_recall: 0.7890\n",
            "Epoch 58/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8937 - precision: 0.8831 - recall: 0.8601 - val_loss: 0.9297 - val_precision: 0.8167 - val_recall: 0.7904\n",
            "Epoch 59/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8910 - precision: 0.8883 - recall: 0.8669 - val_loss: 0.9226 - val_precision: 0.8386 - val_recall: 0.8146\n",
            "Epoch 60/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8884 - precision: 0.8899 - recall: 0.8697 - val_loss: 0.9177 - val_precision: 0.8434 - val_recall: 0.8186\n",
            "Epoch 61/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8872 - precision: 0.8919 - recall: 0.8722 - val_loss: 0.9247 - val_precision: 0.8298 - val_recall: 0.8070\n",
            "Epoch 62/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8855 - precision: 0.8927 - recall: 0.8745 - val_loss: 0.9277 - val_precision: 0.8205 - val_recall: 0.7961\n",
            "Epoch 63/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8841 - precision: 0.8932 - recall: 0.8745 - val_loss: 0.9231 - val_precision: 0.8307 - val_recall: 0.8054\n",
            "Epoch 64/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8843 - precision: 0.8925 - recall: 0.8740 - val_loss: 0.9273 - val_precision: 0.8260 - val_recall: 0.8005\n",
            "Epoch 65/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8833 - precision: 0.8938 - recall: 0.8741 - val_loss: 0.9237 - val_precision: 0.8363 - val_recall: 0.8166\n",
            "Epoch 66/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8801 - precision: 0.8999 - recall: 0.8833 - val_loss: 0.9284 - val_precision: 0.8266 - val_recall: 0.8064\n",
            "Epoch 67/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8792 - precision: 0.9016 - recall: 0.8854 - val_loss: 0.9251 - val_precision: 0.8316 - val_recall: 0.8132\n",
            "Epoch 68/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8786 - precision: 0.9023 - recall: 0.8865 - val_loss: 0.9294 - val_precision: 0.8246 - val_recall: 0.8085\n",
            "Epoch 69/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8765 - precision: 0.9054 - recall: 0.8907 - val_loss: 0.9251 - val_precision: 0.8319 - val_recall: 0.8163\n",
            "Epoch 70/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8755 - precision: 0.9069 - recall: 0.8926 - val_loss: 0.9235 - val_precision: 0.8363 - val_recall: 0.8204\n",
            "Epoch 71/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8755 - precision: 0.9075 - recall: 0.8936 - val_loss: 0.9272 - val_precision: 0.8271 - val_recall: 0.8112\n",
            "Epoch 72/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8749 - precision: 0.9083 - recall: 0.8948 - val_loss: 0.9233 - val_precision: 0.8358 - val_recall: 0.8216\n",
            "Epoch 73/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8747 - precision: 0.9090 - recall: 0.8953 - val_loss: 0.9252 - val_precision: 0.8331 - val_recall: 0.8185\n",
            "Epoch 74/75\n",
            "34/34 [==============================] - 3s 84ms/step - loss: 0.8744 - precision: 0.9094 - recall: 0.8963 - val_loss: 0.9259 - val_precision: 0.8295 - val_recall: 0.8136\n",
            "Epoch 75/75\n",
            "34/34 [==============================] - 3s 83ms/step - loss: 0.8739 - precision: 0.9100 - recall: 0.8970 - val_loss: 0.9247 - val_precision: 0.8335 - val_recall: 0.8183\n",
            "Config Space:\n",
            " {'batch_size': 11, 'learning_rate': 0.006379790977696792, 'optimizer': 'adam', 'sgd_momentum': 0.18897151412792534}\n",
            "Epoch 1/25\n",
            "95/95 [==============================] - 6s 43ms/step - loss: 0.9811 - precision: 0.8223 - recall: 0.4951 - val_loss: 0.9588 - val_precision: 0.8038 - val_recall: 0.6436\n",
            "Epoch 2/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9549 - precision: 0.8136 - recall: 0.6464 - val_loss: 0.9513 - val_precision: 0.8001 - val_recall: 0.6982\n",
            "Epoch 3/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9511 - precision: 0.8137 - recall: 0.6720 - val_loss: 0.9469 - val_precision: 0.8116 - val_recall: 0.7066\n",
            "Epoch 4/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9466 - precision: 0.8079 - recall: 0.6998 - val_loss: 0.9468 - val_precision: 0.7915 - val_recall: 0.7110\n",
            "Epoch 5/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9438 - precision: 0.8063 - recall: 0.7183 - val_loss: 0.9395 - val_precision: 0.8021 - val_recall: 0.7377\n",
            "Epoch 6/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9406 - precision: 0.8095 - recall: 0.7332 - val_loss: 0.9412 - val_precision: 0.8056 - val_recall: 0.7152\n",
            "Epoch 7/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9362 - precision: 0.8199 - recall: 0.7510 - val_loss: 0.9426 - val_precision: 0.8005 - val_recall: 0.7071\n",
            "Epoch 8/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9334 - precision: 0.8217 - recall: 0.7646 - val_loss: 0.9500 - val_precision: 0.7704 - val_recall: 0.6838\n",
            "Epoch 9/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9318 - precision: 0.8254 - recall: 0.7711 - val_loss: 0.9349 - val_precision: 0.8002 - val_recall: 0.7401\n",
            "Epoch 10/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9288 - precision: 0.8296 - recall: 0.7806 - val_loss: 0.9323 - val_precision: 0.8132 - val_recall: 0.7512\n",
            "Epoch 11/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9274 - precision: 0.8326 - recall: 0.7844 - val_loss: 0.9337 - val_precision: 0.8080 - val_recall: 0.7475\n",
            "Epoch 12/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9265 - precision: 0.8340 - recall: 0.7874 - val_loss: 0.9299 - val_precision: 0.8140 - val_recall: 0.7614\n",
            "Epoch 13/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9250 - precision: 0.8367 - recall: 0.7914 - val_loss: 0.9308 - val_precision: 0.8124 - val_recall: 0.7601\n",
            "Epoch 14/25\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9246 - precision: 0.8372 - recall: 0.7926 - val_loss: 0.9310 - val_precision: 0.8141 - val_recall: 0.7598\n",
            "Epoch 15/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9245 - precision: 0.8383 - recall: 0.7931 - val_loss: 0.9312 - val_precision: 0.8136 - val_recall: 0.7627\n",
            "Epoch 16/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9237 - precision: 0.8392 - recall: 0.7952 - val_loss: 0.9290 - val_precision: 0.8178 - val_recall: 0.7683\n",
            "Epoch 17/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9231 - precision: 0.8401 - recall: 0.7966 - val_loss: 0.9273 - val_precision: 0.8223 - val_recall: 0.7742\n",
            "Epoch 18/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9225 - precision: 0.8415 - recall: 0.7985 - val_loss: 0.9266 - val_precision: 0.8209 - val_recall: 0.7760\n",
            "Epoch 19/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9220 - precision: 0.8420 - recall: 0.7993 - val_loss: 0.9284 - val_precision: 0.8211 - val_recall: 0.7683\n",
            "Epoch 20/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9218 - precision: 0.8425 - recall: 0.8002 - val_loss: 0.9288 - val_precision: 0.8190 - val_recall: 0.7711\n",
            "Epoch 21/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9218 - precision: 0.8426 - recall: 0.8003 - val_loss: 0.9289 - val_precision: 0.8174 - val_recall: 0.7703\n",
            "Epoch 22/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9213 - precision: 0.8437 - recall: 0.8014 - val_loss: 0.9276 - val_precision: 0.8187 - val_recall: 0.7736\n",
            "Epoch 23/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9210 - precision: 0.8438 - recall: 0.8018 - val_loss: 0.9296 - val_precision: 0.8153 - val_recall: 0.7676\n",
            "Epoch 24/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9219 - precision: 0.8425 - recall: 0.7999 - val_loss: 0.9299 - val_precision: 0.8148 - val_recall: 0.7655\n",
            "Epoch 25/25\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9218 - precision: 0.8427 - recall: 0.7997 - val_loss: 0.9277 - val_precision: 0.8166 - val_recall: 0.7696\n",
            "Config Space:\n",
            " {'batch_size': 23, 'learning_rate': 0.0029896701407367146, 'optimizer': 'sgd', 'sgd_momentum': 0.5460870135101618}\n",
            "Epoch 1/25\n",
            "46/46 [==============================] - 6s 82ms/step - loss: 1.0546 - precision: 0.0056 - recall: 8.8263e-04 - val_loss: 1.0340 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0391 - precision: 0.0029 - recall: 1.1367e-04 - val_loss: 1.0307 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0334 - precision: 0.0025 - recall: 3.5385e-05 - val_loss: 1.0291 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/25\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.0303 - precision: 0.0032 - recall: 2.0930e-05 - val_loss: 1.0282 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0282 - precision: 0.0044 - recall: 1.6618e-05 - val_loss: 1.0274 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0264 - precision: 0.0088 - recall: 2.3254e-05 - val_loss: 1.0265 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0247 - precision: 0.0201 - recall: 4.4914e-05 - val_loss: 1.0252 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0230 - precision: 0.0567 - recall: 1.2885e-04 - val_loss: 1.0236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0211 - precision: 0.1685 - recall: 4.8452e-04 - val_loss: 1.0217 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0191 - precision: 0.3930 - recall: 0.0020 - val_loss: 1.0194 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0170 - precision: 0.6311 - recall: 0.0073 - val_loss: 1.0169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/25\n",
            "46/46 [==============================] - 3s 65ms/step - loss: 1.0149 - precision: 0.7698 - recall: 0.0222 - val_loss: 1.0144 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0129 - precision: 0.8280 - recall: 0.0524 - val_loss: 1.0121 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/25\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.0112 - precision: 0.8479 - recall: 0.0978 - val_loss: 1.0100 - val_precision: 0.0606 - val_recall: 4.6770e-07\n",
            "Epoch 15/25\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.0097 - precision: 0.8518 - recall: 0.1501 - val_loss: 1.0083 - val_precision: 0.7542 - val_recall: 0.0024\n",
            "Epoch 16/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0086 - precision: 0.8490 - recall: 0.1999 - val_loss: 1.0069 - val_precision: 0.8448 - val_recall: 0.0265\n",
            "Epoch 17/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0076 - precision: 0.8438 - recall: 0.2417 - val_loss: 1.0058 - val_precision: 0.8876 - val_recall: 0.0854\n",
            "Epoch 18/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0068 - precision: 0.8385 - recall: 0.2742 - val_loss: 1.0049 - val_precision: 0.9000 - val_recall: 0.1661\n",
            "Epoch 19/25\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.0062 - precision: 0.8337 - recall: 0.2988 - val_loss: 1.0042 - val_precision: 0.9001 - val_recall: 0.2294\n",
            "Epoch 20/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0056 - precision: 0.8298 - recall: 0.3172 - val_loss: 1.0036 - val_precision: 0.8959 - val_recall: 0.2694\n",
            "Epoch 21/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0051 - precision: 0.8269 - recall: 0.3313 - val_loss: 1.0030 - val_precision: 0.8924 - val_recall: 0.3003\n",
            "Epoch 22/25\n",
            "46/46 [==============================] - 3s 63ms/step - loss: 1.0047 - precision: 0.8245 - recall: 0.3423 - val_loss: 1.0026 - val_precision: 0.8898 - val_recall: 0.3258\n",
            "Epoch 23/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0043 - precision: 0.8227 - recall: 0.3509 - val_loss: 1.0022 - val_precision: 0.8872 - val_recall: 0.3451\n",
            "Epoch 24/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0039 - precision: 0.8213 - recall: 0.3579 - val_loss: 1.0018 - val_precision: 0.8846 - val_recall: 0.3593\n",
            "Epoch 25/25\n",
            "46/46 [==============================] - 3s 64ms/step - loss: 1.0035 - precision: 0.8204 - recall: 0.3637 - val_loss: 1.0015 - val_precision: 0.8820 - val_recall: 0.3698\n",
            "Config Space:\n",
            " {'batch_size': 6, 'learning_rate': 0.002547859030004373, 'optimizer': 'adam', 'sgd_momentum': 0.05517169349458934}\n",
            "Epoch 1/25\n",
            "174/174 [==============================] - 7s 27ms/step - loss: 0.9772 - precision: 0.8318 - recall: 0.5173 - val_loss: 0.9665 - val_precision: 0.7997 - val_recall: 0.5975\n",
            "Epoch 2/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9615 - precision: 0.8025 - recall: 0.6154 - val_loss: 0.9625 - val_precision: 0.7754 - val_recall: 0.6550\n",
            "Epoch 3/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9576 - precision: 0.7998 - recall: 0.6470 - val_loss: 0.9579 - val_precision: 0.7968 - val_recall: 0.6563\n",
            "Epoch 4/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9531 - precision: 0.8098 - recall: 0.6697 - val_loss: 0.9542 - val_precision: 0.8051 - val_recall: 0.6870\n",
            "Epoch 5/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9490 - precision: 0.8075 - recall: 0.6998 - val_loss: 0.9505 - val_precision: 0.7939 - val_recall: 0.7249\n",
            "Epoch 6/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9423 - precision: 0.8099 - recall: 0.7387 - val_loss: 0.9566 - val_precision: 0.7906 - val_recall: 0.7222\n",
            "Epoch 7/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9398 - precision: 0.8152 - recall: 0.7504 - val_loss: 0.9459 - val_precision: 0.8082 - val_recall: 0.7435\n",
            "Epoch 8/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9366 - precision: 0.8201 - recall: 0.7622 - val_loss: 0.9405 - val_precision: 0.8141 - val_recall: 0.7562\n",
            "Epoch 9/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9342 - precision: 0.8260 - recall: 0.7712 - val_loss: 0.9362 - val_precision: 0.8240 - val_recall: 0.7670\n",
            "Epoch 10/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9328 - precision: 0.8290 - recall: 0.7767 - val_loss: 0.9340 - val_precision: 0.8283 - val_recall: 0.7783\n",
            "Epoch 11/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9308 - precision: 0.8321 - recall: 0.7830 - val_loss: 0.9322 - val_precision: 0.8308 - val_recall: 0.7817\n",
            "Epoch 12/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9298 - precision: 0.8345 - recall: 0.7864 - val_loss: 0.9316 - val_precision: 0.8309 - val_recall: 0.7843\n",
            "Epoch 13/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9290 - precision: 0.8355 - recall: 0.7885 - val_loss: 0.9309 - val_precision: 0.8335 - val_recall: 0.7876\n",
            "Epoch 14/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9284 - precision: 0.8369 - recall: 0.7904 - val_loss: 0.9308 - val_precision: 0.8322 - val_recall: 0.7878\n",
            "Epoch 15/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9276 - precision: 0.8382 - recall: 0.7922 - val_loss: 0.9308 - val_precision: 0.8318 - val_recall: 0.7900\n",
            "Epoch 16/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9271 - precision: 0.8394 - recall: 0.7936 - val_loss: 0.9293 - val_precision: 0.8353 - val_recall: 0.7928\n",
            "Epoch 17/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9264 - precision: 0.8409 - recall: 0.7955 - val_loss: 0.9294 - val_precision: 0.8347 - val_recall: 0.7910\n",
            "Epoch 18/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9260 - precision: 0.8418 - recall: 0.7967 - val_loss: 0.9294 - val_precision: 0.8360 - val_recall: 0.7933\n",
            "Epoch 19/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9254 - precision: 0.8427 - recall: 0.7985 - val_loss: 0.9273 - val_precision: 0.8400 - val_recall: 0.7973\n",
            "Epoch 20/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9250 - precision: 0.8434 - recall: 0.7999 - val_loss: 0.9275 - val_precision: 0.8391 - val_recall: 0.7946\n",
            "Epoch 21/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9247 - precision: 0.8440 - recall: 0.8009 - val_loss: 0.9275 - val_precision: 0.8388 - val_recall: 0.7960\n",
            "Epoch 22/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9245 - precision: 0.8443 - recall: 0.8016 - val_loss: 0.9272 - val_precision: 0.8382 - val_recall: 0.7957\n",
            "Epoch 23/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9238 - precision: 0.8457 - recall: 0.8037 - val_loss: 0.9273 - val_precision: 0.8388 - val_recall: 0.7953\n",
            "Epoch 24/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9237 - precision: 0.8456 - recall: 0.8041 - val_loss: 0.9266 - val_precision: 0.8403 - val_recall: 0.7988\n",
            "Epoch 25/25\n",
            "174/174 [==============================] - 4s 22ms/step - loss: 0.9233 - precision: 0.8464 - recall: 0.8054 - val_loss: 0.9271 - val_precision: 0.8403 - val_recall: 0.7984\n",
            "Config Space:\n",
            " {'batch_size': 11, 'learning_rate': 0.006379790977696792, 'optimizer': 'adam', 'sgd_momentum': 0.18897151412792534}\n",
            "Epoch 1/75\n",
            "95/95 [==============================] - 6s 43ms/step - loss: 0.9806 - precision: 0.8061 - recall: 0.5016 - val_loss: 0.9636 - val_precision: 0.7534 - val_recall: 0.6519\n",
            "Epoch 2/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9552 - precision: 0.7992 - recall: 0.6527 - val_loss: 0.9502 - val_precision: 0.7935 - val_recall: 0.7053\n",
            "Epoch 3/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9590 - precision: 0.7789 - recall: 0.6514 - val_loss: 0.9702 - val_precision: 0.8592 - val_recall: 0.5146\n",
            "Epoch 4/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9570 - precision: 0.7806 - recall: 0.6493 - val_loss: 0.9546 - val_precision: 0.7770 - val_recall: 0.6893\n",
            "Epoch 5/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9476 - precision: 0.7900 - recall: 0.7078 - val_loss: 0.9447 - val_precision: 0.7932 - val_recall: 0.7374\n",
            "Epoch 6/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9426 - precision: 0.8010 - recall: 0.7349 - val_loss: 0.9450 - val_precision: 0.7890 - val_recall: 0.7294\n",
            "Epoch 7/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9399 - precision: 0.8044 - recall: 0.7429 - val_loss: 0.9352 - val_precision: 0.8025 - val_recall: 0.7531\n",
            "Epoch 8/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9377 - precision: 0.8117 - recall: 0.7491 - val_loss: 0.9371 - val_precision: 0.7983 - val_recall: 0.7490\n",
            "Epoch 9/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9350 - precision: 0.8166 - recall: 0.7590 - val_loss: 0.9348 - val_precision: 0.8091 - val_recall: 0.7617\n",
            "Epoch 10/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9334 - precision: 0.8198 - recall: 0.7641 - val_loss: 0.9358 - val_precision: 0.8035 - val_recall: 0.7571\n",
            "Epoch 11/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9310 - precision: 0.8243 - recall: 0.7715 - val_loss: 0.9380 - val_precision: 0.7996 - val_recall: 0.7522\n",
            "Epoch 12/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9300 - precision: 0.8260 - recall: 0.7752 - val_loss: 0.9410 - val_precision: 0.7911 - val_recall: 0.7436\n",
            "Epoch 13/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9286 - precision: 0.8285 - recall: 0.7790 - val_loss: 0.9388 - val_precision: 0.7947 - val_recall: 0.7452\n",
            "Epoch 14/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9279 - precision: 0.8298 - recall: 0.7819 - val_loss: 0.9336 - val_precision: 0.8017 - val_recall: 0.7593\n",
            "Epoch 15/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9262 - precision: 0.8336 - recall: 0.7862 - val_loss: 0.9318 - val_precision: 0.8066 - val_recall: 0.7631\n",
            "Epoch 16/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9266 - precision: 0.8325 - recall: 0.7851 - val_loss: 0.9329 - val_precision: 0.8055 - val_recall: 0.7598\n",
            "Epoch 17/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9261 - precision: 0.8333 - recall: 0.7859 - val_loss: 0.9289 - val_precision: 0.8106 - val_recall: 0.7735\n",
            "Epoch 18/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9246 - precision: 0.8366 - recall: 0.7905 - val_loss: 0.9288 - val_precision: 0.8127 - val_recall: 0.7727\n",
            "Epoch 19/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9244 - precision: 0.8370 - recall: 0.7902 - val_loss: 0.9291 - val_precision: 0.8123 - val_recall: 0.7717\n",
            "Epoch 20/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9238 - precision: 0.8387 - recall: 0.7923 - val_loss: 0.9292 - val_precision: 0.8105 - val_recall: 0.7709\n",
            "Epoch 21/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9236 - precision: 0.8394 - recall: 0.7926 - val_loss: 0.9279 - val_precision: 0.8158 - val_recall: 0.7754\n",
            "Epoch 22/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9234 - precision: 0.8400 - recall: 0.7927 - val_loss: 0.9264 - val_precision: 0.8191 - val_recall: 0.7815\n",
            "Epoch 23/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9226 - precision: 0.8417 - recall: 0.7950 - val_loss: 0.9277 - val_precision: 0.8154 - val_recall: 0.7759\n",
            "Epoch 24/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9224 - precision: 0.8423 - recall: 0.7957 - val_loss: 0.9276 - val_precision: 0.8161 - val_recall: 0.7748\n",
            "Epoch 25/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9223 - precision: 0.8426 - recall: 0.7961 - val_loss: 0.9278 - val_precision: 0.8147 - val_recall: 0.7746\n",
            "Epoch 26/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9222 - precision: 0.8428 - recall: 0.7959 - val_loss: 0.9275 - val_precision: 0.8167 - val_recall: 0.7759\n",
            "Epoch 27/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9218 - precision: 0.8438 - recall: 0.7974 - val_loss: 0.9254 - val_precision: 0.8217 - val_recall: 0.7845\n",
            "Epoch 28/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9215 - precision: 0.8444 - recall: 0.7987 - val_loss: 0.9259 - val_precision: 0.8196 - val_recall: 0.7823\n",
            "Epoch 29/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9212 - precision: 0.8449 - recall: 0.7987 - val_loss: 0.9260 - val_precision: 0.8192 - val_recall: 0.7802\n",
            "Epoch 30/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9211 - precision: 0.8450 - recall: 0.7992 - val_loss: 0.9249 - val_precision: 0.8224 - val_recall: 0.7863\n",
            "Epoch 31/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9207 - precision: 0.8455 - recall: 0.8001 - val_loss: 0.9262 - val_precision: 0.8210 - val_recall: 0.7809\n",
            "Epoch 32/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9209 - precision: 0.8456 - recall: 0.7998 - val_loss: 0.9256 - val_precision: 0.8209 - val_recall: 0.7827\n",
            "Epoch 33/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9204 - precision: 0.8463 - recall: 0.8009 - val_loss: 0.9260 - val_precision: 0.8185 - val_recall: 0.7803\n",
            "Epoch 34/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9204 - precision: 0.8460 - recall: 0.8010 - val_loss: 0.9251 - val_precision: 0.8227 - val_recall: 0.7846\n",
            "Epoch 35/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9200 - precision: 0.8473 - recall: 0.8020 - val_loss: 0.9244 - val_precision: 0.8249 - val_recall: 0.7862\n",
            "Epoch 36/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9201 - precision: 0.8468 - recall: 0.8018 - val_loss: 0.9247 - val_precision: 0.8237 - val_recall: 0.7861\n",
            "Epoch 37/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9196 - precision: 0.8478 - recall: 0.8034 - val_loss: 0.9253 - val_precision: 0.8205 - val_recall: 0.7824\n",
            "Epoch 38/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9193 - precision: 0.8482 - recall: 0.8040 - val_loss: 0.9243 - val_precision: 0.8241 - val_recall: 0.7873\n",
            "Epoch 39/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9193 - precision: 0.8484 - recall: 0.8041 - val_loss: 0.9261 - val_precision: 0.8188 - val_recall: 0.7791\n",
            "Epoch 40/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9194 - precision: 0.8483 - recall: 0.8037 - val_loss: 0.9240 - val_precision: 0.8255 - val_recall: 0.7866\n",
            "Epoch 41/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9192 - precision: 0.8485 - recall: 0.8046 - val_loss: 0.9252 - val_precision: 0.8207 - val_recall: 0.7821\n",
            "Epoch 42/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9191 - precision: 0.8491 - recall: 0.8049 - val_loss: 0.9256 - val_precision: 0.8192 - val_recall: 0.7815\n",
            "Epoch 43/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9190 - precision: 0.8488 - recall: 0.8049 - val_loss: 0.9249 - val_precision: 0.8211 - val_recall: 0.7823\n",
            "Epoch 44/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9188 - precision: 0.8494 - recall: 0.8057 - val_loss: 0.9236 - val_precision: 0.8251 - val_recall: 0.7878\n",
            "Epoch 45/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9184 - precision: 0.8503 - recall: 0.8072 - val_loss: 0.9241 - val_precision: 0.8235 - val_recall: 0.7872\n",
            "Epoch 46/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9186 - precision: 0.8497 - recall: 0.8060 - val_loss: 0.9234 - val_precision: 0.8246 - val_recall: 0.7886\n",
            "Epoch 47/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9184 - precision: 0.8498 - recall: 0.8066 - val_loss: 0.9240 - val_precision: 0.8250 - val_recall: 0.7860\n",
            "Epoch 48/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9187 - precision: 0.8497 - recall: 0.8063 - val_loss: 0.9233 - val_precision: 0.8266 - val_recall: 0.7912\n",
            "Epoch 49/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9181 - precision: 0.8506 - recall: 0.8072 - val_loss: 0.9237 - val_precision: 0.8250 - val_recall: 0.7868\n",
            "Epoch 50/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9182 - precision: 0.8506 - recall: 0.8074 - val_loss: 0.9227 - val_precision: 0.8281 - val_recall: 0.7907\n",
            "Epoch 51/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9176 - precision: 0.8516 - recall: 0.8087 - val_loss: 0.9230 - val_precision: 0.8261 - val_recall: 0.7893\n",
            "Epoch 52/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9178 - precision: 0.8510 - recall: 0.8087 - val_loss: 0.9216 - val_precision: 0.8308 - val_recall: 0.7941\n",
            "Epoch 53/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9174 - precision: 0.8509 - recall: 0.8102 - val_loss: 0.9232 - val_precision: 0.8243 - val_recall: 0.7882\n",
            "Epoch 54/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9178 - precision: 0.8501 - recall: 0.8086 - val_loss: 0.9225 - val_precision: 0.8273 - val_recall: 0.7913\n",
            "Epoch 55/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9174 - precision: 0.8505 - recall: 0.8104 - val_loss: 0.9222 - val_precision: 0.8279 - val_recall: 0.7923\n",
            "Epoch 56/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9175 - precision: 0.8505 - recall: 0.8096 - val_loss: 0.9216 - val_precision: 0.8292 - val_recall: 0.7924\n",
            "Epoch 57/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9173 - precision: 0.8508 - recall: 0.8108 - val_loss: 0.9223 - val_precision: 0.8285 - val_recall: 0.7923\n",
            "Epoch 58/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9168 - precision: 0.8517 - recall: 0.8129 - val_loss: 0.9221 - val_precision: 0.8283 - val_recall: 0.7923\n",
            "Epoch 59/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9169 - precision: 0.8515 - recall: 0.8117 - val_loss: 0.9218 - val_precision: 0.8272 - val_recall: 0.7906\n",
            "Epoch 60/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9171 - precision: 0.8506 - recall: 0.8122 - val_loss: 0.9221 - val_precision: 0.8281 - val_recall: 0.7928\n",
            "Epoch 61/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9170 - precision: 0.8515 - recall: 0.8119 - val_loss: 0.9222 - val_precision: 0.8280 - val_recall: 0.7923\n",
            "Epoch 62/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9168 - precision: 0.8514 - recall: 0.8123 - val_loss: 0.9224 - val_precision: 0.8258 - val_recall: 0.7915\n",
            "Epoch 63/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9167 - precision: 0.8518 - recall: 0.8128 - val_loss: 0.9216 - val_precision: 0.8310 - val_recall: 0.7936\n",
            "Epoch 64/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9165 - precision: 0.8519 - recall: 0.8137 - val_loss: 0.9205 - val_precision: 0.8313 - val_recall: 0.7969\n",
            "Epoch 65/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9165 - precision: 0.8516 - recall: 0.8130 - val_loss: 0.9215 - val_precision: 0.8296 - val_recall: 0.7937\n",
            "Epoch 66/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9164 - precision: 0.8520 - recall: 0.8140 - val_loss: 0.9221 - val_precision: 0.8266 - val_recall: 0.7906\n",
            "Epoch 67/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9166 - precision: 0.8513 - recall: 0.8137 - val_loss: 0.9217 - val_precision: 0.8301 - val_recall: 0.7935\n",
            "Epoch 68/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9161 - precision: 0.8523 - recall: 0.8151 - val_loss: 0.9210 - val_precision: 0.8303 - val_recall: 0.7955\n",
            "Epoch 69/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9163 - precision: 0.8515 - recall: 0.8144 - val_loss: 0.9214 - val_precision: 0.8297 - val_recall: 0.7948\n",
            "Epoch 70/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9161 - precision: 0.8516 - recall: 0.8149 - val_loss: 0.9214 - val_precision: 0.8279 - val_recall: 0.7943\n",
            "Epoch 71/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9166 - precision: 0.8512 - recall: 0.8143 - val_loss: 0.9210 - val_precision: 0.8297 - val_recall: 0.7958\n",
            "Epoch 72/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9164 - precision: 0.8511 - recall: 0.8140 - val_loss: 0.9225 - val_precision: 0.8258 - val_recall: 0.7904\n",
            "Epoch 73/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9165 - precision: 0.8508 - recall: 0.8140 - val_loss: 0.9220 - val_precision: 0.8279 - val_recall: 0.7911\n",
            "Epoch 74/75\n",
            "95/95 [==============================] - 3s 35ms/step - loss: 0.9164 - precision: 0.8506 - recall: 0.8149 - val_loss: 0.9220 - val_precision: 0.8275 - val_recall: 0.7928\n",
            "Epoch 75/75\n",
            "95/95 [==============================] - 3s 34ms/step - loss: 0.9160 - precision: 0.8517 - recall: 0.8161 - val_loss: 0.9216 - val_precision: 0.8296 - val_recall: 0.7942\n",
            "Config Space:\n",
            " {'batch_size': 9, 'learning_rate': 0.004740049723020277, 'optimizer': 'adam', 'sgd_momentum': 0.08967610463914634}\n",
            "Epoch 1/75\n",
            "116/116 [==============================] - 6s 37ms/step - loss: 0.9793 - precision: 0.8078 - recall: 0.4944 - val_loss: 0.9620 - val_precision: 0.8185 - val_recall: 0.5948\n",
            "Epoch 2/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9544 - precision: 0.8105 - recall: 0.6448 - val_loss: 0.9570 - val_precision: 0.7834 - val_recall: 0.6721\n",
            "Epoch 3/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9484 - precision: 0.7986 - recall: 0.6951 - val_loss: 0.9525 - val_precision: 0.7839 - val_recall: 0.7289\n",
            "Epoch 4/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9410 - precision: 0.8050 - recall: 0.7344 - val_loss: 0.9547 - val_precision: 0.7703 - val_recall: 0.7082\n",
            "Epoch 5/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9383 - precision: 0.8068 - recall: 0.7459 - val_loss: 0.9483 - val_precision: 0.7787 - val_recall: 0.7252\n",
            "Epoch 6/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9365 - precision: 0.8115 - recall: 0.7524 - val_loss: 0.9400 - val_precision: 0.8007 - val_recall: 0.7321\n",
            "Epoch 7/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9348 - precision: 0.8163 - recall: 0.7575 - val_loss: 0.9444 - val_precision: 0.7924 - val_recall: 0.7197\n",
            "Epoch 8/75\n",
            "116/116 [==============================] - 4s 30ms/step - loss: 0.9331 - precision: 0.8201 - recall: 0.7635 - val_loss: 0.9353 - val_precision: 0.8112 - val_recall: 0.7544\n",
            "Epoch 9/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9321 - precision: 0.8228 - recall: 0.7671 - val_loss: 0.9326 - val_precision: 0.8215 - val_recall: 0.7612\n",
            "Epoch 10/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9305 - precision: 0.8263 - recall: 0.7739 - val_loss: 0.9329 - val_precision: 0.8189 - val_recall: 0.7646\n",
            "Epoch 11/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9284 - precision: 0.8318 - recall: 0.7801 - val_loss: 0.9322 - val_precision: 0.8248 - val_recall: 0.7599\n",
            "Epoch 12/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9280 - precision: 0.8325 - recall: 0.7810 - val_loss: 0.9315 - val_precision: 0.8180 - val_recall: 0.7640\n",
            "Epoch 13/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9268 - precision: 0.8348 - recall: 0.7847 - val_loss: 0.9287 - val_precision: 0.8194 - val_recall: 0.7661\n",
            "Epoch 14/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9259 - precision: 0.8372 - recall: 0.7877 - val_loss: 0.9277 - val_precision: 0.8218 - val_recall: 0.7756\n",
            "Epoch 15/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9249 - precision: 0.8399 - recall: 0.7907 - val_loss: 0.9283 - val_precision: 0.8188 - val_recall: 0.7652\n",
            "Epoch 16/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9241 - precision: 0.8409 - recall: 0.7932 - val_loss: 0.9265 - val_precision: 0.8228 - val_recall: 0.7721\n",
            "Epoch 17/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9236 - precision: 0.8424 - recall: 0.7942 - val_loss: 0.9264 - val_precision: 0.8201 - val_recall: 0.7716\n",
            "Epoch 18/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9232 - precision: 0.8427 - recall: 0.7953 - val_loss: 0.9254 - val_precision: 0.8213 - val_recall: 0.7741\n",
            "Epoch 19/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9222 - precision: 0.8450 - recall: 0.7987 - val_loss: 0.9236 - val_precision: 0.8279 - val_recall: 0.7837\n",
            "Epoch 20/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9224 - precision: 0.8447 - recall: 0.7979 - val_loss: 0.9241 - val_precision: 0.8232 - val_recall: 0.7791\n",
            "Epoch 21/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9222 - precision: 0.8451 - recall: 0.7984 - val_loss: 0.9239 - val_precision: 0.8248 - val_recall: 0.7813\n",
            "Epoch 22/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9215 - precision: 0.8463 - recall: 0.7998 - val_loss: 0.9237 - val_precision: 0.8265 - val_recall: 0.7824\n",
            "Epoch 23/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9214 - precision: 0.8465 - recall: 0.8004 - val_loss: 0.9229 - val_precision: 0.8297 - val_recall: 0.7849\n",
            "Epoch 24/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9210 - precision: 0.8472 - recall: 0.8018 - val_loss: 0.9219 - val_precision: 0.8332 - val_recall: 0.7886\n",
            "Epoch 25/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9211 - precision: 0.8473 - recall: 0.8016 - val_loss: 0.9212 - val_precision: 0.8362 - val_recall: 0.7937\n",
            "Epoch 26/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9210 - precision: 0.8471 - recall: 0.8021 - val_loss: 0.9222 - val_precision: 0.8310 - val_recall: 0.7873\n",
            "Epoch 27/75\n",
            "116/116 [==============================] - 4s 30ms/step - loss: 0.9202 - precision: 0.8488 - recall: 0.8040 - val_loss: 0.9211 - val_precision: 0.8366 - val_recall: 0.7934\n",
            "Epoch 28/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9202 - precision: 0.8484 - recall: 0.8036 - val_loss: 0.9220 - val_precision: 0.8317 - val_recall: 0.7871\n",
            "Epoch 29/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9201 - precision: 0.8490 - recall: 0.8044 - val_loss: 0.9211 - val_precision: 0.8352 - val_recall: 0.7937\n",
            "Epoch 30/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9195 - precision: 0.8494 - recall: 0.8052 - val_loss: 0.9230 - val_precision: 0.8269 - val_recall: 0.7790\n",
            "Epoch 31/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9199 - precision: 0.8492 - recall: 0.8044 - val_loss: 0.9219 - val_precision: 0.8299 - val_recall: 0.7871\n",
            "Epoch 32/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9192 - precision: 0.8503 - recall: 0.8067 - val_loss: 0.9218 - val_precision: 0.8299 - val_recall: 0.7915\n",
            "Epoch 33/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9194 - precision: 0.8497 - recall: 0.8062 - val_loss: 0.9228 - val_precision: 0.8275 - val_recall: 0.7821\n",
            "Epoch 34/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9192 - precision: 0.8502 - recall: 0.8066 - val_loss: 0.9221 - val_precision: 0.8292 - val_recall: 0.7846\n",
            "Epoch 35/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9186 - precision: 0.8513 - recall: 0.8080 - val_loss: 0.9221 - val_precision: 0.8280 - val_recall: 0.7870\n",
            "Epoch 36/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9188 - precision: 0.8509 - recall: 0.8078 - val_loss: 0.9222 - val_precision: 0.8264 - val_recall: 0.7875\n",
            "Epoch 37/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9186 - precision: 0.8514 - recall: 0.8078 - val_loss: 0.9218 - val_precision: 0.8278 - val_recall: 0.7857\n",
            "Epoch 38/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9184 - precision: 0.8518 - recall: 0.8087 - val_loss: 0.9214 - val_precision: 0.8326 - val_recall: 0.7902\n",
            "Epoch 39/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9183 - precision: 0.8523 - recall: 0.8090 - val_loss: 0.9218 - val_precision: 0.8302 - val_recall: 0.7889\n",
            "Epoch 40/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9179 - precision: 0.8531 - recall: 0.8098 - val_loss: 0.9211 - val_precision: 0.8316 - val_recall: 0.7912\n",
            "Epoch 41/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9178 - precision: 0.8534 - recall: 0.8104 - val_loss: 0.9207 - val_precision: 0.8356 - val_recall: 0.7939\n",
            "Epoch 42/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9180 - precision: 0.8526 - recall: 0.8094 - val_loss: 0.9231 - val_precision: 0.8237 - val_recall: 0.7787\n",
            "Epoch 43/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9181 - precision: 0.8528 - recall: 0.8089 - val_loss: 0.9228 - val_precision: 0.8228 - val_recall: 0.7830\n",
            "Epoch 44/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9173 - precision: 0.8537 - recall: 0.8111 - val_loss: 0.9219 - val_precision: 0.8288 - val_recall: 0.7883\n",
            "Epoch 45/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9173 - precision: 0.8541 - recall: 0.8110 - val_loss: 0.9220 - val_precision: 0.8304 - val_recall: 0.7866\n",
            "Epoch 46/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9176 - precision: 0.8537 - recall: 0.8097 - val_loss: 0.9220 - val_precision: 0.8270 - val_recall: 0.7847\n",
            "Epoch 47/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9171 - precision: 0.8544 - recall: 0.8120 - val_loss: 0.9216 - val_precision: 0.8285 - val_recall: 0.7886\n",
            "Epoch 48/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9173 - precision: 0.8539 - recall: 0.8112 - val_loss: 0.9201 - val_precision: 0.8348 - val_recall: 0.7972\n",
            "Epoch 49/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9176 - precision: 0.8518 - recall: 0.8098 - val_loss: 0.9220 - val_precision: 0.8261 - val_recall: 0.7831\n",
            "Epoch 50/75\n",
            "116/116 [==============================] - 4s 30ms/step - loss: 0.9168 - precision: 0.8543 - recall: 0.8126 - val_loss: 0.9213 - val_precision: 0.8285 - val_recall: 0.7934\n",
            "Epoch 51/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9169 - precision: 0.8528 - recall: 0.8129 - val_loss: 0.9208 - val_precision: 0.8298 - val_recall: 0.7918\n",
            "Epoch 52/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9164 - precision: 0.8533 - recall: 0.8142 - val_loss: 0.9216 - val_precision: 0.8271 - val_recall: 0.7860\n",
            "Epoch 53/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9163 - precision: 0.8531 - recall: 0.8145 - val_loss: 0.9204 - val_precision: 0.8342 - val_recall: 0.7930\n",
            "Epoch 54/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9166 - precision: 0.8527 - recall: 0.8142 - val_loss: 0.9211 - val_precision: 0.8296 - val_recall: 0.7897\n",
            "Epoch 55/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9165 - precision: 0.8528 - recall: 0.8151 - val_loss: 0.9214 - val_precision: 0.8299 - val_recall: 0.7924\n",
            "Epoch 56/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9169 - precision: 0.8517 - recall: 0.8135 - val_loss: 0.9227 - val_precision: 0.8246 - val_recall: 0.7862\n",
            "Epoch 57/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9167 - precision: 0.8519 - recall: 0.8135 - val_loss: 0.9203 - val_precision: 0.8297 - val_recall: 0.7910\n",
            "Epoch 58/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9160 - precision: 0.8531 - recall: 0.8159 - val_loss: 0.9217 - val_precision: 0.8258 - val_recall: 0.7864\n",
            "Epoch 59/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9160 - precision: 0.8529 - recall: 0.8159 - val_loss: 0.9229 - val_precision: 0.8234 - val_recall: 0.7846\n",
            "Epoch 60/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9171 - precision: 0.8518 - recall: 0.8130 - val_loss: 0.9225 - val_precision: 0.8296 - val_recall: 0.7884\n",
            "Epoch 61/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9167 - precision: 0.8521 - recall: 0.8142 - val_loss: 0.9213 - val_precision: 0.8264 - val_recall: 0.7904\n",
            "Epoch 62/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9163 - precision: 0.8521 - recall: 0.8157 - val_loss: 0.9216 - val_precision: 0.8262 - val_recall: 0.7902\n",
            "Epoch 63/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9160 - precision: 0.8536 - recall: 0.8167 - val_loss: 0.9199 - val_precision: 0.8320 - val_recall: 0.7950\n",
            "Epoch 64/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9160 - precision: 0.8530 - recall: 0.8171 - val_loss: 0.9201 - val_precision: 0.8339 - val_recall: 0.7970\n",
            "Epoch 65/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9156 - precision: 0.8540 - recall: 0.8184 - val_loss: 0.9204 - val_precision: 0.8343 - val_recall: 0.7954\n",
            "Epoch 66/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9157 - precision: 0.8538 - recall: 0.8178 - val_loss: 0.9211 - val_precision: 0.8284 - val_recall: 0.7892\n",
            "Epoch 67/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9155 - precision: 0.8540 - recall: 0.8185 - val_loss: 0.9198 - val_precision: 0.8373 - val_recall: 0.8017\n",
            "Epoch 68/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9157 - precision: 0.8534 - recall: 0.8178 - val_loss: 0.9200 - val_precision: 0.8331 - val_recall: 0.7978\n",
            "Epoch 69/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9157 - precision: 0.8532 - recall: 0.8172 - val_loss: 0.9204 - val_precision: 0.8302 - val_recall: 0.7939\n",
            "Epoch 70/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9154 - precision: 0.8538 - recall: 0.8186 - val_loss: 0.9195 - val_precision: 0.8348 - val_recall: 0.7998\n",
            "Epoch 71/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9156 - precision: 0.8537 - recall: 0.8185 - val_loss: 0.9206 - val_precision: 0.8307 - val_recall: 0.7955\n",
            "Epoch 72/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9155 - precision: 0.8535 - recall: 0.8183 - val_loss: 0.9188 - val_precision: 0.8376 - val_recall: 0.8023\n",
            "Epoch 73/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9154 - precision: 0.8535 - recall: 0.8186 - val_loss: 0.9216 - val_precision: 0.8274 - val_recall: 0.7892\n",
            "Epoch 74/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9153 - precision: 0.8540 - recall: 0.8187 - val_loss: 0.9193 - val_precision: 0.8346 - val_recall: 0.7993\n",
            "Epoch 75/75\n",
            "116/116 [==============================] - 3s 30ms/step - loss: 0.9149 - precision: 0.8545 - recall: 0.8201 - val_loss: 0.9198 - val_precision: 0.8337 - val_recall: 0.7966\n",
            "Config Space:\n",
            " {'batch_size': 4, 'learning_rate': 0.003905085427973375, 'optimizer': 'adam', 'sgd_momentum': 0.25946352029027697}\n",
            "Epoch 1/75\n",
            "261/261 [==============================] - 7s 21ms/step - loss: 0.9800 - precision: 0.8122 - recall: 0.5319 - val_loss: 0.9681 - val_precision: 0.8249 - val_recall: 0.5999\n",
            "Epoch 2/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9636 - precision: 0.7921 - recall: 0.6352 - val_loss: 0.9643 - val_precision: 0.7837 - val_recall: 0.6647\n",
            "Epoch 3/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9573 - precision: 0.7847 - recall: 0.6841 - val_loss: 0.9615 - val_precision: 0.7772 - val_recall: 0.6891\n",
            "Epoch 4/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9538 - precision: 0.7894 - recall: 0.7023 - val_loss: 0.9584 - val_precision: 0.7831 - val_recall: 0.7036\n",
            "Epoch 5/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9521 - precision: 0.7927 - recall: 0.7102 - val_loss: 0.9552 - val_precision: 0.7879 - val_recall: 0.7134\n",
            "Epoch 6/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9509 - precision: 0.7945 - recall: 0.7154 - val_loss: 0.9541 - val_precision: 0.7903 - val_recall: 0.7169\n",
            "Epoch 7/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9499 - precision: 0.7962 - recall: 0.7203 - val_loss: 0.9536 - val_precision: 0.7890 - val_recall: 0.7211\n",
            "Epoch 8/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9492 - precision: 0.7978 - recall: 0.7241 - val_loss: 0.9527 - val_precision: 0.7914 - val_recall: 0.7234\n",
            "Epoch 9/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9483 - precision: 0.7999 - recall: 0.7286 - val_loss: 0.9513 - val_precision: 0.7960 - val_recall: 0.7251\n",
            "Epoch 10/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9474 - precision: 0.8019 - recall: 0.7325 - val_loss: 0.9505 - val_precision: 0.7994 - val_recall: 0.7266\n",
            "Epoch 11/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9467 - precision: 0.8034 - recall: 0.7356 - val_loss: 0.9492 - val_precision: 0.8002 - val_recall: 0.7328\n",
            "Epoch 12/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9462 - precision: 0.8046 - recall: 0.7381 - val_loss: 0.9487 - val_precision: 0.8016 - val_recall: 0.7339\n",
            "Epoch 13/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9457 - precision: 0.8054 - recall: 0.7399 - val_loss: 0.9482 - val_precision: 0.8027 - val_recall: 0.7350\n",
            "Epoch 14/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9455 - precision: 0.8057 - recall: 0.7410 - val_loss: 0.9480 - val_precision: 0.8035 - val_recall: 0.7366\n",
            "Epoch 15/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9452 - precision: 0.8061 - recall: 0.7418 - val_loss: 0.9470 - val_precision: 0.8027 - val_recall: 0.7411\n",
            "Epoch 16/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9448 - precision: 0.8069 - recall: 0.7433 - val_loss: 0.9467 - val_precision: 0.8035 - val_recall: 0.7420\n",
            "Epoch 17/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9445 - precision: 0.8074 - recall: 0.7445 - val_loss: 0.9468 - val_precision: 0.8036 - val_recall: 0.7424\n",
            "Epoch 18/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9444 - precision: 0.8078 - recall: 0.7451 - val_loss: 0.9464 - val_precision: 0.8042 - val_recall: 0.7439\n",
            "Epoch 19/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9441 - precision: 0.8081 - recall: 0.7459 - val_loss: 0.9460 - val_precision: 0.8049 - val_recall: 0.7448\n",
            "Epoch 20/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9441 - precision: 0.8083 - recall: 0.7462 - val_loss: 0.9459 - val_precision: 0.8044 - val_recall: 0.7462\n",
            "Epoch 21/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9439 - precision: 0.8085 - recall: 0.7469 - val_loss: 0.9459 - val_precision: 0.8046 - val_recall: 0.7473\n",
            "Epoch 22/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9438 - precision: 0.8088 - recall: 0.7474 - val_loss: 0.9458 - val_precision: 0.8048 - val_recall: 0.7483\n",
            "Epoch 23/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9436 - precision: 0.8092 - recall: 0.7479 - val_loss: 0.9454 - val_precision: 0.8054 - val_recall: 0.7498\n",
            "Epoch 24/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9435 - precision: 0.8095 - recall: 0.7481 - val_loss: 0.9454 - val_precision: 0.8053 - val_recall: 0.7499\n",
            "Epoch 25/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9434 - precision: 0.8097 - recall: 0.7485 - val_loss: 0.9453 - val_precision: 0.8051 - val_recall: 0.7511\n",
            "Epoch 26/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9433 - precision: 0.8100 - recall: 0.7490 - val_loss: 0.9451 - val_precision: 0.8058 - val_recall: 0.7516\n",
            "Epoch 27/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9432 - precision: 0.8101 - recall: 0.7493 - val_loss: 0.9452 - val_precision: 0.8054 - val_recall: 0.7522\n",
            "Epoch 28/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9431 - precision: 0.8104 - recall: 0.7500 - val_loss: 0.9451 - val_precision: 0.8054 - val_recall: 0.7525\n",
            "Epoch 29/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9430 - precision: 0.8106 - recall: 0.7503 - val_loss: 0.9451 - val_precision: 0.8050 - val_recall: 0.7529\n",
            "Epoch 30/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9429 - precision: 0.8108 - recall: 0.7508 - val_loss: 0.9451 - val_precision: 0.8052 - val_recall: 0.7528\n",
            "Epoch 31/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9428 - precision: 0.8110 - recall: 0.7509 - val_loss: 0.9449 - val_precision: 0.8054 - val_recall: 0.7535\n",
            "Epoch 32/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9427 - precision: 0.8114 - recall: 0.7515 - val_loss: 0.9449 - val_precision: 0.8058 - val_recall: 0.7532\n",
            "Epoch 33/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9426 - precision: 0.8114 - recall: 0.7516 - val_loss: 0.9448 - val_precision: 0.8055 - val_recall: 0.7542\n",
            "Epoch 34/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9425 - precision: 0.8116 - recall: 0.7522 - val_loss: 0.9449 - val_precision: 0.8049 - val_recall: 0.7543\n",
            "Epoch 35/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9425 - precision: 0.8116 - recall: 0.7525 - val_loss: 0.9446 - val_precision: 0.8058 - val_recall: 0.7548\n",
            "Epoch 36/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9423 - precision: 0.8118 - recall: 0.7529 - val_loss: 0.9446 - val_precision: 0.8058 - val_recall: 0.7553\n",
            "Epoch 37/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9422 - precision: 0.8122 - recall: 0.7534 - val_loss: 0.9443 - val_precision: 0.8063 - val_recall: 0.7559\n",
            "Epoch 38/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9421 - precision: 0.8125 - recall: 0.7538 - val_loss: 0.9446 - val_precision: 0.8051 - val_recall: 0.7557\n",
            "Epoch 39/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9420 - precision: 0.8125 - recall: 0.7541 - val_loss: 0.9442 - val_precision: 0.8067 - val_recall: 0.7566\n",
            "Epoch 40/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9419 - precision: 0.8126 - recall: 0.7543 - val_loss: 0.9442 - val_precision: 0.8066 - val_recall: 0.7570\n",
            "Epoch 41/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9418 - precision: 0.8129 - recall: 0.7548 - val_loss: 0.9440 - val_precision: 0.8069 - val_recall: 0.7569\n",
            "Epoch 42/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9417 - precision: 0.8131 - recall: 0.7552 - val_loss: 0.9440 - val_precision: 0.8072 - val_recall: 0.7574\n",
            "Epoch 43/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9417 - precision: 0.8133 - recall: 0.7554 - val_loss: 0.9439 - val_precision: 0.8074 - val_recall: 0.7576\n",
            "Epoch 44/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9416 - precision: 0.8135 - recall: 0.7558 - val_loss: 0.9438 - val_precision: 0.8076 - val_recall: 0.7581\n",
            "Epoch 45/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9415 - precision: 0.8136 - recall: 0.7560 - val_loss: 0.9438 - val_precision: 0.8072 - val_recall: 0.7580\n",
            "Epoch 46/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9415 - precision: 0.8136 - recall: 0.7561 - val_loss: 0.9439 - val_precision: 0.8070 - val_recall: 0.7577\n",
            "Epoch 47/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9414 - precision: 0.8138 - recall: 0.7566 - val_loss: 0.9440 - val_precision: 0.8066 - val_recall: 0.7575\n",
            "Epoch 48/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9413 - precision: 0.8139 - recall: 0.7569 - val_loss: 0.9438 - val_precision: 0.8070 - val_recall: 0.7581\n",
            "Epoch 49/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9412 - precision: 0.8141 - recall: 0.7574 - val_loss: 0.9439 - val_precision: 0.8064 - val_recall: 0.7578\n",
            "Epoch 50/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9412 - precision: 0.8143 - recall: 0.7577 - val_loss: 0.9437 - val_precision: 0.8067 - val_recall: 0.7584\n",
            "Epoch 51/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9411 - precision: 0.8144 - recall: 0.7580 - val_loss: 0.9436 - val_precision: 0.8068 - val_recall: 0.7588\n",
            "Epoch 52/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9411 - precision: 0.8143 - recall: 0.7582 - val_loss: 0.9435 - val_precision: 0.8068 - val_recall: 0.7594\n",
            "Epoch 53/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9410 - precision: 0.8144 - recall: 0.7585 - val_loss: 0.9435 - val_precision: 0.8068 - val_recall: 0.7590\n",
            "Epoch 54/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9410 - precision: 0.8145 - recall: 0.7587 - val_loss: 0.9434 - val_precision: 0.8068 - val_recall: 0.7598\n",
            "Epoch 55/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9410 - precision: 0.8145 - recall: 0.7589 - val_loss: 0.9434 - val_precision: 0.8069 - val_recall: 0.7599\n",
            "Epoch 56/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9409 - precision: 0.8147 - recall: 0.7592 - val_loss: 0.9434 - val_precision: 0.8068 - val_recall: 0.7598\n",
            "Epoch 57/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9408 - precision: 0.8147 - recall: 0.7595 - val_loss: 0.9433 - val_precision: 0.8069 - val_recall: 0.7599\n",
            "Epoch 58/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9408 - precision: 0.8148 - recall: 0.7597 - val_loss: 0.9434 - val_precision: 0.8065 - val_recall: 0.7602\n",
            "Epoch 59/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9408 - precision: 0.8148 - recall: 0.7598 - val_loss: 0.9431 - val_precision: 0.8071 - val_recall: 0.7608\n",
            "Epoch 60/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9407 - precision: 0.8149 - recall: 0.7601 - val_loss: 0.9430 - val_precision: 0.8074 - val_recall: 0.7611\n",
            "Epoch 61/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9407 - precision: 0.8150 - recall: 0.7604 - val_loss: 0.9431 - val_precision: 0.8069 - val_recall: 0.7610\n",
            "Epoch 62/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9406 - precision: 0.8150 - recall: 0.7605 - val_loss: 0.9430 - val_precision: 0.8072 - val_recall: 0.7613\n",
            "Epoch 63/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9406 - precision: 0.8151 - recall: 0.7606 - val_loss: 0.9429 - val_precision: 0.8073 - val_recall: 0.7616\n",
            "Epoch 64/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9406 - precision: 0.8151 - recall: 0.7609 - val_loss: 0.9429 - val_precision: 0.8076 - val_recall: 0.7617\n",
            "Epoch 65/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9405 - precision: 0.8153 - recall: 0.7610 - val_loss: 0.9427 - val_precision: 0.8079 - val_recall: 0.7622\n",
            "Epoch 66/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9404 - precision: 0.8153 - recall: 0.7613 - val_loss: 0.9427 - val_precision: 0.8077 - val_recall: 0.7621\n",
            "Epoch 67/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9404 - precision: 0.8154 - recall: 0.7614 - val_loss: 0.9426 - val_precision: 0.8080 - val_recall: 0.7624\n",
            "Epoch 68/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9404 - precision: 0.8155 - recall: 0.7615 - val_loss: 0.9425 - val_precision: 0.8086 - val_recall: 0.7630\n",
            "Epoch 69/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9404 - precision: 0.8157 - recall: 0.7616 - val_loss: 0.9426 - val_precision: 0.8081 - val_recall: 0.7627\n",
            "Epoch 70/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9403 - precision: 0.8157 - recall: 0.7619 - val_loss: 0.9424 - val_precision: 0.8086 - val_recall: 0.7635\n",
            "Epoch 71/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9403 - precision: 0.8158 - recall: 0.7621 - val_loss: 0.9424 - val_precision: 0.8085 - val_recall: 0.7633\n",
            "Epoch 72/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9402 - precision: 0.8158 - recall: 0.7621 - val_loss: 0.9423 - val_precision: 0.8086 - val_recall: 0.7638\n",
            "Epoch 73/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9402 - precision: 0.8158 - recall: 0.7623 - val_loss: 0.9424 - val_precision: 0.8085 - val_recall: 0.7638\n",
            "Epoch 74/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9402 - precision: 0.8158 - recall: 0.7624 - val_loss: 0.9423 - val_precision: 0.8089 - val_recall: 0.7639\n",
            "Epoch 75/75\n",
            "261/261 [==============================] - 4s 17ms/step - loss: 0.9402 - precision: 0.8159 - recall: 0.7625 - val_loss: 0.9424 - val_precision: 0.8085 - val_recall: 0.7639\n",
            "Config Space:\n",
            " {'batch_size': 13, 'learning_rate': 0.004852860608821996, 'optimizer': 'adam', 'sgd_momentum': 0.09843644499867876}\n",
            "Epoch 1/25\n",
            "41/81 [==============>...............] - ETA: 1s - loss: 0.9955 - precision: 0.8208 - recall: 0.4181"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4312c198b11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m bohb = BOHB(configspace=worker.get_configspace(), run_id='example1', \n\u001b[1;32m     11\u001b[0m             nameserver='127.0.0.1', min_budget=25, max_budget=75)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbohb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hpbandster/core/master.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                         \u001b[0mnext_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/hpbandster/core/master.py\u001b[0m in \u001b[0;36m_queue_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HBMASTER: running jobs: %i, queue sizes: %s -> wait'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_submit_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bohb.shutdown(shutdown_workers=True)\n",
        "NS.shutdown()"
      ],
      "metadata": {
        "id": "C34NqifUkFt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_36_iterations=[\n",
        "    {'batch_size': 25, 'learning_rate': 0.010423454645547298, 'optimizer': 'adam', 'sgd_momentum': 0.43521186058412903, 'budget': 25, 'loss': 1.2951, 'val_loss': 1.2842, 'precision': 0.54, 'recall': 0.54},\n",
        "    {'batch_size': 26, 'learning_rate': 0.0006325494254217899, 'optimizer': 'sgd', 'sgd_momentum': 0.20260222918369616, 'budget': 25, 'loss': 1.0178, 'val_loss': 1.0177, 'precision': 0.9038, 'recall': 0.0000318},\n",
        "    {'batch_size': 30, 'learning_rate': 0.006410637905687802, 'optimizer': 'sgd', 'sgd_momentum': 0.10204604192227403, 'budget': 25, 'loss': 1.0010, 'val_loss': 0.9982, 'precision': 0.8050, 'recall': 0.4666},\n",
        "    {'batch_size': 30, 'learning_rate': 0.006410637905687802, 'optimizer': 'sgd', 'sgd_momentum': 0.10204604192227403, 'budget': 75, 'loss': 0.9958, 'val_loss': 0.9939, 'precision': 0.8305, 'recall': 0.4423},\n",
        "    {'batch_size': 6, 'learning_rate': 0.00044712998042093497, 'optimizer': 'sgd', 'sgd_momentum': 0.6244634986402445, 'budget': 75, 'loss': 0.9970, 'val_loss': 0.9962, 'precision': 0.8313, 'recall': 0.4437},\n",
        "    {'batch_size': 30, 'learning_rate': 0.0002555337726396552, 'optimizer': 'adam', 'sgd_momentum': 0.11425434943877688, 'budget': 75, 'loss': 0.8888, 'val_loss': 0.9412, 'precision': 0.8058, 'recall': 0.7889},\n",
        "    {'batch_size': 24, 'learning_rate': 0.0012444573981454413, 'optimizer': 'adam', 'sgd_momentum': 0.22181057142726812, 'budget': 25, 'loss': 0.9066, 'val_loss': 0.9241, 'precision': 0.8336, 'recall': 0.8034},\n",
        "    {'batch_size': 11, 'learning_rate': 0.000921560725725206, 'optimizer': 'sgd', 'sgd_momentum': 0.28005263182984264, 'budget': 25, 'loss': 1.0055, 'val_loss': 1.0026, 'precision': 0.8369, 'recall': 0.4438},\n",
        "    {'batch_size': 26, 'learning_rate': 0.0008617202284439472, 'optimizer': 'sgd', 'sgd_momentum': 0.9596310724837166, 'budget': 25, 'loss': 0.9940, 'val_loss': 0.9922, 'precision': 0.8025, 'recall': 0.4704},\n",
        "    {'batch_size': 24, 'learning_rate': 0.0012444573981454413, 'optimizer': 'adam', 'sgd_momentum': 0.22181057142726812, 'budget': 75, 'loss': 0.8981, 'val_loss': 0.9126, 'precision': 0.8549, 'recall': 0.8328},\n",
        "    {'batch_size': 23, 'learning_rate': 0.012702172114669764, 'optimizer': 'adam', 'sgd_momentum': 0.5591241916566293, 'budget': 75, 'loss': 0.9411, 'val_loss': 0.9445, 'precision': 0.7746, 'recall': 0.7079},\n",
        "    {'batch_size': 9, 'learning_rate': 0.05169249868326114, 'optimizer': 'sgd', 'sgd_momentum': 0.36091461749398956, 'budget': 75, 'loss': 0.9234, 'val_loss': 0.9470, 'precision': 0.7787, 'recall': 0.7364},\n",
        "    {'batch_size': 11, 'learning_rate': 0.00393196591281057, 'optimizer': 'adam', 'sgd_momentum': 0.392466295122575, 'budget': 25, 'loss': 0.9144, 'val_loss': 0.9203, 'precision': 0.8297, 'recall': 0.7990},\n",
        "    {'batch_size': 7, 'learning_rate': 0.005020592553323891, 'optimizer': 'adam', 'sgd_momentum': 0.4285698435087847, 'budget': 25, 'loss': 0.9395, 'val_loss': 0.9389, 'precision': 0.8032, 'recall': 0.7463},\n",
        "    {'batch_size': 25, 'learning_rate': 0.033130188028715805, 'optimizer': 'sgd', 'sgd_momentum': 0.7767336836177672, 'budget': 25, 'loss': 0.9536, 'val_loss': 0.9662, 'precision': 0.7420, 'recall': 0.6090},\n",
        "    {'batch_size': 11, 'learning_rate': 0.00393196591281057, 'optimizer': 'adam', 'sgd_momentum': 0.392466295122575, 'budget': 75, 'loss': 0.9130, 'val_loss': 0.9147, 'precision': 0.8437, 'recall': 0.8106},\n",
        "    {'batch_size': 23, 'learning_rate': 0.0032847542515781567, 'optimizer': 'adam', 'sgd_momentum': 0.8016755715024376, 'budget': 75, 'loss': 0.9001, 'val_loss': 0.9171, 'precision': 0.8321, 'recall': 0.8160},\n",
        "    {'batch_size': 26, 'learning_rate': 0.004794279849735609, 'optimizer': 'sgd', 'sgd_momentum': 0.12276821185304304, 'budget': 75, 'loss': 0.9952, 'val_loss': 0.9940, 'precision': 0.8080, 'recall': 0.4617},\n",
        "    {'batch_size': 1, 'learning_rate': 0.035252990416093734, 'optimizer': 'adam', 'sgd_momentum': 0.9226147983361845, 'budget': 25, 'loss': 1.5115, 'val_loss': 1.5067, 'precision': 0.1425, 'recall': 0.1425},\n",
        "    {'batch_size': 24, 'learning_rate': 0.000504924978646984, 'optimizer': 'sgd', 'sgd_momentum': 0.9886347100920375, 'budget': 25, 'loss': 0.9943, 'val_loss': 0.9932, 'precision': 0.8296, 'recall': 0.4517},\n",
        "    {'batch_size': 28, 'learning_rate': 0.061566996059290544, 'optimizer': 'sgd', 'sgd_momentum': 0.9387601099445818, 'budget': 25, 'loss': 0.9362, 'val_loss': 0.9512, 'precision': 0.7744, 'recall': 0.6954},\n",
        "    {'batch_size': 28, 'learning_rate': 0.061566996059290544, 'optimizer': 'sgd', 'sgd_momentum': 0.9387601099445818, 'budget': 75, 'loss': 0.9148, 'val_loss': 0.9287, 'precision': 0.8206, 'recall': 0.7839},\n",
        "    {'batch_size': 24, 'learning_rate': 0.00012765657043279643, 'optimizer': 'adam', 'sgd_momentum': 0.06482325264227154, 'budget': 75, 'loss': 0.8963, 'val_loss': 0.9619, 'precision': 0.7486, 'recall': 0.7406},\n",
        "    {'batch_size': 29, 'learning_rate': 0.000362997661710239, 'optimizer': 'adam', 'sgd_momentum': 0.980606513386686, 'budget': 75, 'loss': 0.8727, 'val_loss': 0.9247, 'precision': 0.8294, 'recall': 0.8178},\n",
        "    {'batch_size': 27, 'learning_rate': 0.000559449566703158, 'optimizer': 'adam', 'sgd_momentum': 0.8351797515182519, 'budget': 25, 'loss': 0.9087, 'val_loss': 0.9307, 'precision': 0.8155, 'recall': 0.7799},\n",
        "    {'batch_size': 30, 'learning_rate': 0.00020648284618882698, 'optimizer': 'sgd', 'sgd_momentum': 0.15901342208840763, 'budget': 25, 'loss': 1.0212, 'val_loss': 1.0226, 'precision': 0., 'recall': 0.},\n",
        "    {'batch_size': 24, 'learning_rate': 0.02619168430040626, 'optimizer': 'sgd', 'sgd_momentum': 0.08896231525961767, 'budget': 25, 'loss': 0.9909, 'val_loss': 0.9900, 'precision': 0.8293, 'recall': 0.4482},\n",
        "    {'batch_size': 27, 'learning_rate': 0.000559449566703158, 'optimizer': 'adam', 'sgd_momentum': 0.8351797515182519, 'budget': 75, 'loss': 0.8792, 'val_loss': 0.9177, 'precision': 0.8431, 'recall': 0.8303},\n",
        "    {'batch_size': 30, 'learning_rate': 0.0003735348770269236, 'optimizer': 'adam', 'sgd_momentum': 0.8584977116587138, 'budget': 75, 'loss': 0.8828, 'val_loss': 0.9210, 'precision': 0.8303, 'recall': 0.8167},\n",
        "    {'batch_size': 31, 'learning_rate': 0.0003401549016294108, 'optimizer': 'adam', 'sgd_momentum': 0.9254391870088128, 'budget': 75, 'loss': 0.8739, 'val_loss': 0.9247, 'precision': 0.8335, 'recall': 0.8183},\n",
        "    {'batch_size': 11, 'learning_rate': 0.006379790977696792, 'optimizer': 'adam', 'sgd_momentum': 0.18897151412792534, 'budget': 25, 'loss': 0.9218, 'val_loss': 0.9277, 'precision': 0.8166, 'recall': 0.7696},\n",
        "    {'batch_size': 23, 'learning_rate': 0.0029896701407367146, 'optimizer': 'sgd', 'sgd_momentum': 0.5460870135101618, 'budget': 25, 'loss': 1.0035, 'val_loss': 1.0015, 'precision': 0.8820, 'recall': 0.3698},\n",
        "    {'batch_size': 6, 'learning_rate': 0.002547859030004373, 'optimizer': 'adam', 'sgd_momentum': 0.05517169349458934, 'budget': 25, 'loss': 0.9233, 'val_loss': 0.9271, 'precision': 0.8403, 'recall': 0.7984},\n",
        "    {'batch_size': 11, 'learning_rate': 0.006379790977696792, 'optimizer': 'adam', 'sgd_momentum': 0.18897151412792534, 'budget': 75, 'loss': 0.9160, 'val_loss': 0.9216, 'precision': 0.8296, 'recall': 0.7942},\n",
        "    {'batch_size': 9, 'learning_rate': 0.004740049723020277, 'optimizer': 'adam', 'sgd_momentum': 0.08967610463914634, 'budget': 75, 'loss': 0.9149, 'val_loss': 0.9198, 'precision': 0.8337, 'recall': 0.7966},\n",
        "    {'batch_size': 4, 'learning_rate': 0.003905085427973375, 'optimizer': 'adam', 'sgd_momentum': 0.25946352029027697, 'budget': 75, 'loss': 0.9402, 'val_loss': 0.9424, 'precision': 0.8085, 'recall': 0.7639}\n",
        "]\n",
        "config_space_to_use = {'batch_size': 9, 'learning_rate': 0.004740049723020277, 'optimizer': 'adam', 'sgd_momentum': 0.08967610463914634, 'budget': 75, 'loss': 0.9149, 'val_loss': 0.9198, 'precision': 0.8337, 'recall': 0.7966}"
      ],
      "metadata": {
        "id": "SPiDnkSMKoZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}